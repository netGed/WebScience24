Log
Grundlegendes zu den Daten/Aufgabenstellung
- strukturierte Daten
- features (ID, Platform/Spiel, Nachricht) + target (positiv, negativ, neutral, irrelevant)
- Train: ca. 75k Datensätze, beim ersten Überfliegen keine Lücken, sehr sauber
- Val: ca. 1750, dabei aber erkennbare Lücken und unsaubere Einträge
- Inhalt: Nachrichten->Tweets, vmtl. um 2020 herum erstellt/gecrawlt (Tweets enthalten Bezug zum Corona-Lockdown, FIFA 20 usw)
- Daten sind komplett ungeeignet für eine Kategorisierung von "Hate-Speech"
- neben dem Tweet gibt es keine weiteren features, die für eine Klassifikation nützlich sein könnten


Trainingsdaten
- Spaltenbezeichnungen hinzugefügt: ['thread', 'topic', "sentiment", "tweet"]
- Indexspalte zurückgesetzt, da thread nicht unique ist
- Duplikate     => droppen
- Nullcheck     => NaN nur bei Tweets -> droppen, da Tweets das entscheidende Feature ist
- Typos/Inkonsistenzen      => ggf. bei CallOfDuty/CallOfDutyBlackopsColdWar, noch nichts geändert
- Ausreißer     => bei Tweets Ausreißer über die Charlänge/Wortanzahl bestimmt gedroppt
=> Bereinigter Datensatz: 70516 (-4166 /~-5,5%)

Validierungsdaten
- enthalten sehr viele Fehler
- geringer Umfang (> 2000)
=> statt Validierungsdaten die bereinigten Trainingsdaten nutzen (80-20); neuen Anteil Trainingsdaten dann nochmal vor Modeltraining in train/test aufsplitten (wieder 80-20)


Preprocessing des bereinigten Datensatzes
- Textvorverarbeitung: Links, Emojis, Sonderzeichen etc. entfernen, alles toLower
- Stopwörter entfernen
- Most frequent words: erstmal nicht entfernen, da auch Wörter wie "shit", "love" darunter sind, vmtl. relevant für die Klassifikation
- Lemmatization: alle Wörter auf ihren Wortstamm reduzieren
- Target-Spalte zu numerischem Wert ändern (für binäre Klassifikation: Negativ = 1, alles andere 0)
- Tokenization

Ergebnisse erste Modellvarianten
- Binäre Klassifikation deutlich besser als multi-class für NB
- RF besser als alle NB Modelle, ggf. aber überangepasst (sehr hohe Train-Acc)
- TF-IDF bringt minimale Verbesserung


TODO
- EDA fortführen, Ergebnisse festhalten
- detaillierter Auswertung der Modell (ROC-AUC)
- Modelle mit (originale/neuen) Validierungsdaten auswerten/vergleichen
- LSTMs auf multi-class target trainieren
- LSTMs mit komplett unbereinigten Daten trainieren
- ggf. Pipelines ergänzen