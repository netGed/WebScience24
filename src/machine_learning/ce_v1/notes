Log

Trainingsdaten
- Spaltenbezeichnungen hinzugefügt: ['thread', 'topic', "sentiment", "tweet"]
- Indexspalte zurückgesetzt, da thread nicht unique ist
- Duplikate     => droppen
- Nullcheck     => NaN nur bei Tweets -> droppen, da Tweets das entscheidende Feature ist
- Typos/Inkonsistenzen      => ggf. bei CallOfDuty/CallOfDutyBlackopsColdWar, noch nichts geändert
- Ausreißer     => bei Tweets Ausreißer über die Charlänge/Wortanzahl bestimmt gedroppt
=> Bereinigter Datensatz: 70516 (-4166 /~-5,5%)

Validierungsdaten
- enthalten sehr viele Fehler
- geringer Umfang (> 2000)
=> statt Validierungsdaten die bereinigten Trainingsdaten nutzen (80-20); neuen Anteil Trainingsdaten dann nochmal vor Modeltraining in train/test aufsplitten (wieder 80-20)


Preprocessing für Naive-Bayes
- Textvorverarbeitung: Links, Emojis, Sonderzeichen etc. entfernen, alles toLower
- Stopwörter entfernen
- Most frequent words: erstmal nicht entfernen, da auch Wörter wie "shit", "love" darunter sind, vmtl. relevant für die Klassifikation
- Lemmatization: alle Wörter auf ihren Wortstamm reduzieren
- Target-Spalte zu numerischem Wert ändern (für binäre Klassifikation: Negativ = 1, alles andere 0)
- Tokenization

Ergebnisse erste Modellvarianten
- Binäre Klassifikation deutlich besser als multi-class für NB
- RF besser als alle NB Modelle, ggf. aber überangepasst (sehr hohe Train-Acc)


TODO
- EDA fortführen, Ergebnisse festhalten
- prüfen, ob Tokenization und TF-IDF zu größeren Unterschieden führt
- detaillierter Auswertung der Modell (ROC-AUC)
- Modelle mit Validierungsdaten auswerten/vergleichen