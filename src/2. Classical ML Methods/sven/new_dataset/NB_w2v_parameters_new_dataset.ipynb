{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d9ec666-3144-4ba2-976b-c91b5fe258bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # ideal f체r counting features wie bow oder tfidf https://towardsdatascience.com/why-how-to-use-the-naive-bayes-algorithms-in-a-regulated-industry-with-sklearn-python-code-dbd8304ab2cf\n",
    "from sklearn.naive_bayes import GaussianNB # f체r Features in Decimal Form geeignet\n",
    "from sklearn.naive_bayes import ComplementNB # 채hnlich wie Multinomial, soll sich aber besser f체r imbalanced data eignen\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f636600b-8b3e-4bba-9b02-5f3733f11b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce5a26-cdc4-46a9-83d1-bf54813f34e4",
   "metadata": {},
   "source": [
    "## Evaluation neue Vectorize-Funktionen (08.12.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d1b5ff-2a21-4fc2-80d0-0ab9d8cd8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../functions/vectorize_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512a7731-bbeb-4a1a-89f5-eb2b208d84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_name = (('../../../data/new_datasets/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd28bfd-3511-4e24-be55-68d5dc363cfa",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e8df3a1-f856-46de-9ebf-1a113b0d3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_param = [df_cleaned]\n",
    "#text_column_param = ['tweet_cleaned']\n",
    "#label_column_param = ['label']\n",
    "vector_size_param = [10, 50, 100, 200, 300]\n",
    "window_param = [3, 5, 10, 20, 35]\n",
    "min_count_param = [1, 3, 5, 10]\n",
    "#test_size_param = [0.3]\n",
    "#random_state_param = [42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a0b505-189b-4273-90fd-19de1ec912ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "#all_combinations = product(df_param, text_column_param, label_column_param, vector_size_param, window_param, min_count_param, test_size_param, \n",
    " #                          random_state_param)\n",
    "all_combinations = product(vector_size_param, window_param, min_count_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b837dc-e18c-407f-962b-f04403759d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def used_parameters(vector_size=300, window=5, min_count=1):\n",
    "    vector_size_res = vector_size\n",
    "    window_res = window\n",
    "    min_count_res = min_count\n",
    "\n",
    "    return  vector_size_res, window_res, min_count_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3b311e1-6545-4983-a54c-433a50278162",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33403b87-f400-4c50-9abb-67cf0fa268bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model  vector_size  window  min_count  train_accuracy  train_recall  \\\n",
      "0   W2V Param           10       3          3        0.779239      0.152983   \n",
      "1   W2V Param           10       3          5        0.788125      0.080793   \n",
      "2   W2V Param           10       3         10        0.786562      0.098323   \n",
      "3   W2V Param           10       5          1        0.782388      0.135453   \n",
      "4   W2V Param           10       5          3        0.782504      0.159734   \n",
      "..        ...          ...     ...        ...             ...           ...   \n",
      "94  W2V Param          300      20         10        0.705520      0.596472   \n",
      "95  W2V Param          300      35          1        0.719933      0.566420   \n",
      "96  W2V Param          300      35          3        0.719280      0.569904   \n",
      "97  W2V Param          300      35          5        0.716108      0.579922   \n",
      "98  W2V Param          300      35         10        0.702139      0.591355   \n",
      "\n",
      "    train_precision  train_f1  test_accuracy  test_recall  test_precision  \\\n",
      "0          0.454398  0.228902       0.782893     0.162286        0.473567   \n",
      "1          0.535740  0.140411       0.788824     0.081909        0.531457   \n",
      "2          0.509019  0.164811       0.788007     0.106660        0.514145   \n",
      "3          0.472106  0.210509       0.782621     0.136004        0.466725   \n",
      "4          0.476918  0.239315       0.783546     0.163052        0.477936   \n",
      "..              ...       ...            ...          ...             ...   \n",
      "94         0.380443  0.464572       0.699532     0.590712        0.371410   \n",
      "95         0.393227  0.464195       0.719556     0.554223        0.389317   \n",
      "96         0.392913  0.465141       0.717760     0.563409        0.388459   \n",
      "97         0.390441  0.466681       0.714496     0.573361        0.385950   \n",
      "98         0.375848  0.459592       0.696866     0.592243        0.368764   \n",
      "\n",
      "     test_f1  \n",
      "0   0.241733  \n",
      "1   0.141941  \n",
      "2   0.176669  \n",
      "3   0.210630  \n",
      "4   0.243151  \n",
      "..       ...  \n",
      "94  0.456068  \n",
      "95  0.457359  \n",
      "96  0.459856  \n",
      "97  0.461349  \n",
      "98  0.454519  \n",
      "\n",
      "[99 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for combination in all_combinations:\n",
    "    #X_train, X_test, y_train, y_test = vectorize_w2v(*combination)\n",
    "    vector_size_used, window_used, min_count_used = used_parameters(*combination)\n",
    "    X_train, X_test, y_train, y_test = vectorize_w2v(df=df_cleaned, text_column='tweet_cleaned', \n",
    "                                                                                 label_column=\"label\", vector_size=vector_size_used,\n",
    "                                                    window=window_used, min_count=min_count_used)\n",
    "    \n",
    "    model = GaussianNB()  \n",
    "    model.fit(X_train, y_train)  \n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    result_dict = {\n",
    "        'model': 'W2V Param',\n",
    "        'vector_size': vector_size_used, \n",
    "        'window': window_used,\n",
    "        'min_count': min_count_used,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'train_precision': train_precision,\n",
    "        'train_f1': train_f1,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_recall': test_recall,\n",
    "        'test_precision': test_precision,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df.to_csv('eval_data/nb_grid_w2v_parameters_new_dataset.csv', index=False)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd6a19-08d0-4287-a61e-7f6a822bdd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
