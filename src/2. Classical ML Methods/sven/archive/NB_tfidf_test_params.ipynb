{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa35707d-8792-40a8-a529-ee504a891cda",
   "metadata": {},
   "source": [
    "# Naive Bayes Complement TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7381fe9-3d7f-4099-9111-7929f45f069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "import joblib\n",
    "from itertools import product\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc52a27-23de-4ab1-8fda-6e341cec671d",
   "metadata": {},
   "source": [
    "#### Evaluations-Funktion definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629804ab-9112-4fb7-bd24-f1ef0d9c1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"\\n\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred)))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c039c7-0f4f-4cae-ab65-db1164890017",
   "metadata": {},
   "source": [
    "#### Vektorisierungs Funktionen laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "944f4e23-eb41-4d62-9cf0-27f75f1aec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../functions/vectorize_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97c88a-5988-49da-8b51-c97daab38e54",
   "metadata": {},
   "source": [
    "#### Dataset in DF laden (Mixed Datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d238d06-98e9-40a2-9bc0-c4be4387021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_name = (('../../../data/mixed_dataset/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c08c04d-f6ae-4ba0-8d00-4ff53cf941d0",
   "metadata": {},
   "source": [
    "#### Vektorisierung vorbereiten: Parameter erstellen und kombinieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fc07a9-4350-4dc1-82bf-1cf09ac3ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tfidf_param(df, text_column, label_column, analyzer, ngram_range, max_features, norm, max_df=1.0, min_df=1, test_size=0.3, random_state=42):\n",
    "\n",
    "    df = df[df[text_column].notna()]\n",
    "\n",
    "    X_base = df[text_column]\n",
    "    y_base = df[label_column]\n",
    "\n",
    "    X_train_base, X_test_base, y_train_tfidf, y_test_tfidf = train_test_split(X_base, y_base, test_size=test_size,\n",
    "                                                                              random_state=random_state)\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer = analyzer, ngram_range=ngram_range, max_df=max_df, min_df=min_df, max_features=max_features, norm = norm)\n",
    "\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_base)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test_base)\n",
    "\n",
    "    return X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2e1dd-8d00-4203-b74e-5fe386a0c078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6945dff7-bcf6-4f00-a1e8-fbff94d59b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter zum Testen festlegen\n",
    "analyzer_param = ['char', 'word']\n",
    "ngram_range_param = [(1,4), (1,3), (1,1),(2,3),(1,15)]\n",
    "#max_df_param = [0.51, 0.75, 1.0]\n",
    "#min_df_param = [0.0, 0.1, 0.25, 0.4]\n",
    "max_features_param = [None, 10, 50, 100]#, 100]\n",
    "norm_param = ['l1', 'l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66529a0-5aff-4501-9e2f-4aaa804de2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_combinations = product(analyzer_param, ngram_range_param, max_df_param, min_df_param, max_features_param, norm_param)\n",
    "all_combinations = product(analyzer_param, ngram_range_param, max_features_param, norm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2149f642-9538-459f-91cd-a089d9c5588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def used_parameters(analyzer_param, ngram_range_param, max_features_param, norm_param):#max_df_param, min_df_param,\n",
    "    analyzer_param = analyzer_param\n",
    "    ngram_range_param = ngram_range_param\n",
    "    #max_df_param = max_df_param\n",
    "    #min_df_param = min_df_param\n",
    "    max_features_param = max_features_param\n",
    "    norm_param = norm_param\n",
    "\n",
    "    return  analyzer_param, ngram_range_param, max_features_param, norm_param #max_df_param, min_df_param,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbea50-87e4-423c-a225-7422519a4d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40729ee1-ae4c-49cb-9a01-89e80857e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dc96065-c5b8-47fa-be63-3b50c30ffa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "              model         alpha   norm analyzer ngram_range  max_features  \\\n",
      "0     TF-IDF (Comp)  1.000000e-10   True     char      (1, 4)           NaN   \n",
      "1     TF-IDF (Comp)  1.000000e-10  False     char      (1, 4)           NaN   \n",
      "2     TF-IDF (Comp)  1.000000e-02   True     char      (1, 4)           NaN   \n",
      "3     TF-IDF (Comp)  1.000000e-02  False     char      (1, 4)           NaN   \n",
      "4     TF-IDF (Comp)  1.000000e-01   True     char      (1, 4)           NaN   \n",
      "...             ...           ...    ...      ...         ...           ...   \n",
      "1115  TF-IDF (Comp)  5.000000e-01  False     word     (1, 15)         100.0   \n",
      "1116  TF-IDF (Comp)  7.500000e-01   True     word     (1, 15)         100.0   \n",
      "1117  TF-IDF (Comp)  7.500000e-01  False     word     (1, 15)         100.0   \n",
      "1118  TF-IDF (Comp)  1.000000e+00   True     word     (1, 15)         100.0   \n",
      "1119  TF-IDF (Comp)  1.000000e+00  False     word     (1, 15)         100.0   \n",
      "\n",
      "     norm_vectorizer  train_accuracy  train_recall  train_precision  train_f1  \\\n",
      "0                 l1        0.187958      1.000000         0.181562  0.307326   \n",
      "1                 l1        0.821164      0.836948         0.502179  0.627719   \n",
      "2                 l1        0.851950      0.429802         0.630719  0.511229   \n",
      "3                 l1        0.788390      0.791344         0.450303  0.573987   \n",
      "4                 l1        0.822734      0.021785         0.789474  0.042401   \n",
      "...              ...             ...           ...              ...       ...   \n",
      "1115              l2        0.655062      0.592758         0.282224  0.382386   \n",
      "1116              l2        0.583950      0.692196         0.256946  0.374774   \n",
      "1117              l2        0.655166      0.592564         0.282262  0.382381   \n",
      "1118              l2        0.584630      0.691615         0.257201  0.374961   \n",
      "1119              l2        0.655114      0.592467         0.282203  0.382306   \n",
      "\n",
      "      test_accuracy  test_recall  test_precision   test_f1  \n",
      "0          0.186025     0.999774        0.180865  0.306316  \n",
      "1          0.756145     0.604709        0.386150  0.471325  \n",
      "2          0.832736     0.363822        0.552804  0.438831  \n",
      "3          0.753703     0.707041        0.396270  0.507887  \n",
      "4          0.822318     0.016980        0.757576  0.033215  \n",
      "...             ...          ...             ...       ...  \n",
      "1115       0.645206     0.581164        0.272072  0.370632  \n",
      "1116       0.574068     0.680326        0.249191  0.364773  \n",
      "1117       0.645206     0.581164        0.272072  0.370632  \n",
      "1118       0.574638     0.679647        0.249356  0.364852  \n",
      "1119       0.645369     0.581164        0.272187  0.370739  \n",
      "\n",
      "[1120 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "for combination in all_combinations:\n",
    "    #max_df_used, min_df_used,max_df=max_df_used, min_df=min_df_used, \n",
    "    analyzer_used, ngram_range_used, max_features_used, norm_used = used_parameters(*combination)\n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, vectorizer_tfidf = vectorize_tfidf_param(df=df_cleaned, text_column='tweet_cleaned', \n",
    "                                                                                 label_column=\"label\", analyzer=analyzer_used, ngram_range=ngram_range_used, \n",
    "                                                                                                      max_features=max_features_used, norm=norm_used)\n",
    "    \n",
    "    param_grid = {\n",
    "    'alpha' : [1.0e-10, 0.01, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "    'norm' : [True, False]\n",
    "    }\n",
    "\n",
    "    cnb = ComplementNB()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=cnb, param_grid=param_grid, scoring='f1', cv=3, verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "    for idx, params in enumerate(grid_search.cv_results_['params']):\n",
    "        model = ComplementNB(**params)  \n",
    "        model.fit(X_train_tfidf, y_train_tfidf)  \n",
    "\n",
    "        y_train_pred_tfidf = model.predict(X_train_tfidf)\n",
    "\n",
    "        y_test_pred_tfidf = model.predict(X_test_tfidf)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "        train_recall = recall_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "        train_precision = precision_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "        train_f1 = f1_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test_tfidf, y_test_pred_tfidf)\n",
    "        test_recall = recall_score(y_test_tfidf, y_test_pred_tfidf)\n",
    "        test_precision = precision_score(y_test_tfidf, y_test_pred_tfidf)\n",
    "        test_f1 = f1_score(y_test_tfidf, y_test_pred_tfidf)\n",
    "\n",
    "        #test_report = classification_report(y_test_tfidf, y_test_pred_tfidf, output_dict=True)\n",
    "\n",
    "        result_dict = {\n",
    "            'model': 'TF-IDF (Comp)',\n",
    "            'alpha': params['alpha'],\n",
    "            'norm': params['norm'],\n",
    "            'analyzer': analyzer_used, \n",
    "            'ngram_range': ngram_range_used, \n",
    "            #'max_df':max_df_used, \n",
    "            #'min_df':min_df_used, \n",
    "            'max_features':max_features_used, \n",
    "            'norm_vectorizer':norm_used,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'train_recall': train_recall,\n",
    "            'train_precision': train_precision,\n",
    "            'train_f1': train_f1,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_recall': test_recall,\n",
    "            'test_precision': test_precision,\n",
    "            'test_f1': test_f1,\n",
    "            #'test_recall_1': test_report['1']['recall'],\n",
    "        }\n",
    "        results_list.append(result_dict)\n",
    "\n",
    "\n",
    "results_df_comp = pd.DataFrame(results_list)\n",
    "results_df_comp.to_csv('eval_data/cnb_grid_tfidf_mixed_dataset_final_test.csv', index=False)\n",
    "\n",
    "print(results_df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6a5d4b-deb6-4e4c-85db-b4076e47f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "      <th>norm</th>\n",
       "      <th>analyzer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_features</th>\n",
       "      <th>norm_vectorizer</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.187958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>0.307326</td>\n",
       "      <td>0.186025</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.180865</td>\n",
       "      <td>0.306316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>False</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.821164</td>\n",
       "      <td>0.836948</td>\n",
       "      <td>0.502179</td>\n",
       "      <td>0.627719</td>\n",
       "      <td>0.756145</td>\n",
       "      <td>0.604709</td>\n",
       "      <td>0.386150</td>\n",
       "      <td>0.471325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.851950</td>\n",
       "      <td>0.429802</td>\n",
       "      <td>0.630719</td>\n",
       "      <td>0.511229</td>\n",
       "      <td>0.832736</td>\n",
       "      <td>0.363822</td>\n",
       "      <td>0.552804</td>\n",
       "      <td>0.438831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.788390</td>\n",
       "      <td>0.791344</td>\n",
       "      <td>0.450303</td>\n",
       "      <td>0.573987</td>\n",
       "      <td>0.753703</td>\n",
       "      <td>0.707041</td>\n",
       "      <td>0.396270</td>\n",
       "      <td>0.507887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.822734</td>\n",
       "      <td>0.021785</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.042401</td>\n",
       "      <td>0.822318</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.033215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>word</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.655062</td>\n",
       "      <td>0.592758</td>\n",
       "      <td>0.282224</td>\n",
       "      <td>0.382386</td>\n",
       "      <td>0.645206</td>\n",
       "      <td>0.581164</td>\n",
       "      <td>0.272072</td>\n",
       "      <td>0.370632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>True</td>\n",
       "      <td>word</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.583950</td>\n",
       "      <td>0.692196</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.374774</td>\n",
       "      <td>0.574068</td>\n",
       "      <td>0.680326</td>\n",
       "      <td>0.249191</td>\n",
       "      <td>0.364773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>word</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.655166</td>\n",
       "      <td>0.592564</td>\n",
       "      <td>0.282262</td>\n",
       "      <td>0.382381</td>\n",
       "      <td>0.645206</td>\n",
       "      <td>0.581164</td>\n",
       "      <td>0.272072</td>\n",
       "      <td>0.370632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "      <td>word</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.584630</td>\n",
       "      <td>0.691615</td>\n",
       "      <td>0.257201</td>\n",
       "      <td>0.374961</td>\n",
       "      <td>0.574638</td>\n",
       "      <td>0.679647</td>\n",
       "      <td>0.249356</td>\n",
       "      <td>0.364852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>word</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.655114</td>\n",
       "      <td>0.592467</td>\n",
       "      <td>0.282203</td>\n",
       "      <td>0.382306</td>\n",
       "      <td>0.645369</td>\n",
       "      <td>0.581164</td>\n",
       "      <td>0.272187</td>\n",
       "      <td>0.370739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              model         alpha   norm analyzer ngram_range  max_features  \\\n",
       "0     TF-IDF (Comp)  1.000000e-10   True     char      (1, 4)           NaN   \n",
       "1     TF-IDF (Comp)  1.000000e-10  False     char      (1, 4)           NaN   \n",
       "2     TF-IDF (Comp)  1.000000e-02   True     char      (1, 4)           NaN   \n",
       "3     TF-IDF (Comp)  1.000000e-02  False     char      (1, 4)           NaN   \n",
       "4     TF-IDF (Comp)  1.000000e-01   True     char      (1, 4)           NaN   \n",
       "...             ...           ...    ...      ...         ...           ...   \n",
       "1115  TF-IDF (Comp)  5.000000e-01  False     word     (1, 15)         100.0   \n",
       "1116  TF-IDF (Comp)  7.500000e-01   True     word     (1, 15)         100.0   \n",
       "1117  TF-IDF (Comp)  7.500000e-01  False     word     (1, 15)         100.0   \n",
       "1118  TF-IDF (Comp)  1.000000e+00   True     word     (1, 15)         100.0   \n",
       "1119  TF-IDF (Comp)  1.000000e+00  False     word     (1, 15)         100.0   \n",
       "\n",
       "     norm_vectorizer  train_accuracy  train_recall  train_precision  train_f1  \\\n",
       "0                 l1        0.187958      1.000000         0.181562  0.307326   \n",
       "1                 l1        0.821164      0.836948         0.502179  0.627719   \n",
       "2                 l1        0.851950      0.429802         0.630719  0.511229   \n",
       "3                 l1        0.788390      0.791344         0.450303  0.573987   \n",
       "4                 l1        0.822734      0.021785         0.789474  0.042401   \n",
       "...              ...             ...           ...              ...       ...   \n",
       "1115              l2        0.655062      0.592758         0.282224  0.382386   \n",
       "1116              l2        0.583950      0.692196         0.256946  0.374774   \n",
       "1117              l2        0.655166      0.592564         0.282262  0.382381   \n",
       "1118              l2        0.584630      0.691615         0.257201  0.374961   \n",
       "1119              l2        0.655114      0.592467         0.282203  0.382306   \n",
       "\n",
       "      test_accuracy  test_recall  test_precision   test_f1  \n",
       "0          0.186025     0.999774        0.180865  0.306316  \n",
       "1          0.756145     0.604709        0.386150  0.471325  \n",
       "2          0.832736     0.363822        0.552804  0.438831  \n",
       "3          0.753703     0.707041        0.396270  0.507887  \n",
       "4          0.822318     0.016980        0.757576  0.033215  \n",
       "...             ...          ...             ...       ...  \n",
       "1115       0.645206     0.581164        0.272072  0.370632  \n",
       "1116       0.574068     0.680326        0.249191  0.364773  \n",
       "1117       0.645206     0.581164        0.272072  0.370632  \n",
       "1118       0.574638     0.679647        0.249356  0.364852  \n",
       "1119       0.645369     0.581164        0.272187  0.370739  \n",
       "\n",
       "[1120 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ddd11e-1e01-4d86-b805-aefdf1ec8235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "      <th>norm</th>\n",
       "      <th>analyzer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_features</th>\n",
       "      <th>norm_vectorizer</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.795524</td>\n",
       "      <td>0.745933</td>\n",
       "      <td>0.458490</td>\n",
       "      <td>0.567911</td>\n",
       "      <td>0.765709</td>\n",
       "      <td>0.675345</td>\n",
       "      <td>0.408295</td>\n",
       "      <td>0.508914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.788390</td>\n",
       "      <td>0.791344</td>\n",
       "      <td>0.450303</td>\n",
       "      <td>0.573987</td>\n",
       "      <td>0.753703</td>\n",
       "      <td>0.707041</td>\n",
       "      <td>0.396270</td>\n",
       "      <td>0.507887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.782739</td>\n",
       "      <td>0.811290</td>\n",
       "      <td>0.443662</td>\n",
       "      <td>0.573629</td>\n",
       "      <td>0.747558</td>\n",
       "      <td>0.723794</td>\n",
       "      <td>0.390831</td>\n",
       "      <td>0.507581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>word</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.842095</td>\n",
       "      <td>0.684353</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.609599</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.575957</td>\n",
       "      <td>0.447966</td>\n",
       "      <td>0.503962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.842854</td>\n",
       "      <td>0.453882</td>\n",
       "      <td>0.590029</td>\n",
       "      <td>0.745483</td>\n",
       "      <td>0.716550</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.503020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.819664</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.819713</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819682</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819682</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.819958</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.819958</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  alpha   norm analyzer ngram_range  max_features  \\\n",
       "21   TF-IDF (Comp)   0.25  False     char      (1, 4)           NaN   \n",
       "3    TF-IDF (Comp)   0.01  False     char      (1, 4)           NaN   \n",
       "19   TF-IDF (Comp)   0.10  False     char      (1, 4)           NaN   \n",
       "806  TF-IDF (Comp)   0.50   True     word      (1, 1)           NaN   \n",
       "17   TF-IDF (Comp)   0.01  False     char      (1, 4)           NaN   \n",
       "..             ...    ...    ...      ...         ...           ...   \n",
       "248  TF-IDF (Comp)   0.75   True     char      (1, 1)           NaN   \n",
       "236  TF-IDF (Comp)   1.00   True     char      (1, 1)           NaN   \n",
       "320  TF-IDF (Comp)   1.00   True     char      (1, 1)         100.0   \n",
       "318  TF-IDF (Comp)   0.75   True     char      (1, 1)         100.0   \n",
       "234  TF-IDF (Comp)   0.75   True     char      (1, 1)           NaN   \n",
       "\n",
       "    norm_vectorizer  train_accuracy  train_recall  train_precision  train_f1  \\\n",
       "21               l2        0.795524      0.745933         0.458490  0.567911   \n",
       "3                l1        0.788390      0.791344         0.450303  0.573987   \n",
       "19               l2        0.782739      0.811290         0.443662  0.573629   \n",
       "806              l2        0.842095      0.684353         0.549568  0.609599   \n",
       "17               l2        0.789001      0.842854         0.453882  0.590029   \n",
       "..              ...             ...           ...              ...       ...   \n",
       "248              l2        0.819664      0.000484         0.238095  0.000966   \n",
       "236              l1        0.819682      0.000097         0.083333  0.000193   \n",
       "320              l1        0.819682      0.000097         0.083333  0.000193   \n",
       "318              l1        0.819717      0.000194         0.166667  0.000387   \n",
       "234              l1        0.819717      0.000194         0.166667  0.000387   \n",
       "\n",
       "     test_accuracy  test_recall  test_precision   test_f1  \n",
       "21        0.765709     0.675345        0.408295  0.508914  \n",
       "3         0.753703     0.707041        0.396270  0.507887  \n",
       "19        0.747558     0.723794        0.390831  0.507581  \n",
       "806       0.796191     0.575957        0.447966  0.503962  \n",
       "17        0.745483     0.716550        0.387535  0.503020  \n",
       "..             ...          ...             ...       ...  \n",
       "248       0.819713     0.000453        0.117647  0.000902  \n",
       "236       0.819998     0.000226        0.125000  0.000452  \n",
       "320       0.819998     0.000226        0.125000  0.000452  \n",
       "318       0.819958     0.000226        0.111111  0.000452  \n",
       "234       0.819958     0.000226        0.111111  0.000452  \n",
       "\n",
       "[1120 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_comp.sort_values(by=['test_f1'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f36b8fb-77f7-4354-8fc7-c048354186c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "      <th>norm</th>\n",
       "      <th>analyzer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_features</th>\n",
       "      <th>norm_vectorizer</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.180894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180279</td>\n",
       "      <td>0.305485</td>\n",
       "      <td>0.180246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>0.304862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.180894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180279</td>\n",
       "      <td>0.305485</td>\n",
       "      <td>0.180246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>0.304862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.187958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>0.307326</td>\n",
       "      <td>0.186025</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.180865</td>\n",
       "      <td>0.306316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.186737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181339</td>\n",
       "      <td>0.307006</td>\n",
       "      <td>0.185252</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.180724</td>\n",
       "      <td>0.306114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180370</td>\n",
       "      <td>0.305616</td>\n",
       "      <td>0.180490</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.179863</td>\n",
       "      <td>0.304878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819752</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.819713</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.819958</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819682</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819682</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>TF-IDF (Comp)</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>True</td>\n",
       "      <td>char</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.819958</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             model         alpha  norm analyzer ngram_range  max_features  \\\n",
       "280  TF-IDF (Comp)  1.000000e-10  True     char      (1, 1)          50.0   \n",
       "294  TF-IDF (Comp)  1.000000e-10  True     char      (1, 1)          50.0   \n",
       "0    TF-IDF (Comp)  1.000000e-10  True     char      (1, 4)           NaN   \n",
       "14   TF-IDF (Comp)  1.000000e-10  True     char      (1, 4)           NaN   \n",
       "224  TF-IDF (Comp)  1.000000e-10  True     char      (1, 1)           NaN   \n",
       "..             ...           ...   ...      ...         ...           ...   \n",
       "230  TF-IDF (Comp)  2.500000e-01  True     char      (1, 1)           NaN   \n",
       "318  TF-IDF (Comp)  7.500000e-01  True     char      (1, 1)         100.0   \n",
       "320  TF-IDF (Comp)  1.000000e+00  True     char      (1, 1)         100.0   \n",
       "236  TF-IDF (Comp)  1.000000e+00  True     char      (1, 1)           NaN   \n",
       "234  TF-IDF (Comp)  7.500000e-01  True     char      (1, 1)           NaN   \n",
       "\n",
       "    norm_vectorizer  train_accuracy  train_recall  train_precision  train_f1  \\\n",
       "280              l1        0.180894      1.000000         0.180279  0.305485   \n",
       "294              l2        0.180894      1.000000         0.180279  0.305485   \n",
       "0                l1        0.187958      1.000000         0.181562  0.307326   \n",
       "14               l2        0.186737      1.000000         0.181339  0.307006   \n",
       "224              l1        0.181400      1.000000         0.180370  0.305616   \n",
       "..              ...             ...           ...              ...       ...   \n",
       "230              l1        0.819752      0.000678         0.350000  0.001353   \n",
       "318              l1        0.819717      0.000194         0.166667  0.000387   \n",
       "320              l1        0.819682      0.000097         0.083333  0.000193   \n",
       "236              l1        0.819682      0.000097         0.083333  0.000193   \n",
       "234              l1        0.819717      0.000194         0.166667  0.000387   \n",
       "\n",
       "     test_accuracy  test_recall  test_precision   test_f1  \n",
       "280       0.180246     1.000000        0.179845  0.304862  \n",
       "294       0.180246     1.000000        0.179845  0.304862  \n",
       "0         0.186025     0.999774        0.180865  0.306316  \n",
       "14        0.185252     0.999774        0.180724  0.306114  \n",
       "224       0.180490     0.999774        0.179863  0.304878  \n",
       "..             ...          ...             ...       ...  \n",
       "230       0.819713     0.000453        0.117647  0.000902  \n",
       "318       0.819958     0.000226        0.111111  0.000452  \n",
       "320       0.819998     0.000226        0.125000  0.000452  \n",
       "236       0.819998     0.000226        0.125000  0.000452  \n",
       "234       0.819958     0.000226        0.111111  0.000452  \n",
       "\n",
       "[1120 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_comp.sort_values(by=['test_recall'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824fd4b-e5f7-4b42-978e-fedd56ed2381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61da3c-45eb-42a6-b9b8-e8885ada2781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb23b46-a931-4372-b759-f6b39ec56a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd43380-1384-443c-a751-bc494de68eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919eaaa-5ba4-4682-8e6f-a23aa3a0813d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddbc1ca-9242-407c-8836-15f4bfc7a69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb40260-9543-4243-a54d-7069bebe125d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59120e-033d-46a5-8526-b49dfea263e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c0be9-31a0-46ad-ab57-625c62c2329a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08c5be-d0e6-4bd2-b82d-5b1698e75271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e606a-9b20-4948-9e84-bf0ad758690a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d896026-a9a4-4caa-952b-324b093748d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa20cb-1745-4933-97f6-ff672e85e911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7438d-d343-4d45-b851-579ed278a78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8a8ca-6bbb-4dcd-a0f7-37b2e8013076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abde8c-70b1-4ea1-ae14-9e7105a5b29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6610f2d6-860b-42b3-a91c-7e75541cdc85",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57684d01-0216-4a0d-a9d9-5e5b6b07c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_c = TfidfVectorizer(analyzer = 'char', ngram_range=(1,5), max_df=1, min_df=0.0, max_features=100, norm = 'l2') #analyzer = word, norm= 'l1' oder None (l2 Standard)\n",
    "\n",
    "X_train_c = tfidf_vectorizer_c.fit_transform(X_train_base)\n",
    "X_test_c = tfidf_vectorizer_c.transform(X_test_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
