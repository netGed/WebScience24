{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9ec666-3144-4ba2-976b-c91b5fe258bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # ideal f체r counting features wie bow oder tfidf https://towardsdatascience.com/why-how-to-use-the-naive-bayes-algorithms-in-a-regulated-industry-with-sklearn-python-code-dbd8304ab2cf\n",
    "from sklearn.naive_bayes import GaussianNB # f체r Features in Decimal Form geeignet\n",
    "from sklearn.naive_bayes import ComplementNB # 채hnlich wie Multinomial, soll sich aber besser f체r imbalanced data eignen\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f636600b-8b3e-4bba-9b02-5f3733f11b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"\\n\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred)))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce5a26-cdc4-46a9-83d1-bf54813f34e4",
   "metadata": {},
   "source": [
    "## Evaluation neue Vectorize-Funktionen (08.12.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d1b5ff-2a21-4fc2-80d0-0ab9d8cd8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../functions/vectorize_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512a7731-bbeb-4a1a-89f5-eb2b208d84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_name = (('../../../data/mixed_dataset/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73a06de-70e1-4076-907b-66d3205c5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, vectorizer_w2v  = vectorize_w2v(df=df_cleaned, text_column='tweet_cleaned', \n",
    "                                                                                 label_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a198a29-26dc-4c6c-8155-b307c8bd7c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57332, 300)\n",
      "(24572, 300)\n",
      "(57332,)\n",
      "(24572,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2290f47-b057-499f-930e-06250433b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/vectorizer/vectorizer_w2v.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save vectorizer\n",
    "\n",
    "#with open('saved_models/vectorizer/vectorizer_nb_w2v.pkl','wb') as f:\n",
    " #   pickle.dump(vectorizer_w2v, f)\n",
    "\n",
    "joblib.dump(vectorizer_w2v, 'saved_models/vectorizer/vectorizer_w2v.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd28bfd-3511-4e24-be55-68d5dc363cfa",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d012c6c6-6df3-4d6d-acf6-c1a0456995f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d37edd1-4623-4c6d-af74-07119a2e79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.636252645287319\n",
      "F1 Score: 0.4250611089669367\n",
      "Recall: 0.7480190174326465\n",
      "Precision: 0.2968820199478839\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "       0     1\n",
      "0  12330  7825\n",
      "1   1113  3304\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.61      0.73     20155\n",
      "           1       0.30      0.75      0.43      4417\n",
      "\n",
      "    accuracy                           0.64     24572\n",
      "   macro avg       0.61      0.68      0.58     24572\n",
      "weighted avg       0.81      0.64      0.68     24572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4b6223-5066-402b-8bfd-1e80c1d2e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/w2v/model_nb_w2v.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model speichern\n",
    "#with open('saved_models/model_nb_tfidf_mn.pkl','wb') as f:\n",
    " #   pickle.dump(clf_tfidf,f)\n",
    "joblib.dump(clf, 'saved_models/w2v/model_nb_w2v.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "131f8528-a1a8-43a9-9bf5-f6ee57762b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "   model        priors  var_smoothing  train_accuracy  train_recall  \\\n",
      "0    W2V          None   1.000000e-10        0.648399      0.743997   \n",
      "1    W2V          None   1.000000e-09        0.648399      0.743997   \n",
      "2    W2V          None   1.000000e-02        0.645887      0.748451   \n",
      "3    W2V          None   1.000000e-01        0.624608      0.781274   \n",
      "4    W2V          None   2.500000e-01        0.602055      0.807417   \n",
      "5    W2V          None   5.000000e-01        0.583671      0.822909   \n",
      "6    W2V          None   7.500000e-01        0.577949      0.826201   \n",
      "7    W2V          None   1.000000e+00        0.578944      0.823683   \n",
      "8    W2V  [0.25, 0.75]   1.000000e-10        0.602805      0.806352   \n",
      "9    W2V  [0.25, 0.75]   1.000000e-09        0.602805      0.806352   \n",
      "10   W2V  [0.25, 0.75]   1.000000e-02        0.598357      0.810515   \n",
      "11   W2V  [0.25, 0.75]   1.000000e-01        0.567519      0.843242   \n",
      "12   W2V  [0.25, 0.75]   2.500000e-01        0.529582      0.873451   \n",
      "13   W2V  [0.25, 0.75]   5.000000e-01        0.490442      0.900368   \n",
      "14   W2V  [0.25, 0.75]   7.500000e-01        0.466127      0.918474   \n",
      "15   W2V  [0.25, 0.75]   1.000000e+00        0.447289      0.931352   \n",
      "16   W2V    [0.5, 0.5]   1.000000e-10        0.622637      0.782630   \n",
      "17   W2V    [0.5, 0.5]   1.000000e-09        0.622637      0.782630   \n",
      "18   W2V    [0.5, 0.5]   1.000000e-02        0.619427      0.787858   \n",
      "19   W2V    [0.5, 0.5]   1.000000e-01        0.591886      0.818455   \n",
      "20   W2V    [0.5, 0.5]   2.500000e-01        0.560106      0.848567   \n",
      "21   W2V    [0.5, 0.5]   5.000000e-01        0.528501      0.874419   \n",
      "22   W2V    [0.5, 0.5]   7.500000e-01        0.510326      0.887684   \n",
      "23   W2V    [0.5, 0.5]   1.000000e+00        0.498116      0.895043   \n",
      "\n",
      "    train_precision  train_f1  test_accuracy  test_recall  test_precision  \\\n",
      "0          0.304945  0.432585       0.636253     0.748019        0.296882   \n",
      "1          0.304945  0.432585       0.636253     0.748019        0.296882   \n",
      "2          0.303924  0.432302       0.633078     0.753000        0.295618   \n",
      "3          0.295222  0.428518       0.613910     0.783337        0.288574   \n",
      "4          0.285925  0.422303       0.591161     0.807788        0.279514   \n",
      "5          0.278300  0.415935       0.574149     0.823183        0.272993   \n",
      "6          0.275836  0.413591       0.569998     0.827485        0.271565   \n",
      "7          0.275968  0.413423       0.570894     0.822730        0.271295   \n",
      "8          0.286186  0.422441       0.589126     0.804845        0.277973   \n",
      "9          0.286186  0.422441       0.589126     0.804845        0.277973   \n",
      "10         0.284331  0.420981       0.584934     0.810052        0.276550   \n",
      "11         0.273138  0.412622       0.555307     0.846049        0.267234   \n",
      "12         0.260091  0.400826       0.520389     0.880915        0.256832   \n",
      "13         0.248079  0.388982       0.482541     0.906724        0.245585   \n",
      "14         0.241669  0.382654       0.457431     0.922345        0.238762   \n",
      "15         0.236933  0.377764       0.440217     0.933892        0.234535   \n",
      "16         0.294216  0.427661       0.609067     0.784695        0.285950   \n",
      "17         0.294216  0.427661       0.609067     0.784695        0.285950   \n",
      "18         0.293067  0.427218       0.606056     0.790355        0.285096   \n",
      "19         0.281992  0.419462       0.578870     0.820240        0.274949   \n",
      "20         0.270327  0.410031       0.548999     0.850351        0.264936   \n",
      "21         0.259765  0.400541       0.520674     0.875028        0.256113   \n",
      "22         0.254088  0.395087       0.502605     0.889065        0.250782   \n",
      "23         0.250284  0.391181       0.491779     0.899026        0.247986   \n",
      "\n",
      "     test_f1  test_recall_1  \n",
      "0   0.425061       0.748019  \n",
      "1   0.425061       0.748019  \n",
      "2   0.424560       0.753000  \n",
      "3   0.421771       0.783337  \n",
      "4   0.415318       0.807788  \n",
      "5   0.410014       0.823183  \n",
      "6   0.408928       0.827485  \n",
      "7   0.408040       0.822730  \n",
      "8   0.413228       0.804845  \n",
      "9   0.413228       0.804845  \n",
      "10  0.412331       0.810052  \n",
      "11  0.406174       0.846049  \n",
      "12  0.397710       0.880915  \n",
      "13  0.386490       0.906724  \n",
      "14  0.379330       0.922345  \n",
      "15  0.374915       0.933892  \n",
      "16  0.419156       0.784695  \n",
      "17  0.419156       0.784695  \n",
      "18  0.419037       0.790355  \n",
      "19  0.411845       0.820240  \n",
      "20  0.404001       0.850351  \n",
      "21  0.396248       0.875028  \n",
      "22  0.391213       0.889065  \n",
      "23  0.388742       0.899026  \n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "param_grid = {\n",
    "    'priors' : [None, [.25,.75], [.5,.5]],\n",
    "    'var_smoothing' : [1.0e-10,1e-9, 0.01, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, scoring='f1', cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "for idx, params in enumerate(grid_search.cv_results_['params']):\n",
    "    model = GaussianNB(**params)  \n",
    "    model.fit(X_train, y_train)  \n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "    result_dict = {\n",
    "        'model': 'W2V',\n",
    "        'priors': params['priors'],\n",
    "        'var_smoothing': params['var_smoothing'],\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'train_precision': train_precision,\n",
    "        'train_f1': train_f1,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_recall': test_recall,\n",
    "        'test_precision': test_precision,\n",
    "        'test_f1': test_f1,\n",
    "        'test_recall_1': test_report['1']['recall'],\n",
    "    }\n",
    "\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "    filename = f'saved_models/w2v/model_nb_w2v_{idx}.joblib'\n",
    "    #with open(filename,'wb') as file:\n",
    "     #   pickle.dump(model,file)\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df.to_csv('eval_data/nb_grid_w2v_mixed_dataset.csv', index=False)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d23d991-89fb-4f58-8b17-0ae489e9d8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.743997</td>\n",
       "      <td>0.304945</td>\n",
       "      <td>0.432585</td>\n",
       "      <td>0.636253</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>0.425061</td>\n",
       "      <td>0.748019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.743997</td>\n",
       "      <td>0.304945</td>\n",
       "      <td>0.432585</td>\n",
       "      <td>0.636253</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>0.425061</td>\n",
       "      <td>0.748019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.645887</td>\n",
       "      <td>0.748451</td>\n",
       "      <td>0.303924</td>\n",
       "      <td>0.432302</td>\n",
       "      <td>0.633078</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.295618</td>\n",
       "      <td>0.424560</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.624608</td>\n",
       "      <td>0.781274</td>\n",
       "      <td>0.295222</td>\n",
       "      <td>0.428518</td>\n",
       "      <td>0.613910</td>\n",
       "      <td>0.783337</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.421771</td>\n",
       "      <td>0.783337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.622637</td>\n",
       "      <td>0.782630</td>\n",
       "      <td>0.294216</td>\n",
       "      <td>0.427661</td>\n",
       "      <td>0.609067</td>\n",
       "      <td>0.784695</td>\n",
       "      <td>0.285950</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>0.784695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.622637</td>\n",
       "      <td>0.782630</td>\n",
       "      <td>0.294216</td>\n",
       "      <td>0.427661</td>\n",
       "      <td>0.609067</td>\n",
       "      <td>0.784695</td>\n",
       "      <td>0.285950</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>0.784695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.619427</td>\n",
       "      <td>0.787858</td>\n",
       "      <td>0.293067</td>\n",
       "      <td>0.427218</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>0.790355</td>\n",
       "      <td>0.285096</td>\n",
       "      <td>0.419037</td>\n",
       "      <td>0.790355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.602055</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.285925</td>\n",
       "      <td>0.422303</td>\n",
       "      <td>0.591161</td>\n",
       "      <td>0.807788</td>\n",
       "      <td>0.279514</td>\n",
       "      <td>0.415318</td>\n",
       "      <td>0.807788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.602805</td>\n",
       "      <td>0.806352</td>\n",
       "      <td>0.286186</td>\n",
       "      <td>0.422441</td>\n",
       "      <td>0.589126</td>\n",
       "      <td>0.804845</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.602805</td>\n",
       "      <td>0.806352</td>\n",
       "      <td>0.286186</td>\n",
       "      <td>0.422441</td>\n",
       "      <td>0.589126</td>\n",
       "      <td>0.804845</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.598357</td>\n",
       "      <td>0.810515</td>\n",
       "      <td>0.284331</td>\n",
       "      <td>0.420981</td>\n",
       "      <td>0.584934</td>\n",
       "      <td>0.810052</td>\n",
       "      <td>0.276550</td>\n",
       "      <td>0.412331</td>\n",
       "      <td>0.810052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.591886</td>\n",
       "      <td>0.818455</td>\n",
       "      <td>0.281992</td>\n",
       "      <td>0.419462</td>\n",
       "      <td>0.578870</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.274949</td>\n",
       "      <td>0.411845</td>\n",
       "      <td>0.820240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.583671</td>\n",
       "      <td>0.822909</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.415935</td>\n",
       "      <td>0.574149</td>\n",
       "      <td>0.823183</td>\n",
       "      <td>0.272993</td>\n",
       "      <td>0.410014</td>\n",
       "      <td>0.823183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.577949</td>\n",
       "      <td>0.826201</td>\n",
       "      <td>0.275836</td>\n",
       "      <td>0.413591</td>\n",
       "      <td>0.569998</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>0.271565</td>\n",
       "      <td>0.408928</td>\n",
       "      <td>0.827485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.578944</td>\n",
       "      <td>0.823683</td>\n",
       "      <td>0.275968</td>\n",
       "      <td>0.413423</td>\n",
       "      <td>0.570894</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.271295</td>\n",
       "      <td>0.408040</td>\n",
       "      <td>0.822730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.567519</td>\n",
       "      <td>0.843242</td>\n",
       "      <td>0.273138</td>\n",
       "      <td>0.412622</td>\n",
       "      <td>0.555307</td>\n",
       "      <td>0.846049</td>\n",
       "      <td>0.267234</td>\n",
       "      <td>0.406174</td>\n",
       "      <td>0.846049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.560106</td>\n",
       "      <td>0.848567</td>\n",
       "      <td>0.270327</td>\n",
       "      <td>0.410031</td>\n",
       "      <td>0.548999</td>\n",
       "      <td>0.850351</td>\n",
       "      <td>0.264936</td>\n",
       "      <td>0.404001</td>\n",
       "      <td>0.850351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.529582</td>\n",
       "      <td>0.873451</td>\n",
       "      <td>0.260091</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.520389</td>\n",
       "      <td>0.880915</td>\n",
       "      <td>0.256832</td>\n",
       "      <td>0.397710</td>\n",
       "      <td>0.880915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.528501</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>0.259765</td>\n",
       "      <td>0.400541</td>\n",
       "      <td>0.520674</td>\n",
       "      <td>0.875028</td>\n",
       "      <td>0.256113</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>0.875028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.510326</td>\n",
       "      <td>0.887684</td>\n",
       "      <td>0.254088</td>\n",
       "      <td>0.395087</td>\n",
       "      <td>0.502605</td>\n",
       "      <td>0.889065</td>\n",
       "      <td>0.250782</td>\n",
       "      <td>0.391213</td>\n",
       "      <td>0.889065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.498116</td>\n",
       "      <td>0.895043</td>\n",
       "      <td>0.250284</td>\n",
       "      <td>0.391181</td>\n",
       "      <td>0.491779</td>\n",
       "      <td>0.899026</td>\n",
       "      <td>0.247986</td>\n",
       "      <td>0.388742</td>\n",
       "      <td>0.899026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.490442</td>\n",
       "      <td>0.900368</td>\n",
       "      <td>0.248079</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.482541</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.245585</td>\n",
       "      <td>0.386490</td>\n",
       "      <td>0.906724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.466127</td>\n",
       "      <td>0.918474</td>\n",
       "      <td>0.241669</td>\n",
       "      <td>0.382654</td>\n",
       "      <td>0.457431</td>\n",
       "      <td>0.922345</td>\n",
       "      <td>0.238762</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.922345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.447289</td>\n",
       "      <td>0.931352</td>\n",
       "      <td>0.236933</td>\n",
       "      <td>0.377764</td>\n",
       "      <td>0.440217</td>\n",
       "      <td>0.933892</td>\n",
       "      <td>0.234535</td>\n",
       "      <td>0.374915</td>\n",
       "      <td>0.933892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        priors  var_smoothing  train_accuracy  train_recall  \\\n",
       "0    W2V          None   1.000000e-10        0.648399      0.743997   \n",
       "1    W2V          None   1.000000e-09        0.648399      0.743997   \n",
       "2    W2V          None   1.000000e-02        0.645887      0.748451   \n",
       "3    W2V          None   1.000000e-01        0.624608      0.781274   \n",
       "17   W2V    [0.5, 0.5]   1.000000e-09        0.622637      0.782630   \n",
       "16   W2V    [0.5, 0.5]   1.000000e-10        0.622637      0.782630   \n",
       "18   W2V    [0.5, 0.5]   1.000000e-02        0.619427      0.787858   \n",
       "4    W2V          None   2.500000e-01        0.602055      0.807417   \n",
       "9    W2V  [0.25, 0.75]   1.000000e-09        0.602805      0.806352   \n",
       "8    W2V  [0.25, 0.75]   1.000000e-10        0.602805      0.806352   \n",
       "10   W2V  [0.25, 0.75]   1.000000e-02        0.598357      0.810515   \n",
       "19   W2V    [0.5, 0.5]   1.000000e-01        0.591886      0.818455   \n",
       "5    W2V          None   5.000000e-01        0.583671      0.822909   \n",
       "6    W2V          None   7.500000e-01        0.577949      0.826201   \n",
       "7    W2V          None   1.000000e+00        0.578944      0.823683   \n",
       "11   W2V  [0.25, 0.75]   1.000000e-01        0.567519      0.843242   \n",
       "20   W2V    [0.5, 0.5]   2.500000e-01        0.560106      0.848567   \n",
       "12   W2V  [0.25, 0.75]   2.500000e-01        0.529582      0.873451   \n",
       "21   W2V    [0.5, 0.5]   5.000000e-01        0.528501      0.874419   \n",
       "22   W2V    [0.5, 0.5]   7.500000e-01        0.510326      0.887684   \n",
       "23   W2V    [0.5, 0.5]   1.000000e+00        0.498116      0.895043   \n",
       "13   W2V  [0.25, 0.75]   5.000000e-01        0.490442      0.900368   \n",
       "14   W2V  [0.25, 0.75]   7.500000e-01        0.466127      0.918474   \n",
       "15   W2V  [0.25, 0.75]   1.000000e+00        0.447289      0.931352   \n",
       "\n",
       "    train_precision  train_f1  test_accuracy  test_recall  test_precision  \\\n",
       "0          0.304945  0.432585       0.636253     0.748019        0.296882   \n",
       "1          0.304945  0.432585       0.636253     0.748019        0.296882   \n",
       "2          0.303924  0.432302       0.633078     0.753000        0.295618   \n",
       "3          0.295222  0.428518       0.613910     0.783337        0.288574   \n",
       "17         0.294216  0.427661       0.609067     0.784695        0.285950   \n",
       "16         0.294216  0.427661       0.609067     0.784695        0.285950   \n",
       "18         0.293067  0.427218       0.606056     0.790355        0.285096   \n",
       "4          0.285925  0.422303       0.591161     0.807788        0.279514   \n",
       "9          0.286186  0.422441       0.589126     0.804845        0.277973   \n",
       "8          0.286186  0.422441       0.589126     0.804845        0.277973   \n",
       "10         0.284331  0.420981       0.584934     0.810052        0.276550   \n",
       "19         0.281992  0.419462       0.578870     0.820240        0.274949   \n",
       "5          0.278300  0.415935       0.574149     0.823183        0.272993   \n",
       "6          0.275836  0.413591       0.569998     0.827485        0.271565   \n",
       "7          0.275968  0.413423       0.570894     0.822730        0.271295   \n",
       "11         0.273138  0.412622       0.555307     0.846049        0.267234   \n",
       "20         0.270327  0.410031       0.548999     0.850351        0.264936   \n",
       "12         0.260091  0.400826       0.520389     0.880915        0.256832   \n",
       "21         0.259765  0.400541       0.520674     0.875028        0.256113   \n",
       "22         0.254088  0.395087       0.502605     0.889065        0.250782   \n",
       "23         0.250284  0.391181       0.491779     0.899026        0.247986   \n",
       "13         0.248079  0.388982       0.482541     0.906724        0.245585   \n",
       "14         0.241669  0.382654       0.457431     0.922345        0.238762   \n",
       "15         0.236933  0.377764       0.440217     0.933892        0.234535   \n",
       "\n",
       "     test_f1  test_recall_1  \n",
       "0   0.425061       0.748019  \n",
       "1   0.425061       0.748019  \n",
       "2   0.424560       0.753000  \n",
       "3   0.421771       0.783337  \n",
       "17  0.419156       0.784695  \n",
       "16  0.419156       0.784695  \n",
       "18  0.419037       0.790355  \n",
       "4   0.415318       0.807788  \n",
       "9   0.413228       0.804845  \n",
       "8   0.413228       0.804845  \n",
       "10  0.412331       0.810052  \n",
       "19  0.411845       0.820240  \n",
       "5   0.410014       0.823183  \n",
       "6   0.408928       0.827485  \n",
       "7   0.408040       0.822730  \n",
       "11  0.406174       0.846049  \n",
       "20  0.404001       0.850351  \n",
       "12  0.397710       0.880915  \n",
       "21  0.396248       0.875028  \n",
       "22  0.391213       0.889065  \n",
       "23  0.388742       0.899026  \n",
       "13  0.386490       0.906724  \n",
       "14  0.379330       0.922345  \n",
       "15  0.374915       0.933892  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=['test_f1'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f55885-9f81-47ec-bc13-088e004adfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.447289</td>\n",
       "      <td>0.931352</td>\n",
       "      <td>0.236933</td>\n",
       "      <td>0.377764</td>\n",
       "      <td>0.440217</td>\n",
       "      <td>0.933892</td>\n",
       "      <td>0.234535</td>\n",
       "      <td>0.374915</td>\n",
       "      <td>0.933892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.466127</td>\n",
       "      <td>0.918474</td>\n",
       "      <td>0.241669</td>\n",
       "      <td>0.382654</td>\n",
       "      <td>0.457431</td>\n",
       "      <td>0.922345</td>\n",
       "      <td>0.238762</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.922345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.490442</td>\n",
       "      <td>0.900368</td>\n",
       "      <td>0.248079</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.482541</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.245585</td>\n",
       "      <td>0.386490</td>\n",
       "      <td>0.906724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.498116</td>\n",
       "      <td>0.895043</td>\n",
       "      <td>0.250284</td>\n",
       "      <td>0.391181</td>\n",
       "      <td>0.491779</td>\n",
       "      <td>0.899026</td>\n",
       "      <td>0.247986</td>\n",
       "      <td>0.388742</td>\n",
       "      <td>0.899026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.510326</td>\n",
       "      <td>0.887684</td>\n",
       "      <td>0.254088</td>\n",
       "      <td>0.395087</td>\n",
       "      <td>0.502605</td>\n",
       "      <td>0.889065</td>\n",
       "      <td>0.250782</td>\n",
       "      <td>0.391213</td>\n",
       "      <td>0.889065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.529582</td>\n",
       "      <td>0.873451</td>\n",
       "      <td>0.260091</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.520389</td>\n",
       "      <td>0.880915</td>\n",
       "      <td>0.256832</td>\n",
       "      <td>0.397710</td>\n",
       "      <td>0.880915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.528501</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>0.259765</td>\n",
       "      <td>0.400541</td>\n",
       "      <td>0.520674</td>\n",
       "      <td>0.875028</td>\n",
       "      <td>0.256113</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>0.875028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.560106</td>\n",
       "      <td>0.848567</td>\n",
       "      <td>0.270327</td>\n",
       "      <td>0.410031</td>\n",
       "      <td>0.548999</td>\n",
       "      <td>0.850351</td>\n",
       "      <td>0.264936</td>\n",
       "      <td>0.404001</td>\n",
       "      <td>0.850351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.567519</td>\n",
       "      <td>0.843242</td>\n",
       "      <td>0.273138</td>\n",
       "      <td>0.412622</td>\n",
       "      <td>0.555307</td>\n",
       "      <td>0.846049</td>\n",
       "      <td>0.267234</td>\n",
       "      <td>0.406174</td>\n",
       "      <td>0.846049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.577949</td>\n",
       "      <td>0.826201</td>\n",
       "      <td>0.275836</td>\n",
       "      <td>0.413591</td>\n",
       "      <td>0.569998</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>0.271565</td>\n",
       "      <td>0.408928</td>\n",
       "      <td>0.827485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.583671</td>\n",
       "      <td>0.822909</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.415935</td>\n",
       "      <td>0.574149</td>\n",
       "      <td>0.823183</td>\n",
       "      <td>0.272993</td>\n",
       "      <td>0.410014</td>\n",
       "      <td>0.823183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.578944</td>\n",
       "      <td>0.823683</td>\n",
       "      <td>0.275968</td>\n",
       "      <td>0.413423</td>\n",
       "      <td>0.570894</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.271295</td>\n",
       "      <td>0.408040</td>\n",
       "      <td>0.822730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.591886</td>\n",
       "      <td>0.818455</td>\n",
       "      <td>0.281992</td>\n",
       "      <td>0.419462</td>\n",
       "      <td>0.578870</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.274949</td>\n",
       "      <td>0.411845</td>\n",
       "      <td>0.820240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.598357</td>\n",
       "      <td>0.810515</td>\n",
       "      <td>0.284331</td>\n",
       "      <td>0.420981</td>\n",
       "      <td>0.584934</td>\n",
       "      <td>0.810052</td>\n",
       "      <td>0.276550</td>\n",
       "      <td>0.412331</td>\n",
       "      <td>0.810052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.602055</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.285925</td>\n",
       "      <td>0.422303</td>\n",
       "      <td>0.591161</td>\n",
       "      <td>0.807788</td>\n",
       "      <td>0.279514</td>\n",
       "      <td>0.415318</td>\n",
       "      <td>0.807788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.602805</td>\n",
       "      <td>0.806352</td>\n",
       "      <td>0.286186</td>\n",
       "      <td>0.422441</td>\n",
       "      <td>0.589126</td>\n",
       "      <td>0.804845</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.602805</td>\n",
       "      <td>0.806352</td>\n",
       "      <td>0.286186</td>\n",
       "      <td>0.422441</td>\n",
       "      <td>0.589126</td>\n",
       "      <td>0.804845</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.619427</td>\n",
       "      <td>0.787858</td>\n",
       "      <td>0.293067</td>\n",
       "      <td>0.427218</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>0.790355</td>\n",
       "      <td>0.285096</td>\n",
       "      <td>0.419037</td>\n",
       "      <td>0.790355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.622637</td>\n",
       "      <td>0.782630</td>\n",
       "      <td>0.294216</td>\n",
       "      <td>0.427661</td>\n",
       "      <td>0.609067</td>\n",
       "      <td>0.784695</td>\n",
       "      <td>0.285950</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>0.784695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>W2V</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.622637</td>\n",
       "      <td>0.782630</td>\n",
       "      <td>0.294216</td>\n",
       "      <td>0.427661</td>\n",
       "      <td>0.609067</td>\n",
       "      <td>0.784695</td>\n",
       "      <td>0.285950</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>0.784695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.624608</td>\n",
       "      <td>0.781274</td>\n",
       "      <td>0.295222</td>\n",
       "      <td>0.428518</td>\n",
       "      <td>0.613910</td>\n",
       "      <td>0.783337</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.421771</td>\n",
       "      <td>0.783337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.645887</td>\n",
       "      <td>0.748451</td>\n",
       "      <td>0.303924</td>\n",
       "      <td>0.432302</td>\n",
       "      <td>0.633078</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.295618</td>\n",
       "      <td>0.424560</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.743997</td>\n",
       "      <td>0.304945</td>\n",
       "      <td>0.432585</td>\n",
       "      <td>0.636253</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>0.425061</td>\n",
       "      <td>0.748019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2V</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.743997</td>\n",
       "      <td>0.304945</td>\n",
       "      <td>0.432585</td>\n",
       "      <td>0.636253</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>0.425061</td>\n",
       "      <td>0.748019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        priors  var_smoothing  train_accuracy  train_recall  \\\n",
       "15   W2V  [0.25, 0.75]   1.000000e+00        0.447289      0.931352   \n",
       "14   W2V  [0.25, 0.75]   7.500000e-01        0.466127      0.918474   \n",
       "13   W2V  [0.25, 0.75]   5.000000e-01        0.490442      0.900368   \n",
       "23   W2V    [0.5, 0.5]   1.000000e+00        0.498116      0.895043   \n",
       "22   W2V    [0.5, 0.5]   7.500000e-01        0.510326      0.887684   \n",
       "12   W2V  [0.25, 0.75]   2.500000e-01        0.529582      0.873451   \n",
       "21   W2V    [0.5, 0.5]   5.000000e-01        0.528501      0.874419   \n",
       "20   W2V    [0.5, 0.5]   2.500000e-01        0.560106      0.848567   \n",
       "11   W2V  [0.25, 0.75]   1.000000e-01        0.567519      0.843242   \n",
       "6    W2V          None   7.500000e-01        0.577949      0.826201   \n",
       "5    W2V          None   5.000000e-01        0.583671      0.822909   \n",
       "7    W2V          None   1.000000e+00        0.578944      0.823683   \n",
       "19   W2V    [0.5, 0.5]   1.000000e-01        0.591886      0.818455   \n",
       "10   W2V  [0.25, 0.75]   1.000000e-02        0.598357      0.810515   \n",
       "4    W2V          None   2.500000e-01        0.602055      0.807417   \n",
       "8    W2V  [0.25, 0.75]   1.000000e-10        0.602805      0.806352   \n",
       "9    W2V  [0.25, 0.75]   1.000000e-09        0.602805      0.806352   \n",
       "18   W2V    [0.5, 0.5]   1.000000e-02        0.619427      0.787858   \n",
       "16   W2V    [0.5, 0.5]   1.000000e-10        0.622637      0.782630   \n",
       "17   W2V    [0.5, 0.5]   1.000000e-09        0.622637      0.782630   \n",
       "3    W2V          None   1.000000e-01        0.624608      0.781274   \n",
       "2    W2V          None   1.000000e-02        0.645887      0.748451   \n",
       "1    W2V          None   1.000000e-09        0.648399      0.743997   \n",
       "0    W2V          None   1.000000e-10        0.648399      0.743997   \n",
       "\n",
       "    train_precision  train_f1  test_accuracy  test_recall  test_precision  \\\n",
       "15         0.236933  0.377764       0.440217     0.933892        0.234535   \n",
       "14         0.241669  0.382654       0.457431     0.922345        0.238762   \n",
       "13         0.248079  0.388982       0.482541     0.906724        0.245585   \n",
       "23         0.250284  0.391181       0.491779     0.899026        0.247986   \n",
       "22         0.254088  0.395087       0.502605     0.889065        0.250782   \n",
       "12         0.260091  0.400826       0.520389     0.880915        0.256832   \n",
       "21         0.259765  0.400541       0.520674     0.875028        0.256113   \n",
       "20         0.270327  0.410031       0.548999     0.850351        0.264936   \n",
       "11         0.273138  0.412622       0.555307     0.846049        0.267234   \n",
       "6          0.275836  0.413591       0.569998     0.827485        0.271565   \n",
       "5          0.278300  0.415935       0.574149     0.823183        0.272993   \n",
       "7          0.275968  0.413423       0.570894     0.822730        0.271295   \n",
       "19         0.281992  0.419462       0.578870     0.820240        0.274949   \n",
       "10         0.284331  0.420981       0.584934     0.810052        0.276550   \n",
       "4          0.285925  0.422303       0.591161     0.807788        0.279514   \n",
       "8          0.286186  0.422441       0.589126     0.804845        0.277973   \n",
       "9          0.286186  0.422441       0.589126     0.804845        0.277973   \n",
       "18         0.293067  0.427218       0.606056     0.790355        0.285096   \n",
       "16         0.294216  0.427661       0.609067     0.784695        0.285950   \n",
       "17         0.294216  0.427661       0.609067     0.784695        0.285950   \n",
       "3          0.295222  0.428518       0.613910     0.783337        0.288574   \n",
       "2          0.303924  0.432302       0.633078     0.753000        0.295618   \n",
       "1          0.304945  0.432585       0.636253     0.748019        0.296882   \n",
       "0          0.304945  0.432585       0.636253     0.748019        0.296882   \n",
       "\n",
       "     test_f1  test_recall_1  \n",
       "15  0.374915       0.933892  \n",
       "14  0.379330       0.922345  \n",
       "13  0.386490       0.906724  \n",
       "23  0.388742       0.899026  \n",
       "22  0.391213       0.889065  \n",
       "12  0.397710       0.880915  \n",
       "21  0.396248       0.875028  \n",
       "20  0.404001       0.850351  \n",
       "11  0.406174       0.846049  \n",
       "6   0.408928       0.827485  \n",
       "5   0.410014       0.823183  \n",
       "7   0.408040       0.822730  \n",
       "19  0.411845       0.820240  \n",
       "10  0.412331       0.810052  \n",
       "4   0.415318       0.807788  \n",
       "8   0.413228       0.804845  \n",
       "9   0.413228       0.804845  \n",
       "18  0.419037       0.790355  \n",
       "16  0.419156       0.784695  \n",
       "17  0.419156       0.784695  \n",
       "3   0.421771       0.783337  \n",
       "2   0.424560       0.753000  \n",
       "1   0.425061       0.748019  \n",
       "0   0.425061       0.748019  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=['test_recall_1'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c569426-3d0e-4868-8f18-23e5af9c469e",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce4c32f3-8390-4366-8204-7f8b81374519",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_name_test = (('../../../data/mixed_dataset/test_cleaned.csv'))\n",
    "df_test = pd.read_csv(filepath_name_test, encoding ='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476b160f-e225-4ce9-837e-2cc371200cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['tweet_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10ef6df7-5281-4d8b-bd88-c284a197cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('saved_models/vectorizer/vectorizer_nb_w2v.pkl','rb') as f:\n",
    " #   vectorizer_w2v_saved = pickle.load(f)\n",
    "\n",
    "vectorizer_w2v_saved = joblib.load('saved_models/vectorizer/vectorizer_w2v.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b1ff153-ba56-4aa3-bd96-756d48fd36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokenized = df_test['tweet_cleaned'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24751160-1e91-4984-8b64-240feb02c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_vector(tokenized_tweet, vector_size):\n",
    "        vec = np.zeros(vector_size).reshape((1, vector_size))\n",
    "        count = 0\n",
    "        for word in tokenized_tweet:\n",
    "            try:\n",
    "                vec += vectorizer_w2v_saved.wv[word].reshape((1, vector_size))\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dff562f-9199-4313-bf1d-25f8a2bd4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8af584c9-1941-4f79-8c04-5d86c9cd85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_w2v = np.zeros((len(x_test_tokenized), 300))\n",
    "for i in range(len(x_test_tokenized)):\n",
    "    X_test_w2v[i, :] = w2v_vector(x_test_tokenized.iloc[i], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86ae7f92-40bc-4441-ba8d-fc579d9e303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test, X_empty, y_test, y_empty, vectorizer_w2v  = vectorize_w2v(df=df_test, text_column='tweet_cleaned', \n",
    " #                                                                                label_column=\"label\", test_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbb932ec-2c3c-4ee3-9dd8-19f5dea69b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cbb09be-5868-46cc-af8e-cd0a32821e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32466, 300)\n",
      "(32466,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_test_w2v.shape)\n",
    "print(y_test.shape)\n",
    "print(type(X_test_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59f666-bf57-4b6d-97d6-4128c2b5567d",
   "metadata": {},
   "source": [
    "# Test bestes F1-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5683cbf4-74d9-46c8-8869-997aa41a9ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Model 0\n",
    "#with open('saved_models/w2v/model_nb_w2v_0.pkl','rb') as f:\n",
    " #   clf_w2v_0 = pickle.load(f)\n",
    "clf_w2v_0 = joblib.load('saved_models/w2v/model_nb_w2v_0.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f908075c-c08b-4ef2-894e-9c03738026a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_w2v_0.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2d02562-fcf5-4dfa-8bc2-41e79fe15bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5861824678124807\n",
      "F1 Score: 0.4465955431066442\n",
      "Recall: 0.7926597455768387\n",
      "Precision: 0.31087280651450855\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "       0      1\n",
      "0  13610  12017\n",
      "1   1418   5421\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67     25627\n",
      "           1       0.31      0.79      0.45      6839\n",
      "\n",
      "    accuracy                           0.59     32466\n",
      "   macro avg       0.61      0.66      0.56     32466\n",
      "weighted avg       0.78      0.59      0.62     32466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54c7a81b-fdfc-4b4e-b088-2a46fcf8d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Confusionmatrix\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25832331-3f18-480d-b21e-53d6e5baa44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13610</td>\n",
       "      <td>12017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1418</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  13610  12017\n",
       "1   1418   5421"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6777603a-c4ca-4425-af9c-d7ca3fb53bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_df.to_csv(\"eval_data/nb_w2v_confusion_matrix.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06623d5c-6b2e-43d0-b809-868c12d44e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Classificationreport\n",
    "classification_report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da0b82a1-30cf-4939-915a-8a31d38d02e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905643</td>\n",
       "      <td>0.531081</td>\n",
       "      <td>0.669536</td>\n",
       "      <td>25627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.310873</td>\n",
       "      <td>0.792660</td>\n",
       "      <td>0.446596</td>\n",
       "      <td>6839.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.586182</td>\n",
       "      <td>0.586182</td>\n",
       "      <td>0.586182</td>\n",
       "      <td>0.586182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.608258</td>\n",
       "      <td>0.661870</td>\n",
       "      <td>0.558066</td>\n",
       "      <td>32466.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.780354</td>\n",
       "      <td>0.586182</td>\n",
       "      <td>0.622574</td>\n",
       "      <td>32466.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.905643  0.531081  0.669536  25627.000000\n",
       "1              0.310873  0.792660  0.446596   6839.000000\n",
       "accuracy       0.586182  0.586182  0.586182      0.586182\n",
       "macro avg      0.608258  0.661870  0.558066  32466.000000\n",
       "weighted avg   0.780354  0.586182  0.622574  32466.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ee5395a-d87f-4c71-8a2f-cf5207456dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_df.to_csv(\"eval_data/nb_w2v_classification_report.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
