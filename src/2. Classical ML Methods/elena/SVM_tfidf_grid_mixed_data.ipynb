{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using randomizedSearch instead of gridSearch due to performance issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "# # Daten laden\n",
    "# filepath_name = (\"..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\train_cleaned.csv\")\n",
    "# df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')\n",
    "# df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# # TF-IDF Vektorisierung\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "# y = df_cleaned[\"label\"]\n",
    "\n",
    "# # Train-Test-Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Vektorisierungsmodell speichern\n",
    "# with open(\"svm_tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(vectorizer, file)\n",
    "\n",
    "# # Parameterraum definieren\n",
    "# param_dist = {\n",
    "#     'kernel': ['sigmoid'],\n",
    "#     'C': uniform(0.01, 1),\n",
    "#     'gamma': uniform(0.01, 0.1),\n",
    "#     'random_state': [40, 42],\n",
    "#     'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "# }\n",
    "\n",
    "# # SVM erstellen\n",
    "# svm = SVC()\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=svm, \n",
    "#     param_distributions=param_dist, \n",
    "#     n_iter=50,\n",
    "#     scoring='f1', \n",
    "#     cv=3,\n",
    "#     verbose=2, \n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # SVM Training\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# cv_results = random_search.cv_results_\n",
    "# params = cv_results['params']\n",
    "\n",
    "# model_results = []\n",
    "\n",
    "# for idx, param in enumerate(params):\n",
    "#     model = SVC(**param)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     y_test_pred = model.predict(X_test)\n",
    "#     f1 = f1_score(y_test, y_test_pred)\n",
    "#     recall = recall_score(y_test, y_test_pred)\n",
    "    \n",
    "#     model_results.append({\n",
    "#         'index': idx,\n",
    "#         'params': param,\n",
    "#         'f1_score': f1,\n",
    "#         'recall': recall,\n",
    "#         'model': model\n",
    "#     })\n",
    "\n",
    "# # Nach Metrik sortieren\n",
    "# top_3_f1 = sorted(model_results, key=lambda x: x['f1_score'], reverse=True)[:3]\n",
    "# top_3_recall = sorted(model_results, key=lambda x: x['recall'], reverse=True)[:3]\n",
    "\n",
    "# # Modelle und Konfigurationen speichern\n",
    "# model_configs = []\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "#     filename = f\"svm_tfidf_sigmoid_top_f1_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'F1-Score',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "#     filename = f\"svm_tfidf_sigmoid_top_recall_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'Recall',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# config_df = pd.DataFrame(model_configs)\n",
    "# config_df.to_csv(\"top_models_config.csv\", index=False)\n",
    "\n",
    "# print(\"Top 6 Modelle gespeichert!\")\n",
    "# print(config_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "df_cleaned = pd.read_csv(\"data/mixed_dataset/train_cleaned.csv\")\n",
    "df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# TF-IDF Vektorisierung\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "y = df_cleaned[\"label\"]\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vektorisierungsmodell speichern\n",
    "with open(\"svm_tfidf_sigmoid_vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "# Parameterraum definieren\n",
    "param_dist = {\n",
    "    'kernel': ['sigmoid'],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'random_state': [40, 42],\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "# SVM erstellen\n",
    "svm = SVC()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SVM Training\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Ergebnisse sammeln\n",
    "results_list = []\n",
    "model_results = []\n",
    "\n",
    "for idx, params in enumerate(random_search.cv_results_['params']):\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "    test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    result_dict = {\n",
    "        'vectorization': 'tfidf',\n",
    "        'kernel': params['kernel'],\n",
    "        'degree': 'X',\n",
    "        'C': params['C'],\n",
    "        'gamma': params['gamma'],\n",
    "        'random_state': params['random_state'],\n",
    "        'class_weight': params['class_weight'],\n",
    "\n",
    "        # Train metrics\n",
    "        'train_precision_0': train_report['0']['precision'],\n",
    "        'train_recall_0': train_report['0']['recall'],\n",
    "        'train_f1_0': train_report['0']['f1-score'],\n",
    "        'train_support_0': train_report['0']['support'],\n",
    "        'train_precision_1': train_report['1']['precision'],\n",
    "        'train_recall_1': train_report['1']['recall'],\n",
    "        'train_f1_1': train_report['1']['f1-score'],\n",
    "        'train_support_1': train_report['1']['support'],\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'train_precision': train_precision,\n",
    "        'train_f1': train_f1,\n",
    "\n",
    "        # Test metrics\n",
    "        'test_precision_0': test_report['0']['precision'],\n",
    "        'test_recall_0': test_report['0']['recall'],\n",
    "        'test_f1_0': test_report['0']['f1-score'],\n",
    "        'test_support_0': test_report['0']['support'],\n",
    "        'test_precision_1': test_report['1']['precision'],\n",
    "        'test_recall_1': test_report['1']['recall'],\n",
    "        'test_f1_1': test_report['1']['f1-score'],\n",
    "        'test_support_1': test_report['1']['support'],\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_recall': test_recall,\n",
    "        'test_precision': test_precision,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "    # Modell speichern\n",
    "    filename = f\"svm_tfidf_sigmoid_model_{idx}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    model_results.append({\n",
    "        'index': idx,\n",
    "        'params': params,\n",
    "        'f1_score': test_f1,\n",
    "        'recall': test_recall,\n",
    "        'model': model,\n",
    "        'filename': filename\n",
    "    })\n",
    "\n",
    "# Modelle sortieren\n",
    "top_3_f1 = results_df.nlargest(3, 'test_f1')\n",
    "top_3_recall = results_df.nlargest(3, 'test_recall')\n",
    "\n",
    "# Speicherpfade f端r Modelle\n",
    "for rank, row in enumerate(top_3_f1.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_sigmoid_top_f1_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "for rank, row in enumerate(top_3_recall.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_sigmoid_top_recall_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "# Modelle und Konfigurationen speichern\n",
    "model_configs = []\n",
    "\n",
    "for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'F1-Score',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'Recall',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "# Speichern der Top-Modelle als CSV\n",
    "config_df = pd.DataFrame(model_configs)\n",
    "config_df.to_csv(\"svm_tfidf_sigmoid_top_models_config.csv\", index=False)\n",
    "\n",
    "# Speichern der gesamten Ergebnisse als CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"svm_tfidf_sigmoid_results.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '# Daten laden\n",
    "# filepath_name = (\"..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\train_cleaned.csv\")\n",
    "# df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')\n",
    "# df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# # TF-IDF Vektorisierung\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "# y = df_cleaned[\"label\"]\n",
    "\n",
    "# # Train-Test-Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Vektorisierungsmodell speichern\n",
    "# with open(\"svm_tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(vectorizer, file)\n",
    "\n",
    "# # Parameterraum definieren\n",
    "# param_dist = {\n",
    "#     'kernel': ['linear'],\n",
    "#     'C': uniform(0.01, 1),\n",
    "#     'gamma': uniform(0.01, 0.1),\n",
    "#     'random_state': [40, 42],\n",
    "#     'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "# }\n",
    "\n",
    "# # SVM erstellen\n",
    "# svm = SVC()\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=svm, \n",
    "#     param_distributions=param_dist, \n",
    "#     n_iter=50,\n",
    "#     scoring='f1', \n",
    "#     cv=3,\n",
    "#     verbose=2, \n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # SVM Training\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# cv_results = random_search.cv_results_\n",
    "# params = cv_results['params']\n",
    "\n",
    "# model_results = []\n",
    "\n",
    "# for idx, param in enumerate(params):\n",
    "#     model = SVC(**param)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     y_test_pred = model.predict(X_test)\n",
    "#     f1 = f1_score(y_test, y_test_pred)\n",
    "#     recall = recall_score(y_test, y_test_pred)\n",
    "    \n",
    "#     model_results.append({\n",
    "#         'index': idx,\n",
    "#         'params': param,\n",
    "#         'f1_score': f1,\n",
    "#         'recall': recall,\n",
    "#         'model': model\n",
    "#     })\n",
    "\n",
    "# # Nach Metrik sortieren\n",
    "# top_3_f1 = sorted(model_results, key=lambda x: x['f1_score'], reverse=True)[:3]\n",
    "# top_3_recall = sorted(model_results, key=lambda x: x['recall'], reverse=True)[:3]\n",
    "\n",
    "# # Modelle und Konfigurationen speichern\n",
    "# model_configs = []\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "#     filename = f\"svm_tfidf_linear_top_f1_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'F1-Score',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "#     filename = f\"svm_tfidf_linear_top_recall_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'Recall',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# config_df = pd.DataFrame(model_configs)\n",
    "# config_df.to_csv(\"top_models_config.csv\", index=False)\n",
    "\n",
    "# print(\"Top 6 Modelle gespeichert!\")\n",
    "# print(config_df)\n",
    "# '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "df_cleaned = pd.read_csv(\"data/mixed_dataset/train_cleaned.csv\")\n",
    "df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# TF-IDF Vektorisierung\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "y = df_cleaned[\"label\"]\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vektorisierungsmodell speichern\n",
    "with open(\"svm_tfidf_linear_vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "# Parameterraum definieren\n",
    "param_dist = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'random_state': [40, 42],\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "# SVM erstellen\n",
    "svm = SVC()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SVM Training\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Ergebnisse sammeln\n",
    "results_list = []\n",
    "model_results = []\n",
    "\n",
    "for idx, params in enumerate(random_search.cv_results_['params']):\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "    test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    result_dict = {\n",
    "        'vectorization': 'tfidf',\n",
    "        'kernel': params['kernel'],\n",
    "        'degree': 'X',\n",
    "        'C': params['C'],\n",
    "        'gamma': params['gamma'],\n",
    "        'random_state': params['random_state'],\n",
    "        'class_weight': params['class_weight'],\n",
    "\n",
    "        # Train metrics\n",
    "        'train_precision_0': train_report['0']['precision'],\n",
    "        'train_recall_0': train_report['0']['recall'],\n",
    "        'train_f1_0': train_report['0']['f1-score'],\n",
    "        'train_support_0': train_report['0']['support'],\n",
    "        'train_precision_1': train_report['1']['precision'],\n",
    "        'train_recall_1': train_report['1']['recall'],\n",
    "        'train_f1_1': train_report['1']['f1-score'],\n",
    "        'train_support_1': train_report['1']['support'],\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'train_precision': train_precision,\n",
    "        'train_f1': train_f1,\n",
    "\n",
    "        # Test metrics\n",
    "        'test_precision_0': test_report['0']['precision'],\n",
    "        'test_recall_0': test_report['0']['recall'],\n",
    "        'test_f1_0': test_report['0']['f1-score'],\n",
    "        'test_support_0': test_report['0']['support'],\n",
    "        'test_precision_1': test_report['1']['precision'],\n",
    "        'test_recall_1': test_report['1']['recall'],\n",
    "        'test_f1_1': test_report['1']['f1-score'],\n",
    "        'test_support_1': test_report['1']['support'],\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_recall': test_recall,\n",
    "        'test_precision': test_precision,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "    # Modell speichern\n",
    "    filename = f\"svm_tfidf_linear_model_{idx}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    model_results.append({\n",
    "        'index': idx,\n",
    "        'params': params,\n",
    "        'f1_score': test_f1,\n",
    "        'recall': test_recall,\n",
    "        'model': model,\n",
    "        'filename': filename\n",
    "    })\n",
    "\n",
    "# Modelle sortieren\n",
    "top_3_f1 = results_df.nlargest(3, 'test_f1')\n",
    "top_3_recall = results_df.nlargest(3, 'test_recall')\n",
    "\n",
    "# Speicherpfade f端r Modelle\n",
    "for rank, row in enumerate(top_3_f1.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_linear_top_f1_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "for rank, row in enumerate(top_3_recall.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_linear_top_recall_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "# Modelle und Konfigurationen speichern\n",
    "model_configs = []\n",
    "\n",
    "for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'F1-Score',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'Recall',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "# Speichern der Top-Modelle als CSV\n",
    "config_df = pd.DataFrame(model_configs)\n",
    "config_df.to_csv(\"svm_tfidf_linear_top_models_config.csv\", index=False)\n",
    "\n",
    "# Speichern der gesamten Ergebnisse als CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"svm_tfidf_linear_results.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Daten laden\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filepath_name \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmixed_dataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(filepath_name, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m df_cleaned\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# TF-IDF Vektorisierung\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# # Daten laden\n",
    "# filepath_name = (\"..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\train_cleaned.csv\")\n",
    "# df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')\n",
    "# df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# # TF-IDF Vektorisierung\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "# y = df_cleaned[\"label\"]\n",
    "\n",
    "# # Train-Test-Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Vektorisierungsmodell speichern\n",
    "# with open(\"svm_tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(vectorizer, file)\n",
    "\n",
    "# # Parameterraum definieren\n",
    "# param_dist = {\n",
    "#     'kernel': ['poly'],\n",
    "#     'degree': [3, 4, 5],\n",
    "#     'C': uniform(0.01, 1),\n",
    "#     'gamma': uniform(0.01, 0.1),\n",
    "#     'random_state': [40, 42],\n",
    "#     'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "# }\n",
    "\n",
    "# # SVM erstellen\n",
    "# svm = SVC()\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=svm, \n",
    "#     param_distributions=param_dist, \n",
    "#     n_iter=50,\n",
    "#     scoring='f1', \n",
    "#     cv=3,\n",
    "#     verbose=2, \n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # SVM Training\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# cv_results = random_search.cv_results_\n",
    "# params = cv_results['params']\n",
    "\n",
    "# model_results = []\n",
    "\n",
    "# for idx, param in enumerate(params):\n",
    "#     model = SVC(**param)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     y_test_pred = model.predict(X_test)\n",
    "#     f1 = f1_score(y_test, y_test_pred)\n",
    "#     recall = recall_score(y_test, y_test_pred)\n",
    "    \n",
    "#     model_results.append({\n",
    "#         'index': idx,\n",
    "#         'params': param,\n",
    "#         'f1_score': f1,\n",
    "#         'recall': recall,\n",
    "#         'model': model\n",
    "#     })\n",
    "\n",
    "# # Nach Metrik sortieren\n",
    "# top_3_f1 = sorted(model_results, key=lambda x: x['f1_score'], reverse=True)[:3]\n",
    "# top_3_recall = sorted(model_results, key=lambda x: x['recall'], reverse=True)[:3]\n",
    "\n",
    "# # Modelle und Konfigurationen speichern\n",
    "# model_configs = []\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "#     filename = f\"svm_top_f1_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'F1-Score',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "#     filename = f\"svm_tfidf_poly_top_recall_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'Recall',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# config_df = pd.DataFrame(model_configs)\n",
    "# config_df.to_csv(\"top_tfidf_poly_models_config.csv\", index=False)\n",
    "\n",
    "# print(\"Top 6 Modelle gespeichert!\")\n",
    "# print(config_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "df_cleaned = pd.read_csv(\"data/mixed_dataset/train_cleaned.csv\")\n",
    "df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# TF-IDF Vektorisierung\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "y = df_cleaned[\"label\"]\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vektorisierungsmodell speichern\n",
    "with open(\"svm_tfidf_poly_vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "# Parameterraum definieren\n",
    "param_dist = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [3, 4, 5],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'random_state': [40, 42],\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "# SVM erstellen\n",
    "svm = SVC()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SVM Training\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Ergebnisse sammeln\n",
    "results_list = []\n",
    "model_results = []\n",
    "\n",
    "for idx, params in enumerate(random_search.cv_results_['params']):\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "    test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    result_dict = {\n",
    "        'vectorization': 'tfidf',\n",
    "        'kernel': params['kernel'],\n",
    "        'degree': 'X',\n",
    "        'C': params['C'],\n",
    "        'gamma': params['gamma'],\n",
    "        'random_state': params['random_state'],\n",
    "        'class_weight': params['class_weight'],\n",
    "\n",
    "        # Train metrics\n",
    "        'train_precision_0': train_report['0']['precision'],\n",
    "        'train_recall_0': train_report['0']['recall'],\n",
    "        'train_f1_0': train_report['0']['f1-score'],\n",
    "        'train_support_0': train_report['0']['support'],\n",
    "        'train_precision_1': train_report['1']['precision'],\n",
    "        'train_recall_1': train_report['1']['recall'],\n",
    "        'train_f1_1': train_report['1']['f1-score'],\n",
    "        'train_support_1': train_report['1']['support'],\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'train_precision': train_precision,\n",
    "        'train_f1': train_f1,\n",
    "\n",
    "        # Test metrics\n",
    "        'test_precision_0': test_report['0']['precision'],\n",
    "        'test_recall_0': test_report['0']['recall'],\n",
    "        'test_f1_0': test_report['0']['f1-score'],\n",
    "        'test_support_0': test_report['0']['support'],\n",
    "        'test_precision_1': test_report['1']['precision'],\n",
    "        'test_recall_1': test_report['1']['recall'],\n",
    "        'test_f1_1': test_report['1']['f1-score'],\n",
    "        'test_support_1': test_report['1']['support'],\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_recall': test_recall,\n",
    "        'test_precision': test_precision,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "    # Modell speichern\n",
    "    filename = f\"svm_tfidf_poly_model_{idx}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    model_results.append({\n",
    "        'index': idx,\n",
    "        'params': params,\n",
    "        'f1_score': test_f1,\n",
    "        'recall': test_recall,\n",
    "        'model': model,\n",
    "        'filename': filename\n",
    "    })\n",
    "\n",
    "# Modelle sortieren\n",
    "top_3_f1 = results_df.nlargest(3, 'test_f1')\n",
    "top_3_recall = results_df.nlargest(3, 'test_recall')\n",
    "\n",
    "# Speicherpfade f端r Modelle\n",
    "for rank, row in enumerate(top_3_f1.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_poly_top_f1_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "for rank, row in enumerate(top_3_recall.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_poly_top_recall_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "# Modelle und Konfigurationen speichern\n",
    "model_configs = []\n",
    "\n",
    "for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'F1-Score',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'Recall',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "# Speichern der Top-Modelle als CSV\n",
    "config_df = pd.DataFrame(model_configs)\n",
    "config_df.to_csv(\"svm_tfidf_poly_top_models_config.csv\", index=False)\n",
    "\n",
    "# Speichern der gesamten Ergebnisse als CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"svm_tfidf_poly_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Daten laden\n",
    "# filepath_name = (\"..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\train_cleaned.csv\")\n",
    "# df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')\n",
    "# df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# # TF-IDF Vektorisierung\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "# y = df_cleaned[\"label\"]\n",
    "\n",
    "# # Train-Test-Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Vektorisierungsmodell speichern\n",
    "# with open(\"svm_tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(vectorizer, file)\n",
    "\n",
    "# # Parameterraum definieren\n",
    "# param_dist = {\n",
    "#     'kernel': ['rbf'],\n",
    "#     'C': uniform(0.01, 1),\n",
    "#     'gamma': uniform(0.01, 0.1),\n",
    "#     'random_state': [40, 42],\n",
    "#     'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "# }\n",
    "\n",
    "# # SVM erstellen\n",
    "# svm = SVC()\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=svm, \n",
    "#     param_distributions=param_dist, \n",
    "#     n_iter=50,\n",
    "#     scoring='f1', \n",
    "#     cv=3,\n",
    "#     verbose=2, \n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # SVM Training\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# cv_results = random_search.cv_results_\n",
    "# params = cv_results['params']\n",
    "\n",
    "# model_results = []\n",
    "\n",
    "# for idx, param in enumerate(params):\n",
    "#     model = SVC(**param)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     y_test_pred = model.predict(X_test)\n",
    "#     f1 = f1_score(y_test, y_test_pred)\n",
    "#     recall = recall_score(y_test, y_test_pred)\n",
    "    \n",
    "#     model_results.append({\n",
    "#         'index': idx,\n",
    "#         'params': param,\n",
    "#         'f1_score': f1,\n",
    "#         'recall': recall,\n",
    "#         'model': model\n",
    "#     })\n",
    "\n",
    "# # Nach Metrik sortieren\n",
    "# top_3_f1 = sorted(model_results, key=lambda x: x['f1_score'], reverse=True)[:3]\n",
    "# top_3_recall = sorted(model_results, key=lambda x: x['recall'], reverse=True)[:3]\n",
    "\n",
    "# # Modelle und Konfigurationen speichern\n",
    "# model_configs = []\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "#     filename = f\"svm_tfidf_rbf_top_f1_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'F1-Score',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "#     filename = f\"svm_tfidf_rbf_top_recall_{rank}.pkl\"\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         pickle.dump(model_info['model'], file)\n",
    "    \n",
    "#     model_configs.append({\n",
    "#         'Rank': rank,\n",
    "#         'Metric': 'Recall',\n",
    "#         'Model Filename': filename,\n",
    "#         'F1 Score': model_info['f1_score'],\n",
    "#         'Recall': model_info['recall'],\n",
    "#         'Kernel': model_info['params']['kernel'],\n",
    "#         'C': model_info['params']['C'],\n",
    "#         'Gamma': model_info['params']['gamma'],\n",
    "#         'Random State': model_info['params']['random_state'],\n",
    "#         'Class Weight': model_info['params']['class_weight']\n",
    "#     })\n",
    "\n",
    "# config_df = pd.DataFrame(model_configs)\n",
    "# config_df.to_csv(\"top_models_config.csv\", index=False)\n",
    "\n",
    "# print(\"Top 6 Modelle gespeichert!\")\n",
    "# print(config_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "df_cleaned = pd.read_csv(\"data/mixed_dataset/train_cleaned.csv\")\n",
    "df_cleaned = df_cleaned.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# TF-IDF Vektorisierung\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "y = df_cleaned[\"label\"]\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vektorisierungsmodell speichern\n",
    "with open(\"svm_tfidf_rbf_vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "# Parameterraum definieren\n",
    "param_dist = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'random_state': [40, 42],\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "# SVM erstellen\n",
    "svm = SVC()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SVM Training\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Ergebnisse sammeln\n",
    "results_list = []\n",
    "model_results = []\n",
    "\n",
    "for idx, params in enumerate(random_search.cv_results_['params']):\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "    test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    result_dict = {\n",
    "        'vectorization': 'tfidf',\n",
    "        'kernel': params['kernel'],\n",
    "        'degree': 'X',\n",
    "        'C': params['C'],\n",
    "        'gamma': params['gamma'],\n",
    "        'random_state': params['random_state'],\n",
    "        'class_weight': params['class_weight'],\n",
    "\n",
    "        # Train metrics\n",
    "        'train_precision_0': train_report['0']['precision'],\n",
    "        'train_recall_0': train_report['0']['recall'],\n",
    "        'train_f1_0': train_report['0']['f1-score'],\n",
    "        'train_support_0': train_report['0']['support'],\n",
    "        'train_precision_1': train_report['1']['precision'],\n",
    "        'train_recall_1': train_report['1']['recall'],\n",
    "        'train_f1_1': train_report['1']['f1-score'],\n",
    "        'train_support_1': train_report['1']['support'],\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'train_precision': train_precision,\n",
    "        'train_f1': train_f1,\n",
    "\n",
    "        # Test metrics\n",
    "        'test_precision_0': test_report['0']['precision'],\n",
    "        'test_recall_0': test_report['0']['recall'],\n",
    "        'test_f1_0': test_report['0']['f1-score'],\n",
    "        'test_support_0': test_report['0']['support'],\n",
    "        'test_precision_1': test_report['1']['precision'],\n",
    "        'test_recall_1': test_report['1']['recall'],\n",
    "        'test_f1_1': test_report['1']['f1-score'],\n",
    "        'test_support_1': test_report['1']['support'],\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_recall': test_recall,\n",
    "        'test_precision': test_precision,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "    # Modell speichern\n",
    "    filename = f\"svm_tfidf_rbf_model_{idx}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    model_results.append({\n",
    "        'index': idx,\n",
    "        'params': params,\n",
    "        'f1_score': test_f1,\n",
    "        'recall': test_recall,\n",
    "        'model': model,\n",
    "        'filename': filename\n",
    "    })\n",
    "\n",
    "# Modelle sortieren\n",
    "top_3_f1 = results_df.nlargest(3, 'test_f1')\n",
    "top_3_recall = results_df.nlargest(3, 'test_recall')\n",
    "\n",
    "# Speicherpfade f端r Modelle\n",
    "for rank, row in enumerate(top_3_f1.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_rbf_top_f1_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "for rank, row in enumerate(top_3_recall.itertuples(), start=1):\n",
    "    filename = f\"svm_tfidf_rbf_top_recall_{rank}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(row.model, file)\n",
    "\n",
    "# Modelle und Konfigurationen speichern\n",
    "model_configs = []\n",
    "\n",
    "for rank, model_info in enumerate(top_3_f1, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'F1-Score',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "for rank, model_info in enumerate(top_3_recall, start=1):\n",
    "    model_configs.append({\n",
    "        'Rank': rank,\n",
    "        'Metric': 'Recall',\n",
    "        'Model Filename': model_info['filename'],\n",
    "        'F1 Score': model_info['f1_score'],\n",
    "        'Recall': model_info['recall'],\n",
    "        'Kernel': model_info['params']['kernel'],\n",
    "        'C': model_info['params']['C'],\n",
    "        'Gamma': model_info['params']['gamma'],\n",
    "        'Random State': model_info['params']['random_state'],\n",
    "        'Class Weight': model_info['params']['class_weight']\n",
    "    })\n",
    "\n",
    "# Speichern der Top-Modelle als CSV\n",
    "config_df = pd.DataFrame(model_configs)\n",
    "config_df.to_csv(\"svm_tfidf_rbf_top_models_config.csv\", index=False)\n",
    "\n",
    "# Speichern der gesamten Ergebnisse als CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"svm_tfidf_rbf_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
