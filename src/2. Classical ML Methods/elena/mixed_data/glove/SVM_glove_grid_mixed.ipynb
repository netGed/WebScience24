{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../../../functions/vectorize_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_name = (\"..\\\\..\\\\..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\train_cleaned.csv\")\n",
    "df_cleaned = pd.read_csv(filepath_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, glove_vectorizer = vectorize_glove(df=df_cleaned, text_column='tweet_cleaned', \n",
    "                                                                                 label_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"svm_glove_vectorizer_opt.joblib\", \"wb\") as file:\n",
    "    joblib.dump(glove_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 10328\n",
      "- Negative: 47004\n",
      "- Verh채ltnis: 4.551123160340821\n",
      "Test\n",
      "- Positive: 4417\n",
      "- Negative: 20155\n",
      "- Verh채ltnis: 4.563051845143763\n"
     ]
    }
   ],
   "source": [
    "positive = np.count_nonzero(y_train == 1)\n",
    "negative = np.count_nonzero(y_train == 0)\n",
    "print(\"Train\")\n",
    "print(\"- Positive:\", positive)\n",
    "print(\"- Negative:\", negative)\n",
    "print(\"- Verh채ltnis:\", negative / positive)\n",
    "\n",
    "positive = np.count_nonzero(y_test == 1)\n",
    "negative = np.count_nonzero(y_test == 0)\n",
    "print(\"Test\")\n",
    "print(\"- Positive:\", positive)\n",
    "print(\"- Negative:\", negative)\n",
    "print(\"- Verh채ltnis:\", negative / positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (57332, 100)\n",
      "y_train shape (57332,)\n",
      "X_test shape (24572, 100)\n",
      "y_test shape (24572,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (300,) (100,) (300,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df_test\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Use vectorizer to transform test data\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m X_test, _, y_test, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvectorize_glove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Evaluate model on test set\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\Desktop\\WS 24_25\\Projektpraktikum\\WebScience24\\src\\functions\\vectorize_functions.py:150\u001b[0m, in \u001b[0;36mvectorize_glove\u001b[1;34m(df, text_column, label_column, vector_size, test_size, random_state)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Step 6: Convert tokenized tweets to vectors\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m X_train_glv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([average_glove_vector(tweet, glv_model, vector_size) \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m X_train_tokenized])\n\u001b[0;32m    151\u001b[0m X_test_glv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([average_glove_vector(tweet, glv_model, vector_size) \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m X_test_tokenized])\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_train_glv, X_test_glv, y_train_glv, y_test_glv, glv_model\n",
      "File \u001b[1;32m~\\Desktop\\WS 24_25\\Projektpraktikum\\WebScience24\\src\\functions\\vectorize_functions.py:150\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Step 6: Convert tokenized tweets to vectors\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m X_train_glv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43maverage_glove_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglv_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m X_train_tokenized])\n\u001b[0;32m    151\u001b[0m X_test_glv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([average_glove_vector(tweet, glv_model, vector_size) \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m X_test_tokenized])\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_train_glv, X_test_glv, y_train_glv, y_test_glv, glv_model\n",
      "File \u001b[1;32m~\\Desktop\\WS 24_25\\Projektpraktikum\\WebScience24\\src\\functions\\vectorize_functions.py:143\u001b[0m, in \u001b[0;36mvectorize_glove.<locals>.average_glove_vector\u001b[1;34m(tokenized_tweet, glv_model, vector_size)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokenized_tweet:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m glv_model:\n\u001b[1;32m--> 143\u001b[0m         vec \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m glv_model[word]\n\u001b[0;32m    144\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (300,) (100,) (300,) "
     ]
    }
   ],
   "source": [
    "# Hyperparameter search for SVC-model\n",
    "param_dist = {\n",
    "    'kernel': ['sigmoid'],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    scoring='f1',\n",
    "    cv=2, \n",
    "    verbose=1,  \n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    refit=True \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieing best model found\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(\"..\\\\..\\\\..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\test_cleaned.csv\")\n",
    "df_test = df_test.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# Use vectorizer to transform test data\n",
    "X_test, _, y_test, _, _ = vectorize_glove(df_test, \"tweet\", \"label\", vector_size=300)\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_report)\n",
    "\n",
    "# Save best model and hyperparameter search results\n",
    "with open(\"svm_glove_sigmoid_best_model_opt.joblib\", \"wb\") as file:\n",
    "    joblib.dump(best_model, file)\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "results_df.to_csv(\"svm_glove_sigmoid_results_opt.csv\", index=False)\n",
    "\n",
    "# Save configuration of best model\n",
    "best_model_config = best_model.get_params()\n",
    "best_model_config_df = pd.DataFrame([best_model_config])\n",
    "best_model_config_df.to_csv(\"svm_glove_sigmoid_best_model_config_opt.csv\", index=False)\n",
    "\n",
    "# Save confusion matrix\n",
    "unique_labels = sorted(y_test.unique())\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[f\"Actual_{label}\" for label in unique_labels],\n",
    "                     columns=[f\"Predicted_{label}\" for label in unique_labels])\n",
    "cm_df.to_csv(\"svm_glove_sigmoid_confusion_matrix_opt.csv\", index=True)\n",
    "\n",
    "# Save classification report\n",
    "classification_report_df = pd.DataFrame(test_report).transpose()\n",
    "classification_report_df.to_csv(\"svm_glove_sigmoid_classification_report_opt.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Test Classification Report:\n",
      "{'0': {'precision': 0.6664289632473944, 'recall': 0.4962624075813897, 'f1-score': 0.5688932593477091, 'support': 24481}, '1': {'precision': 0.22852674382233343, 'recall': 0.37528251489624, 'f1-score': 0.2840701426960613, 'support': 9734}, 'accuracy': 0.4618442203711822, 'macro avg': {'precision': 0.4474778535348639, 'recall': 0.43577246123881486, 'f1-score': 0.4264817010218852, 'support': 34215}, 'weighted avg': {'precision': 0.5418479255772631, 'recall': 0.4618442203711822, 'f1-score': 0.4878624770157746, 'support': 34215}}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search for SVC-model\n",
    "param_dist = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    scoring='f1',\n",
    "    cv=2, \n",
    "    verbose=1,  \n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    refit=True \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieing best model found\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(\"..\\\\..\\\\..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\test_cleaned.csv\")\n",
    "df_test = df_test.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# Use vectorizer to transform test data\n",
    "X_test, _, y_test, _, _ = vectorize_glove_test_data(df_test, \"tweet\", \"label\", vector_size=300)\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_report)\n",
    "\n",
    "# Save best model and hyperparameter search results\n",
    "with open(\"svm_glove_linear_best_model_opt.joblib\", \"wb\") as file:\n",
    "    joblib.dump(best_model, file)\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "results_df.to_csv(\"svm_glove_linear_results_opt.csv\", index=False)\n",
    "\n",
    "# Save configuration of best model\n",
    "best_model_config = best_model.get_params()\n",
    "best_model_config_df = pd.DataFrame([best_model_config])\n",
    "best_model_config_df.to_csv(\"svm_glove_linear_best_model_config_opt.csv\", index=False)\n",
    "\n",
    "# Save confusion matrix\n",
    "unique_labels = sorted(y_test.unique())\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[f\"Actual_{label}\" for label in unique_labels],\n",
    "                     columns=[f\"Predicted_{label}\" for label in unique_labels])\n",
    "cm_df.to_csv(\"svm_glove_linear_confusion_matrix_opt.csv\", index=True)\n",
    "\n",
    "# Save classification report\n",
    "classification_report_df = pd.DataFrame(test_report).transpose()\n",
    "classification_report_df.to_csv(\"svm_glove_linear_classification_report_opt.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Test Classification Report:\n",
      "{'0': {'precision': 0.7059746885117237, 'recall': 0.293942240921531, 'f1-score': 0.41506604372152045, 'support': 24481}, '1': {'precision': 0.2804512530180668, 'recall': 0.6921101294431888, 'f1-score': 0.39915866808863615, 'support': 9734}, 'accuracy': 0.40721905596960395, 'macro avg': {'precision': 0.49321297076489523, 'recall': 0.4930261851823599, 'f1-score': 0.4071123559050783, 'support': 34215}, 'weighted avg': {'precision': 0.5849153542695711, 'recall': 0.40721905596960395, 'f1-score': 0.4105404732287396, 'support': 34215}}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search for SVC-model\n",
    "param_dist = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [3, 4, 5],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    scoring='f1',\n",
    "    cv=2, \n",
    "    verbose=1,  \n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    refit=True \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieing best model found\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(\"..\\\\..\\\\..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\test_cleaned.csv\")\n",
    "df_test = df_test.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# Use vectorizer to transform test data\n",
    "X_test, _, y_test, _, _ = vectorize_glove_test_data(df_test, \"tweet\", \"label\", vector_size=300)\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_report)\n",
    "\n",
    "# Save best model and hyperparameter search results\n",
    "with open(\"svm_glove_poly_best_model_opt.joblib\", \"wb\") as file:\n",
    "    joblib.dump(best_model, file)\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "results_df.to_csv(\"svm_glove_poly_results_opt.csv\", index=False)\n",
    "\n",
    "# Save configuration of best model\n",
    "best_model_config = best_model.get_params()\n",
    "best_model_config_df = pd.DataFrame([best_model_config])\n",
    "best_model_config_df.to_csv(\"svm_glove_poly_best_model_config_opt.csv\", index=False)\n",
    "\n",
    "# Save confusion matrix\n",
    "unique_labels = sorted(y_test.unique())\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[f\"Actual_{label}\" for label in unique_labels],\n",
    "                     columns=[f\"Predicted_{label}\" for label in unique_labels])\n",
    "cm_df.to_csv(\"svm_glove_poly_confusion_matrix_opt.csv\", index=True)\n",
    "\n",
    "# Save classification report\n",
    "classification_report_df = pd.DataFrame(test_report).transpose()\n",
    "classification_report_df.to_csv(\"svm_glove_poly_classification_report_opt.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Test Classification Report:\n",
      "{'0': {'precision': 0.7177775128174556, 'recall': 0.9836199501654345, 'f1-score': 0.8299298626548794, 'support': 24481}, '1': {'precision': 0.3988005997001499, 'recall': 0.027326895418122048, 'f1-score': 0.05114892798769349, 'support': 9734}, 'accuracy': 0.71155925763554, 'macro avg': {'precision': 0.5582890562588028, 'recall': 0.5054734227917782, 'f1-score': 0.4405393953212865, 'support': 34215}, 'weighted avg': {'precision': 0.6270301425914186, 'recall': 0.71155925763554, 'f1-score': 0.6083704992747716, 'support': 34215}}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search for SVC-model\n",
    "param_dist = {\n",
    "    'kernel': ['rbf'],\n",
    "    'degree': [3, 4, 5],\n",
    "    'C': uniform(0.01, 1),\n",
    "    'gamma': uniform(0.01, 0.1),\n",
    "    'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    scoring='f1',\n",
    "    cv=2, \n",
    "    verbose=1,  \n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    refit=True \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieing best model found\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(\"..\\\\..\\\\..\\\\..\\\\..\\\\data\\\\mixed_dataset\\\\test_cleaned.csv\")\n",
    "df_test = df_test.dropna(subset=['tweet_cleaned'])\n",
    "\n",
    "# Use vectorizer to transform test data\n",
    "X_test, _, y_test, _, _ = vectorize_glove_test_data(df_test, \"tweet\", \"label\", vector_size=300)\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_report)\n",
    "\n",
    "# Save best model and hyperparameter search results\n",
    "with open(\"svm_glove_rbf_best_model_opt.joblib\", \"wb\") as file:\n",
    "    joblib.dump(best_model, file)\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "results_df.to_csv(\"svm_glove_rbf_results_opt.csv\", index=False)\n",
    "\n",
    "# Save configuration of best model\n",
    "best_model_config = best_model.get_params()\n",
    "best_model_config_df = pd.DataFrame([best_model_config])\n",
    "best_model_config_df.to_csv(\"svm_glove_rbf_best_model_config_opt.csv\", index=False)\n",
    "\n",
    "# Save confusion matrix\n",
    "unique_labels = sorted(y_test.unique())\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[f\"Actual_{label}\" for label in unique_labels],\n",
    "                     columns=[f\"Predicted_{label}\" for label in unique_labels])\n",
    "cm_df.to_csv(\"svm_glove_rbf_confusion_matrix_opt.csv\", index=True)\n",
    "\n",
    "# Save classification report\n",
    "classification_report_df = pd.DataFrame(test_report).transpose()\n",
    "classification_report_df.to_csv(\"svm_glove_rbf_classification_report_opt.csv\", index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
