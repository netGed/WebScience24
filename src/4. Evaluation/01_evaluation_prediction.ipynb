{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.401701300Z",
     "start_time": "2025-03-15T08:04:18.017201600Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.src.saving import load_model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer\n",
    "from nltk import word_tokenize\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.src.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.405426300Z",
     "start_time": "2025-03-15T08:04:27.401701300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.410818900Z",
     "start_time": "2025-03-15T08:04:27.405426300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funktionen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datenvorbereitung etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_dataset(tokenizer, max_len, labels_data, tweets_data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for tweet in tweets_data:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels_data)\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.416065400Z",
     "start_time": "2025-03-15T08:04:27.410818900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, dataset, sampler):\n",
    "    if sampler == \"random\":\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            sampler=RandomSampler(dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    if sampler == \"sequential\":\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            sampler=SequentialSampler(dataset),\n",
    "            batch_size=batch_size\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.419931900Z",
     "start_time": "2025-03-15T08:04:27.416065400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_max_len(tweets, tokenizer):\n",
    "    max_len = 0\n",
    "\n",
    "    for sent in tweets:\n",
    "        input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "        max_len = max(max_len, len(input_ids))\n",
    "    return max_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.471108500Z",
     "start_time": "2025-03-15T08:04:27.420932400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.495193Z",
     "start_time": "2025-03-15T08:04:27.425361300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def vectorize_w2v(tweets, loaded_vectorizer, vector_size=300):\n",
    "    x_tokenized = tweets.map(word_tokenize)\n",
    "\n",
    "    def w2v_vector(x_tokenized, vector_size):\n",
    "        vec = np.zeros(vector_size).reshape((1, vector_size))\n",
    "        count = 0\n",
    "        for word in x_tokenized:\n",
    "            try:\n",
    "                vec += loaded_vectorizer.wv[word].reshape((1, vector_size))\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        return vec\n",
    "\n",
    "    tweets_w2v = np.zeros((len(x_tokenized), 300))\n",
    "    for i in range(len(x_tokenized)):\n",
    "        tweets_w2v[i, :] = w2v_vector(x_tokenized.iloc[i], 300)\n",
    "\n",
    "    return tweets_w2v"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.495193Z",
     "start_time": "2025-03-15T08:04:27.431317800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def tokenize_and_vectorize_for_lstm(tokenizer, glove_embeddings, tweets, vector_size=200, max_seq_len=50):\n",
    "    X_sequences = tokenizer.texts_to_sequences(tweets)\n",
    "    X_padded = pad_sequences(X_sequences, padding='post', maxlen=max_seq_len)\n",
    "\n",
    "    def get_glove_vectors(sequence, glove_embeddings, vector_size, max_seq_len):\n",
    "        vectors = [glove_embeddings.get(tokenizer.index_word.get(idx, ''), np.zeros(vector_size)) for idx in sequence]\n",
    "\n",
    "        # Padding sicherstellen\n",
    "        if len(vectors) < max_seq_len:\n",
    "            vectors.extend([np.zeros(vector_size)] * (max_seq_len - len(vectors)))\n",
    "        else:\n",
    "            vectors = vectors[:max_seq_len]\n",
    "\n",
    "        return np.array(vectors, dtype=np.float32)\n",
    "\n",
    "    X_vectors = np.array([get_glove_vectors(seq, glove_embeddings, vector_size, max_seq_len) for seq in X_padded],\n",
    "                         dtype=np.float32)\n",
    "\n",
    "    return X_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.495193Z",
     "start_time": "2025-03-15T08:04:27.436646300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluationsfunktionen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def print_wordcloud(dataframe, tweet_col, label_col):\n",
    "    dataset_0_text = \" \".join(dataframe[dataframe[label_col] == 0][tweet_col].tolist())\n",
    "    dataset_1_text = \" \".join(dataframe[dataframe[label_col] == 1][tweet_col].tolist())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Subplot 1: Dataset 0\n",
    "    plt.subplot(1, 2, 1)\n",
    "    wordcloud = WordCloud(stopwords=None, width=800, height=480, max_words=100, colormap='RdYlGn').generate(\n",
    "        dataset_0_text)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Worthäufigkeit in falsch vorhergesagten Tweets (Label 0)\", fontsize=14)\n",
    "\n",
    "    # Subplot 2: Dataset 1\n",
    "    plt.subplot(1, 2, 2)\n",
    "    wordcloud = WordCloud(stopwords=None, width=800, height=480, max_words=100, colormap='Paired').generate(\n",
    "        dataset_1_text)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Worthäufigkeit in falsch vorhergesagten Tweets (Label 1)\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.495193Z",
     "start_time": "2025-03-15T08:04:27.439112900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Metriken"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_predictions_bert(test_dataloader, model):\n",
    "    predictions = []\n",
    "    print(\"Prediction start.\")\n",
    "    total_t0 = time.time()\n",
    "    batches_completed = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            predictions.extend(list(pred_flat))\n",
    "\n",
    "        batches_completed += 1\n",
    "\n",
    "    print(\"Total Prediction took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.495193Z",
     "start_time": "2025-03-15T08:04:27.447377300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model_name, y_prediction, y_true, sample_size, df, dataset_name, threshold):\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_prediction)\n",
    "    precision = precision_score(y_true, y_prediction)\n",
    "    recall = recall_score(y_true, y_prediction)\n",
    "    f1 = f1_score(y_true, y_prediction)\n",
    "    mcc = matthews_corrcoef(y_true, y_prediction)\n",
    "\n",
    "    df.loc[len(df.index)] = [model_name, dataset_name, sample_size, threshold, accuracy, precision, recall, f1, mcc]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.496194100Z",
     "start_time": "2025-03-15T08:04:27.449287900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def eval_model_bert(tokenizer, model, model_name, labels, tweets, batch_size, data_size, df, dataset_name, threshold,\n",
    "                    max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = get_max_len(tweets, tokenizer)\n",
    "    dataset = create_dataset(tokenizer=tokenizer, max_len=max_len, labels_data=labels,\n",
    "                             tweets_data=tweets)\n",
    "    dataloader = get_dataloader(batch_size=batch_size, sampler=\"sequential\", dataset=dataset)\n",
    "    predictions = get_predictions_bert(test_dataloader=dataloader, model=model)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.496194100Z",
     "start_time": "2025-03-15T08:04:27.453813300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# geeignet für tf-idf bayes und ensemble\n",
    "def eval_classic_model(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorizer.transform(tweets)\n",
    "    predictions = (model.predict_proba(X_vectorized)[:, 1] >= threshold)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.496194100Z",
     "start_time": "2025-03-15T08:04:27.460495200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def eval_model_svm(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorizer.transform(tweets)\n",
    "    predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497194600Z",
     "start_time": "2025-03-15T08:04:27.462782300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def eval_model_gru(tokenizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold, max_len):\n",
    "    X_data = [str(x) for x in tweets]\n",
    "    tweets_seq = tokenizer.texts_to_sequences(X_data)\n",
    "    tweets_padded = pad_sequences(tweets_seq, padding='post', maxlen=max_len)\n",
    "    predictions = (model.predict(tweets_padded) > threshold).astype(int)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497194600Z",
     "start_time": "2025-03-15T08:04:27.471108500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def eval_model_lstm(tokenizer, vectorizer, model, labels, tweets, threshold, model_name, data_size, df, dataset_name):\n",
    "    X_data_vectorized = tokenize_and_vectorize_for_lstm(\n",
    "        glove_embeddings=vectorizer,\n",
    "        tweets=tweets,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    predictions = (model.predict(X_data_vectorized) > threshold).astype(int)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497194600Z",
     "start_time": "2025-03-15T08:04:27.473542400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Wahrscheinlichkeiten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_predictions_with_probabilities_bert(test_dataloader, model, threshold):\n",
    "    predictions = []\n",
    "    predictions_proba = []\n",
    "    print(\"Prediction start.\")\n",
    "    total_t0 = time.time()\n",
    "    batches_completed = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            pred_with_thresh = [1 if value[1] > threshold else 0 for value in output.logits.softmax(dim=-1).tolist()]\n",
    "            pred_with_thresh = np.array(pred_with_thresh)\n",
    "\n",
    "            predictions.extend(list(pred_with_thresh))\n",
    "            predictions_proba.extend(output.logits.softmax(dim=-1).tolist())\n",
    "\n",
    "        batches_completed += 1\n",
    "\n",
    "    print(\"Prediction finished.\")\n",
    "    print(\"Total Prediction took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "    return predictions, predictions_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497194600Z",
     "start_time": "2025-03-15T08:04:27.475048200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def add_to_detail_eval_df(dataframe, predictions, probabilities=None):\n",
    "    if probabilities is not None:\n",
    "        dataframe[\"zero_proba\"] = pd.Series((v[0] for v in probabilities), index=dataframe.index)\n",
    "        dataframe[\"one_proba\"] = pd.Series((v[1] for v in probabilities), index=dataframe.index)\n",
    "    else:\n",
    "        dataframe[\"zero_proba\"] = 0\n",
    "        dataframe[\"one_proba\"] = 0\n",
    "    dataframe[\"pred\"] = predictions\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497194600Z",
     "start_time": "2025-03-15T08:04:27.482573800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_bert(model, tokenizer, data, label_name, tweet_name, batch_size, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "    y_data = data[label_name].values\n",
    "    max_len = get_max_len(x_data, tokenizer)\n",
    "    test_dataset = create_dataset(tokenizer=tokenizer, max_len=max_len, labels_data=y_data,\n",
    "                                  tweets_data=x_data)\n",
    "    test_dataloader = get_dataloader(batch_size=batch_size, sampler=\"sequential\", dataset=test_dataset)\n",
    "\n",
    "    predictions, predictions_proba = get_predictions_with_probabilities_bert(test_dataloader=test_dataloader,\n",
    "                                                                             model=model, threshold=threshold)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=predictions_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497626200Z",
     "start_time": "2025-03-15T08:04:27.488763300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def add_pred_and_probas(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_vectorized = vectorizer.transform(x_data)\n",
    "    probabilities = model.predict_proba(X_vectorized)\n",
    "    predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.497626200Z",
     "start_time": "2025-03-15T08:04:27.490800400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_svm(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_vectorized = vectorizer.transform(x_data)\n",
    "    predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.519838200Z",
     "start_time": "2025-03-15T08:04:27.495193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_gru(model, tokenizer, data, tweet_name, threshold, max_len):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_data = [str(x) for x in x_data]\n",
    "    tweets_seq = tokenizer.texts_to_sequences(X_data)\n",
    "    tweets_padded = pad_sequences(tweets_seq, padding='post', maxlen=max_len)\n",
    "\n",
    "    probabilities = model.predict(tweets_padded)\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    new_array = []\n",
    "    for proba in probabilities:\n",
    "        complement = 1 - proba[0]\n",
    "        new_array.append([complement, proba[0]])\n",
    "    probabilities = pd.Series(new_array)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.645674200Z",
     "start_time": "2025-03-15T08:04:27.499131200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_lstm(model, tokenizer, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_data_vectorized = tokenize_and_vectorize_for_lstm(\n",
    "        glove_embeddings=vectorizer,\n",
    "        tweets=x_data,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    probabilities = model.predict(X_data_vectorized)\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    new_array = []\n",
    "    for proba in probabilities:\n",
    "        complement = 1 - proba[0]\n",
    "        new_array.append([complement, proba[0]])\n",
    "    probabilities = pd.Series(new_array)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.645674200Z",
     "start_time": "2025-03-15T08:04:27.503816500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Modelle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "MODELS_PATH = \"../../webapp/backend/app/models\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.646675400Z",
     "start_time": "2025-03-15T08:04:27.509404100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "nb_vectorizer = joblib.load(MODELS_PATH + \"/nb/vectorizer_nb_tfidf.joblib\")\n",
    "nb_model = joblib.load(MODELS_PATH + \"/nb/model_nb_tfidf_comp.joblib\")\n",
    "nb_modelname = \"ComplementNB\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:27.648677700Z",
     "start_time": "2025-03-15T08:04:27.512832700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "ensemble_vectorizer = joblib.load(MODELS_PATH + \"/ensemble/tfidf_vectorizer_for_brf.joblib\")\n",
    "ensemble_model = joblib.load(MODELS_PATH + \"/ensemble/tfidf_balancedrandomforest.joblib\")\n",
    "ensemble_modelname = \"BalancedRandomForest\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:28.077573500Z",
     "start_time": "2025-03-15T08:04:27.542580200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "svm_vectorizer = joblib.load(MODELS_PATH + \"/svc/tfidf_vectorizer_svc_linear.joblib\")\n",
    "svm_model = joblib.load(MODELS_PATH + \"/svc/svc_linear_best.joblib\")\n",
    "svm_modelname = \"LinearSVC\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:28.090892600Z",
     "start_time": "2025-03-15T08:04:28.055552400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4 RNN-GRU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "max_len_gru = 40\n",
    "gru_model = load_model(MODELS_PATH + \"/gru/gru-model_mixed-dataset.keras\")\n",
    "with open(MODELS_PATH + \"/gru/tokenizer_mixed-dataset.pkl\", 'rb') as f:\n",
    "    gru_tokenizer = pickle.load(f)\n",
    "gru_modelname = \"RNN-GRU\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:28.319101300Z",
     "start_time": "2025-03-15T08:04:28.089892400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.5 RNN-LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "lstm_model = load_model(MODELS_PATH + \"/lstm/model_lstm_17.keras\")\n",
    "with open(MODELS_PATH + \"/lstm/tokenizer_lstm.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tokenizer_data = f.read()\n",
    "    lstm_tokenizer = tokenizer_from_json(tokenizer_data)\n",
    "lstm_glove_embeddings = {}\n",
    "with open(MODELS_PATH + \"/lstm/glove.6B.200d.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        lstm_glove_embeddings[word] = vector\n",
    "lstm_modelname = \"RNN-LSTM\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:48.768048800Z",
     "start_time": "2025-03-15T08:04:28.319101300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.6 BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "PATH_BERT_TUNED = MODELS_PATH + \"/bert/bert_mixed_imran\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(PATH_BERT_TUNED, local_files_only=True)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(PATH_BERT_TUNED, local_files_only=True)\n",
    "bert_modelname = \"bert_tuned_uncased\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:49.070509Z",
     "start_time": "2025-03-15T08:04:48.767047900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.7 RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "PATH_ROBERTA_TUNED = MODELS_PATH + \"/roberta/roberta_hate_mixed_cleaned\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(PATH_ROBERTA_TUNED, local_files_only=True)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(PATH_ROBERTA_TUNED, local_files_only=True)\n",
    "roberta_modelname = \"roberta_hate_mixed_cleaned\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:49.237335800Z",
     "start_time": "2025-03-15T08:04:49.056082800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "sample_size = None  # setzen, um nur für eine Stichprobe der Daten die Metriken zu bestimmen"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:49.237335800Z",
     "start_time": "2025-03-15T08:04:49.219779Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Mixed-Train (cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "        label                                tweet_cleaned\n140232      0  nickis \" good pout buy botox trade mark mkr",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>140232</th>\n      <td>0</td>\n      <td>nickis \" good pout buy botox trade mark mkr</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixed_train_cleaned = pd.read_csv(\"../../data/mixed_dataset/train_cleaned.csv\", index_col=0)\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned[df_mixed_train_cleaned.tweet_cleaned.notna()]\n",
    "if sample_size is not None:\n",
    "    df_mixed_train_cleaned = df_mixed_train_cleaned.sample(n=sample_size)\n",
    "\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned[[\"label\", \"tweet_cleaned\"]]\n",
    "df_mixed_train_cleaned.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:49.525824500Z",
     "start_time": "2025-03-15T08:04:49.224288300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Mixed-Train (cleaned-rnn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "        label                                      tweet_cleaned\n140232      0  nickis \"thats not good\" pout bought to you by ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>140232</th>\n      <td>0</td>\n      <td>nickis \"thats not good\" pout bought to you by ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixed_train_cleaned_rnn = pd.read_csv(\"../../data/mixed_dataset/train_cleaned_rnn.csv\", index_col=0)\n",
    "df_mixed_train_cleaned_rnn = df_mixed_train_cleaned_rnn[df_mixed_train_cleaned_rnn.tweet_cleaned.notna()]\n",
    "if sample_size is not None:\n",
    "    df_mixed_train_cleaned_rnn = df_mixed_train_cleaned_rnn.sample(n=sample_size)\n",
    "\n",
    "df_mixed_train_cleaned_rnn = df_mixed_train_cleaned_rnn[[\"label\", \"tweet_cleaned\"]]\n",
    "df_mixed_train_cleaned_rnn.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:49.888174600Z",
     "start_time": "2025-03-15T08:04:49.519817400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Mixed-Train (uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                              tweet\n",
      "140232      0  Nicki's \"that's not good\" pout bought to you b...\n",
      "Daten: \t 81905\n"
     ]
    }
   ],
   "source": [
    "df_mixed_train_uncleaned = pd.read_csv(\"../../data/mixed_dataset/train_cleaned.csv\", index_col=0)\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned[df_mixed_train_uncleaned.tweet.notna()]\n",
    "if sample_size is not None:\n",
    "    df_mixed_train_uncleaned = df_mixed_train_uncleaned.sample(n=sample_size)\n",
    "\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned[[\"label\", \"tweet\"]]\n",
    "print(df_mixed_train_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_train_uncleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.175599300Z",
     "start_time": "2025-03-15T08:04:49.867155900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Mixed-Test (cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                 tweet_cleaned\n",
      "8886      0  final gear evening butterfly stage hope like\n",
      "Daten: \t 32466\n"
     ]
    }
   ],
   "source": [
    "df_mixed_test_cleaned = pd.read_csv(\"../../data/mixed_dataset/test_cleaned.csv\", index_col=0)\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned[df_mixed_test_cleaned.tweet_cleaned.notna()]\n",
    "if sample_size is not None:\n",
    "    df_mixed_test_cleaned = df_mixed_test_cleaned.sample(n=sample_size)\n",
    "\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned[[\"label\", \"tweet_cleaned\"]]\n",
    "print(df_mixed_test_cleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_cleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.288476900Z",
     "start_time": "2025-03-15T08:04:50.174598800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.5 Mixed-Test (cleaned-RNN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                      tweet_cleaned\n",
      "8886      0  cinemaaawards final rehearsals gearing up for ...\n",
      "Daten: \t 32529\n"
     ]
    }
   ],
   "source": [
    "df_mixed_test_cleaned_rnn = pd.read_csv(\"../../data/mixed_dataset/test_cleaned_rnn.csv\", index_col=0)\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn[df_mixed_test_cleaned_rnn.tweet_cleaned.notna()]\n",
    "if sample_size is not None:\n",
    "    df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn.sample(n=sample_size)\n",
    "\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn[[\"label\", \"tweet_cleaned\"]]\n",
    "print(df_mixed_test_cleaned_rnn.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_cleaned_rnn))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.431612700Z",
     "start_time": "2025-03-15T08:04:50.287476100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.6 Mixed-Test (uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                              tweet\n",
      "8886      0   @user #cinemaaawards final rehearsals!! geari...\n",
      "Daten: \t 32582\n"
     ]
    }
   ],
   "source": [
    "df_mixed_test_uncleaned = pd.read_csv(\"../../data/mixed_dataset/test_cleaned.csv\", index_col=0)\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned[df_mixed_test_uncleaned.tweet.notna()]\n",
    "if sample_size is not None:\n",
    "    df_mixed_test_uncleaned = df_mixed_test_uncleaned.sample(n=sample_size)\n",
    "\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned[[\"label\", \"tweet\", ]]\n",
    "print(df_mixed_test_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_uncleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.576355Z",
     "start_time": "2025-03-15T08:04:50.428609600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.7 Mixed-Test (manual-labeled, uncleaned, new)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label_manual                                  tweet\n",
      "0             1  Post the shit or kill yourself faggot\n",
      "Daten: \t 498\n"
     ]
    }
   ],
   "source": [
    "df_mixed_manual_uncleaned_new = pd.read_csv(\"../../data/manual_labeled/manual_labeled_group.csv\", index_col=0)\n",
    "df_mixed_manual_uncleaned_new = df_mixed_manual_uncleaned_new[df_mixed_manual_uncleaned_new.tweet.notna()]\n",
    "\n",
    "df_mixed_manual_uncleaned_new = df_mixed_manual_uncleaned_new[[\"label_manual\", \"tweet\", ]]\n",
    "print(df_mixed_manual_uncleaned_new.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_manual_uncleaned_new))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.577351200Z",
     "start_time": "2025-03-15T08:04:50.543387800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.8 Mixed-Test (manual-labeled, uncleaned, old)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                  tweet\n",
      "0      1  Post the shit or kill yourself faggot\n",
      "Daten: \t 498\n"
     ]
    }
   ],
   "source": [
    "df_mixed_manual_uncleaned_old = pd.read_csv(\"../../data/manual_labeled/manual_labeled_group.csv\", index_col=0)\n",
    "df_mixed_manual_uncleaned_old = df_mixed_manual_uncleaned_old[df_mixed_manual_uncleaned_old.label.notna()]\n",
    "\n",
    "df_mixed_manual_uncleaned_old = df_mixed_manual_uncleaned_old[[\"label\", \"tweet\", ]]\n",
    "print(df_mixed_manual_uncleaned_old.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_manual_uncleaned_old))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.577351200Z",
     "start_time": "2025-03-15T08:04:50.554404Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Allgemeine Evaluation - Metriken"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def evaluate(label_col, tweet_col, data, dataset_name, threshold):\n",
    "    evaluation_df = pd.DataFrame(\n",
    "        columns=[\"model\", \"dataset_name\", \"sample_size\", \"threshold\", \"accuracy\", \"precision\", \"recall\", \"f1_score\",\n",
    "                 \"mcc\"])\n",
    "    eval_classic_model(vectorizer=ensemble_vectorizer,\n",
    "                       model=ensemble_model,\n",
    "                       model_name=ensemble_modelname,\n",
    "                       labels=data[label_col],\n",
    "                       tweets=data[tweet_col],\n",
    "                       data_size=len(data),\n",
    "                       df=evaluation_df,\n",
    "                       dataset_name=dataset_name,\n",
    "                       threshold=threshold)\n",
    "\n",
    "    eval_classic_model(vectorizer=nb_vectorizer,\n",
    "                       model=nb_model,\n",
    "                       model_name=nb_modelname,\n",
    "                       labels=data[label_col],\n",
    "                       tweets=data[tweet_col],\n",
    "                       data_size=len(data),\n",
    "                       df=evaluation_df,\n",
    "                       dataset_name=dataset_name,\n",
    "                       threshold=threshold)\n",
    "\n",
    "    eval_model_svm(vectorizer=svm_vectorizer,\n",
    "                   model=svm_model,\n",
    "                   model_name=svm_modelname,\n",
    "                   labels=data[label_col],\n",
    "                   tweets=data[tweet_col],\n",
    "                   data_size=len(data),\n",
    "                   df=evaluation_df,\n",
    "                   dataset_name=dataset_name,\n",
    "                   threshold=\"None\")\n",
    "\n",
    "    eval_model_lstm(tokenizer=lstm_tokenizer,\n",
    "                    vectorizer=lstm_glove_embeddings,\n",
    "                    model=lstm_model,\n",
    "                    model_name=lstm_modelname,\n",
    "                    labels=data[label_col],\n",
    "                    tweets=data[tweet_col],\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    eval_model_gru(tokenizer=gru_tokenizer,\n",
    "                   model=gru_model,\n",
    "                   model_name=gru_modelname,\n",
    "                   labels=data[label_col],\n",
    "                   tweets=data[tweet_col],\n",
    "                   data_size=len(data),\n",
    "                   df=evaluation_df,\n",
    "                   dataset_name=dataset_name,\n",
    "                   threshold=threshold,\n",
    "                   max_len=40)\n",
    "\n",
    "    eval_model_bert(tokenizer=bert_tokenizer,\n",
    "                    model=bert_model,\n",
    "                    model_name=bert_modelname,\n",
    "                    labels=data[label_col].values,\n",
    "                    tweets=data[tweet_col].values,\n",
    "                    batch_size=16,\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    eval_model_bert(tokenizer=roberta_tokenizer,\n",
    "                    model=roberta_model,\n",
    "                    model_name=roberta_modelname,\n",
    "                    labels=data[label_col].values,\n",
    "                    tweets=data[tweet_col].values,\n",
    "                    batch_size=16,\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    return evaluation_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.577351200Z",
     "start_time": "2025-03-15T08:04:50.557407300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1 Alle Datensätze - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.1 Mixed-Train (cleaned) - df_mixed_train_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 7ms/step\n",
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 9ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 3:02:09 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 3:02:02 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned = evaluate(label_col=\"label\",\n",
    "                                          tweet_col=\"tweet_cleaned\",\n",
    "                                          data=df_mixed_train_cleaned,\n",
    "                                          dataset_name=\"df_mixed_train_cleaned\",\n",
    "                                          threshold=0.5,\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T07:18:13.882576700Z",
     "start_time": "2025-03-13T01:08:52.553409100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned.to_csv(\"evaluation_data/evaluation_mixed_train_cleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T07:18:13.899510900Z",
     "start_time": "2025-03-13T07:18:13.891491500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.2 Mixed-Train (cleaned-RNN) - df_mixed_train_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2604/2604\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 7ms/step\n",
      "\u001B[1m2604/2604\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 3:05:10 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 3:04:42 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned_rnn = evaluate(label_col=\"label\",\n",
    "                                              tweet_col=\"tweet_cleaned\",\n",
    "                                              data=df_mixed_train_cleaned_rnn,\n",
    "                                              dataset_name=\"df_mixed_train_cleaned_rnn\",\n",
    "                                              threshold=0.5,\n",
    "                                              )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T13:33:41.498716100Z",
     "start_time": "2025-03-13T07:18:13.899510900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned_rnn.to_csv(\"evaluation_data/evaluation_mixed_train_cleaned_rnn.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T13:33:41.498716100Z",
     "start_time": "2025-03-13T13:33:41.498716100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.3 Mixed-Train (uncleaned) - df_mixed_train_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 7ms/step\n",
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Total Prediction took 3:02:10 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Total Prediction took 3:03:11 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_uncleaned = evaluate(label_col=\"label\",\n",
    "                                            tweet_col=\"tweet\",\n",
    "                                            data=df_mixed_train_uncleaned,\n",
    "                                            dataset_name=\"df_mixed_train_uncleaned\",\n",
    "                                            threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T19:44:43.138239500Z",
     "start_time": "2025-03-13T13:33:41.498716100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_uncleaned.to_csv(\"evaluation_data/evaluation_mixed_train_uncleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T19:44:43.152639800Z",
     "start_time": "2025-03-13T19:44:43.147435Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.4 Mixed-Test (cleaned) - df_mixed_test_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1015/1015\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7ms/step\n",
      "\u001B[1m1015/1015\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 1:09:20 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 1:09:17 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned = evaluate(label_col=\"label\",\n",
    "                                         tweet_col=\"tweet_cleaned\",\n",
    "                                         data=df_mixed_test_cleaned,\n",
    "                                         dataset_name=\"df_mixed_test_cleaned\",\n",
    "                                         threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T01:30:42.086595900Z",
     "start_time": "2025-03-13T23:10:01.961121400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned.to_csv(\"evaluation_data/evaluation_mixed_test_cleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T01:30:42.098626Z",
     "start_time": "2025-03-14T01:30:42.092759Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.5 Mixed-Test (cleaned-RNN) - df_mixed_test_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1017/1017\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7ms/step\n",
      "\u001B[1m1017/1017\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 9ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 1:11:00 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 1:11:02 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned_rnn = evaluate(label_col=\"label\",\n",
    "                                             tweet_col=\"tweet_cleaned\",\n",
    "                                             data=df_mixed_test_cleaned_rnn,\n",
    "                                             dataset_name=\"df_mixed_test_cleaned_rnn\",\n",
    "                                             threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T03:54:56.733555300Z",
     "start_time": "2025-03-14T01:30:42.096622800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn.to_csv(\"evaluation_data/evaluation_mixed_test_cleaned_rnn.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T03:54:56.745533900Z",
     "start_time": "2025-03-14T03:54:56.738983400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.6 Mixed-Test (uncleaned) - df_mixed_test_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1019/1019\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7ms/step\n",
      "\u001B[1m1019/1019\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 9ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 1:11:16 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 1:11:10 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_uncleaned = evaluate(label_col=\"label\",\n",
    "                                           tweet_col=\"tweet\",\n",
    "                                           data=df_mixed_test_uncleaned,\n",
    "                                           dataset_name=\"df_mixed_test_uncleaned\",\n",
    "                                           threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T06:19:40.722085300Z",
     "start_time": "2025-03-14T03:54:56.742531400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned.to_csv(\"evaluation_data/evaluation_mixed_test_uncleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T06:19:40.736257900Z",
     "start_time": "2025-03-14T06:19:40.727253600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.7 Mixed-Test (manual-labeled, uncleaned, new) - df_mixed_manual_uncleaned_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:01:04 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:01:05 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_manual_uncleaned_new = evaluate(label_col=\"label_manual\",\n",
    "                                                 tweet_col=\"tweet\",\n",
    "                                                 data=df_mixed_manual_uncleaned_new,\n",
    "                                                 dataset_name=\"df_mixed_manual_uncleaned_new\",\n",
    "                                                 threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T06:21:52.920657500Z",
     "start_time": "2025-03-14T06:19:40.732254700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned_new.to_csv(\"evaluation_data/evaluation_mixed_manual_uncleaned_new.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T06:21:52.932502100Z",
     "start_time": "2025-03-14T06:21:52.924978200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.8 Mixed-Test (manual-labeled, uncleaned, old) - df_mixed_manual_uncleaned_old"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:01:05 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:01:05 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_manual_uncleaned_old = evaluate(label_col=\"label\",\n",
    "                                                 tweet_col=\"tweet\",\n",
    "                                                 data=df_mixed_manual_uncleaned_old,\n",
    "                                                 dataset_name=\"df_mixed_manual_uncleaned_old\",\n",
    "                                                 threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T06:24:05.270592500Z",
     "start_time": "2025-03-14T06:21:52.930500400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned_old.to_csv(\"evaluation_data/evaluation_mixed_manual_uncleaned_old.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T06:24:05.283581200Z",
     "start_time": "2025-03-14T06:24:05.276471500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Alle Datensätze - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.1 Mixed-Train (cleaned) - df_mixed_train_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 7ms/step\n",
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 9ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 2:56:26 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 2:56:17 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned2 = evaluate(label_col=\"label\",\n",
    "                                           tweet_col=\"tweet_cleaned\",\n",
    "                                           data=df_mixed_train_cleaned,\n",
    "                                           dataset_name=\"df_mixed_train_cleaned\",\n",
    "                                           threshold=0.35,\n",
    "                                           )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T12:21:59.167171900Z",
     "start_time": "2025-03-14T06:24:05.284582200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned2.to_csv(\"evaluation_data/evaluation_mixed_train_cleaned2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T12:21:59.180692500Z",
     "start_time": "2025-03-14T12:21:59.174632700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.2 Mixed-Train (cleaned-RNN) - df_mixed_train_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2604/2604\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 7ms/step\n",
      "\u001B[1m2604/2604\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 3:00:21 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 3:41:51 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned_rnn2 = evaluate(label_col=\"label\",\n",
    "                                               tweet_col=\"tweet_cleaned\",\n",
    "                                               data=df_mixed_train_cleaned_rnn,\n",
    "                                               dataset_name=\"df_mixed_train_cleaned_rnn\",\n",
    "                                               threshold=0.35,\n",
    "                                               )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T19:10:05.128487300Z",
     "start_time": "2025-03-14T12:21:59.179691600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned_rnn2.to_csv(\"evaluation_data/evaluation_mixed_train_cleaned_rnn2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T19:10:05.171641500Z",
     "start_time": "2025-03-14T19:10:05.159241500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.3 Mixed-Train (uncleaned) - df_mixed_train_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 11ms/step\n",
      "\u001B[1m2560/2560\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Total Prediction took 4:39:09 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Total Prediction took 4:38:07 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_uncleaned2 = evaluate(label_col=\"label\",\n",
    "                                             tweet_col=\"tweet\",\n",
    "                                             data=df_mixed_train_uncleaned,\n",
    "                                             dataset_name=\"df_mixed_train_uncleaned\",\n",
    "                                             threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T04:38:04.383490600Z",
     "start_time": "2025-03-14T19:13:37.137342900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_uncleaned2.to_csv(\"evaluation_data/evaluation_mixed_train_uncleaned2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T04:38:04.393499200Z",
     "start_time": "2025-03-15T04:38:04.376484800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.4 Mixed-Test (cleaned) - df_mixed_test_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned2 = evaluate(label_col=\"label\",\n",
    "                                          tweet_col=\"tweet_cleaned\",\n",
    "                                          data=df_mixed_test_cleaned,\n",
    "                                          dataset_name=\"df_mixed_test_cleaned\",\n",
    "                                          threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned2.to_csv(\"evaluation_data/evaluation_mixed_test_cleaned2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.5 Mixed-Test (cleaned-RNN) - df_mixed_test_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn2 = evaluate(label_col=\"label\",\n",
    "                                              tweet_col=\"tweet_cleaned\",\n",
    "                                              data=df_mixed_test_cleaned_rnn,\n",
    "                                              dataset_name=\"df_mixed_test_cleaned_rnn\",\n",
    "                                              threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn2.to_csv(\"evaluation_data/evaluation_mixed_test_cleaned_rnn2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.6 Mixed-Test (uncleaned) - df_mixed_test_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned2 = evaluate(label_col=\"label\",\n",
    "                                            tweet_col=\"tweet\",\n",
    "                                            data=df_mixed_test_uncleaned,\n",
    "                                            dataset_name=\"df_mixed_test_uncleaned\",\n",
    "                                            threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned2.to_csv(\"evaluation_data/evaluation_mixed_test_uncleaned2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.7 Mixed-Test (manual-labeled, uncleaned, new) - df_mixed_manual_uncleaned_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned_new2 = evaluate(label_col=\"label_manual\",\n",
    "                                                  tweet_col=\"tweet\",\n",
    "                                                  data=df_mixed_manual_uncleaned_new,\n",
    "                                                  dataset_name=\"df_mixed_manual_uncleaned_new\",\n",
    "                                                  threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned_new2.to_csv(\"evaluation_data/evaluation_mixed_manual_uncleaned_new2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.8 Mixed-Test (manual-labeled, uncleaned, old) - df_mixed_manual_uncleaned_old"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned_old2 = evaluate(label_col=\"label\",\n",
    "                                                  tweet_col=\"tweet\",\n",
    "                                                  data=df_mixed_manual_uncleaned_old,\n",
    "                                                  dataset_name=\"df_mixed_manual_uncleaned_old\",\n",
    "                                                  threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned_old2.to_csv(\"evaluation_data/evaluation_mixed_manual_uncleaned_old2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Detaillierte Evaluation - Tweetbetrachtung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def create_false_tweet_df(tweet_col, label_col, original_df, threshold):\n",
    "    merged_false = original_df.copy()\n",
    "\n",
    "    add_pred_and_probas(model=ensemble_model,\n",
    "                        vectorizer=ensemble_vectorizer,\n",
    "                        data=merged_false,\n",
    "                        tweet_name=tweet_col,\n",
    "                        threshold=threshold)\n",
    "    merged_false.rename(columns={'zero_proba': '0_ens',\n",
    "                                 'one_proba': '1_ens',\n",
    "                                 'pred': 'pred_ens'}, inplace=True)\n",
    "\n",
    "    add_pred_and_probas(model=nb_model,\n",
    "                        vectorizer=nb_vectorizer,\n",
    "                        data=merged_false,\n",
    "                        tweet_name=tweet_col,\n",
    "                        threshold=threshold)\n",
    "    merged_false.rename(columns={'zero_proba': '0_nb',\n",
    "                                 'one_proba': '1_nb',\n",
    "                                 'pred': 'pred_nb'}, inplace=True)\n",
    "\n",
    "    add_pred_and_probas_svm(model=svm_model,\n",
    "                            vectorizer=svm_vectorizer,\n",
    "                            data=merged_false,\n",
    "                            tweet_name=tweet_col,\n",
    "                            threshold=threshold)\n",
    "    merged_false.rename(columns={'zero_proba': '0_svm',\n",
    "                                 'one_proba': '1_svm',\n",
    "                                 'pred': 'pred_svm'}, inplace=True)\n",
    "\n",
    "    add_pred_and_probas_lstm(model=lstm_model,\n",
    "                             tokenizer=lstm_tokenizer,\n",
    "                             vectorizer=lstm_glove_embeddings,\n",
    "                             data=merged_false,\n",
    "                             tweet_name=tweet_col,\n",
    "                             threshold=threshold)\n",
    "    merged_false.rename(columns={'zero_proba': '0_lstm',\n",
    "                                 'one_proba': '1_lstm',\n",
    "                                 'pred': 'pred_lstm'}, inplace=True)\n",
    "\n",
    "    add_pred_and_probas_gru(model=gru_model,\n",
    "                            tokenizer=gru_tokenizer,\n",
    "                            data=merged_false,\n",
    "                            tweet_name=tweet_col,\n",
    "                            threshold=threshold,\n",
    "                            max_len=40)\n",
    "    merged_false.rename(columns={'zero_proba': '0_gru',\n",
    "                                 'one_proba': '1_gru',\n",
    "                                 'pred': 'pred_gru'}, inplace=True)\n",
    "\n",
    "    add_pred_and_probas_bert(model=bert_model,\n",
    "                             tokenizer=bert_tokenizer,\n",
    "                             data=merged_false,\n",
    "                             label_name=label_col,\n",
    "                             tweet_name=tweet_col,\n",
    "                             batch_size=16,\n",
    "                             threshold=threshold)\n",
    "    merged_false.rename(columns={'zero_proba': '0_bert',\n",
    "                                 'one_proba': '1_bert',\n",
    "                                 'pred': 'pred_bert'}, inplace=True)\n",
    "\n",
    "    add_pred_and_probas_bert(model=roberta_model,\n",
    "                             tokenizer=roberta_tokenizer,\n",
    "                             data=merged_false,\n",
    "                             label_name=label_col,\n",
    "                             tweet_name=tweet_col,\n",
    "                             batch_size=16,\n",
    "                             threshold=threshold)\n",
    "    merged_false.rename(columns={'zero_proba': '0_rob',\n",
    "                                 'one_proba': '1_rob',\n",
    "                                 'pred': 'pred_rob'}, inplace=True)\n",
    "\n",
    "    return merged_false"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.577351200Z",
     "start_time": "2025-03-15T08:04:50.565644100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def get_all_false_merged(merged_false, label_col):\n",
    "    all_false_merged = merged_false[\n",
    "        (merged_false.pred_ens != merged_false[label_col]) &\n",
    "        (merged_false.pred_nb != merged_false[label_col]) &\n",
    "        (merged_false.pred_svm != merged_false[label_col]) &\n",
    "        (merged_false.pred_gru != merged_false[label_col]) &\n",
    "        (merged_false.pred_lstm != merged_false[label_col]) &\n",
    "        (merged_false.pred_bert != merged_false[label_col]) &\n",
    "        (merged_false.pred_rob != merged_false[label_col])]\n",
    "\n",
    "    print(\"Anzahl falsch vorhergesagter Tweets (von allen Modelle):\", len(all_false_merged), \"/\", len(merged_false),\n",
    "          \"| Anteil: \", round((len(all_false_merged) / len(merged_false) * 100), 2), \"%\")\n",
    "    print(\"-- davon Label 0:\", len(all_false_merged[all_false_merged[label_col] == 0]))\n",
    "    print(\"-- davon Label 1:\", len(all_false_merged[all_false_merged[label_col] == 1]))\n",
    "\n",
    "    return all_false_merged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.577351200Z",
     "start_time": "2025-03-15T08:04:50.572662500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def get_num_of_false(df, label_col, model_pred_col):\n",
    "    return len(\n",
    "        df[((df[label_col] == 0) & (df[model_pred_col] == 1)) | ((df[label_col] == 1) & (df[model_pred_col] == 0))])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.595462600Z",
     "start_time": "2025-03-15T08:04:50.577351200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_mostly_false_merged(merged_false, label_col):\n",
    "    merged_false[\"preds\"] = merged_false.pred_ens.values + \\\n",
    "                            merged_false.pred_nb.values + \\\n",
    "                            merged_false.pred_svm.values + \\\n",
    "                            merged_false.pred_gru.values + \\\n",
    "                            merged_false.pred_lstm.values + \\\n",
    "                            merged_false.pred_bert.values + \\\n",
    "                            merged_false.pred_rob.values\n",
    "    mostly_false_merge = merged_false[((merged_false[label_col] == 0) & (merged_false.preds >= 4)) | (\n",
    "            (merged_false[label_col] == 1) & (merged_false.preds <= 4))]\n",
    "\n",
    "    print(\"Anzahl falsch vorhergesagter Tweets (4/7 Modelle falsch):\", len(mostly_false_merge), \"/\", len(merged_false),\n",
    "          \"| Anteil: \", round((len(mostly_false_merge) / len(merged_false) * 100), 2), \"%\")\n",
    "    print(\"-- davon Label 0:\", len(mostly_false_merge[mostly_false_merge[label_col] == 0]))\n",
    "    print(\"-- davon Label 1:\", len(mostly_false_merge[mostly_false_merge[label_col] == 1]))\n",
    "\n",
    "    print(\"Modelle:\")\n",
    "    print(\"-- Ensemble: \\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_ens\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \",\n",
    "          round((get_num_of_false(mostly_false_merge, label_col, \"pred_ens\") / len(mostly_false_merge)) * 100, 2), \"%\")\n",
    "    print(\"-- NB: \\t\\t\\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_nb\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \", round((get_num_of_false(mostly_false_merge, label_col, \"pred_nb\") / len(mostly_false_merge)) * 100, 2),\n",
    "          \"%\")\n",
    "    print(\"-- SVM: \\t\\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_svm\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \",\n",
    "          round((get_num_of_false(mostly_false_merge, label_col, \"pred_svm\") / len(mostly_false_merge)) * 100, 2), \"%\")\n",
    "    print(\"-- GRU: \\t\\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_gru\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \",\n",
    "          round((get_num_of_false(mostly_false_merge, label_col, \"pred_gru\") / len(mostly_false_merge)) * 100, 2), \"%\")\n",
    "    print(\"-- LSTM: \\t\\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_lstm\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \",\n",
    "          round((get_num_of_false(mostly_false_merge, label_col, \"pred_lstm\") / len(mostly_false_merge)) * 100, 2), \"%\")\n",
    "    print(\"-- BERT: \\t\\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_bert\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \",\n",
    "          round((get_num_of_false(mostly_false_merge, label_col, \"pred_bert\") / len(mostly_false_merge)) * 100, 2), \"%\")\n",
    "    print(\"-- ROBERTA: \\t\", get_num_of_false(mostly_false_merge, label_col, \"pred_rob\"), \"/\", len(mostly_false_merge),\n",
    "          \" - \",\n",
    "          round((get_num_of_false(mostly_false_merge, label_col, \"pred_rob\") / len(mostly_false_merge)) * 100, 2), \"%\")\n",
    "\n",
    "    return mostly_false_merge"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T08:04:50.729374800Z",
     "start_time": "2025-03-15T08:04:50.582357900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1 manuell gelabelte Tweets (new) - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction finished.\n",
      "Total Prediction took 0:01:14 (h:mm:ss)\n",
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:01:07 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "merged_false_manual1 = create_false_tweet_df(tweet_col=\"tweet\", label_col=\"label_manual\",\n",
    "                                             original_df=df_mixed_manual_uncleaned_new,\n",
    "                                             threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:07:43.324965200Z",
     "start_time": "2025-03-13T23:05:19.377879800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n0              1              Post the shit or kill yourself faggot   0.06   \n2              1  i hate jews so much i wish the holocaust actua...   0.16   \n3              1  Poor kid would have been better off with his h...   0.48   \n10             1  Close your fucking legs, hoe. Use birth contro...   0.60   \n11             1  @user @user Please take away their license to ...   0.70   \n..           ...                                                ...    ...   \n94             0  You want genocide? Cause this is how genocide ...   0.61   \n95             0                        The black girl is gorgeous.   0.83   \n96             0  God help us Africans have mercy on us in the n...   0.95   \n97             0  India not only exporting goods and services, A...   0.73   \n98             0  There a lot of marriages in Ghana in which wom...   0.91   \n\n    1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n0    0.94         1  0.104995  0.895005        1      0      0  ...   \n2    0.84         1  0.273041  0.726959        1      0      0  ...   \n3    0.52         1  0.343098  0.656902        1      0      0  ...   \n10   0.40         0  0.527259  0.472741        0      0      0  ...   \n11   0.30         0  0.450629  0.549371        1      0      0  ...   \n..    ...       ...       ...       ...      ...    ...    ...  ...   \n94   0.39         0  0.319353  0.680647        1      0      0  ...   \n95   0.17         0  0.466069  0.533931        1      0      0  ...   \n96   0.05         0  0.462962  0.537038        1      0      0  ...   \n97   0.27         0  0.694790  0.305210        0      0      0  ...   \n98   0.09         0  0.516557  0.483443        0      0      0  ...   \n\n    pred_lstm     0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert  \\\n0           1  0.011137  0.988863         1  0.180920  0.819080          1   \n2           1  0.195016  0.804984         1  0.512623  0.487377          0   \n3           1  0.036294  0.963706         1  0.157057  0.842943          1   \n10          1  0.006292  0.993708         1  0.713035  0.286965          0   \n11          0  0.997577  0.002423         0  0.865542  0.134458          0   \n..        ...       ...       ...       ...       ...       ...        ...   \n94          1  0.306345  0.693655         1  0.525672  0.474328          0   \n95          0  0.999834  0.000166         0  0.951984  0.048016          0   \n96          0  0.996012  0.003988         0  0.994697  0.005303          0   \n97          0  0.985596  0.014404         0  0.994159  0.005841          0   \n98          0  0.999959  0.000041         0  0.977965  0.022035          0   \n\n       0_rob     1_rob  pred_rob  \n0   0.192266  0.807734         1  \n2   0.023317  0.976683         1  \n3   0.221822  0.778178         1  \n10  0.158761  0.841239         1  \n11  0.961045  0.038955         0  \n..       ...       ...       ...  \n94  0.667509  0.332491         0  \n95  0.999379  0.000621         0  \n96  0.999194  0.000806         0  \n97  0.999075  0.000925         0  \n98  0.998708  0.001292         0  \n\n[498 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>pred_lstm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Post the shit or kill yourself faggot</td>\n      <td>0.06</td>\n      <td>0.94</td>\n      <td>1</td>\n      <td>0.104995</td>\n      <td>0.895005</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.011137</td>\n      <td>0.988863</td>\n      <td>1</td>\n      <td>0.180920</td>\n      <td>0.819080</td>\n      <td>1</td>\n      <td>0.192266</td>\n      <td>0.807734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>i hate jews so much i wish the holocaust actua...</td>\n      <td>0.16</td>\n      <td>0.84</td>\n      <td>1</td>\n      <td>0.273041</td>\n      <td>0.726959</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.195016</td>\n      <td>0.804984</td>\n      <td>1</td>\n      <td>0.512623</td>\n      <td>0.487377</td>\n      <td>0</td>\n      <td>0.023317</td>\n      <td>0.976683</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Poor kid would have been better off with his h...</td>\n      <td>0.48</td>\n      <td>0.52</td>\n      <td>1</td>\n      <td>0.343098</td>\n      <td>0.656902</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.036294</td>\n      <td>0.963706</td>\n      <td>1</td>\n      <td>0.157057</td>\n      <td>0.842943</td>\n      <td>1</td>\n      <td>0.221822</td>\n      <td>0.778178</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>Close your fucking legs, hoe. Use birth contro...</td>\n      <td>0.60</td>\n      <td>0.40</td>\n      <td>0</td>\n      <td>0.527259</td>\n      <td>0.472741</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.006292</td>\n      <td>0.993708</td>\n      <td>1</td>\n      <td>0.713035</td>\n      <td>0.286965</td>\n      <td>0</td>\n      <td>0.158761</td>\n      <td>0.841239</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>@user @user Please take away their license to ...</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>0.450629</td>\n      <td>0.549371</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.997577</td>\n      <td>0.002423</td>\n      <td>0</td>\n      <td>0.865542</td>\n      <td>0.134458</td>\n      <td>0</td>\n      <td>0.961045</td>\n      <td>0.038955</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0</td>\n      <td>You want genocide? Cause this is how genocide ...</td>\n      <td>0.61</td>\n      <td>0.39</td>\n      <td>0</td>\n      <td>0.319353</td>\n      <td>0.680647</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.306345</td>\n      <td>0.693655</td>\n      <td>1</td>\n      <td>0.525672</td>\n      <td>0.474328</td>\n      <td>0</td>\n      <td>0.667509</td>\n      <td>0.332491</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>The black girl is gorgeous.</td>\n      <td>0.83</td>\n      <td>0.17</td>\n      <td>0</td>\n      <td>0.466069</td>\n      <td>0.533931</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999834</td>\n      <td>0.000166</td>\n      <td>0</td>\n      <td>0.951984</td>\n      <td>0.048016</td>\n      <td>0</td>\n      <td>0.999379</td>\n      <td>0.000621</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0</td>\n      <td>God help us Africans have mercy on us in the n...</td>\n      <td>0.95</td>\n      <td>0.05</td>\n      <td>0</td>\n      <td>0.462962</td>\n      <td>0.537038</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.996012</td>\n      <td>0.003988</td>\n      <td>0</td>\n      <td>0.994697</td>\n      <td>0.005303</td>\n      <td>0</td>\n      <td>0.999194</td>\n      <td>0.000806</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>India not only exporting goods and services, A...</td>\n      <td>0.73</td>\n      <td>0.27</td>\n      <td>0</td>\n      <td>0.694790</td>\n      <td>0.305210</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.985596</td>\n      <td>0.014404</td>\n      <td>0</td>\n      <td>0.994159</td>\n      <td>0.005841</td>\n      <td>0</td>\n      <td>0.999075</td>\n      <td>0.000925</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0</td>\n      <td>There a lot of marriages in Ghana in which wom...</td>\n      <td>0.91</td>\n      <td>0.09</td>\n      <td>0</td>\n      <td>0.516557</td>\n      <td>0.483443</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999959</td>\n      <td>0.000041</td>\n      <td>0</td>\n      <td>0.977965</td>\n      <td>0.022035</td>\n      <td>0</td>\n      <td>0.998708</td>\n      <td>0.001292</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>498 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_false_manual1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:07:43.343253300Z",
     "start_time": "2025-03-13T23:07:43.319960900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl falsch vorhergesagter Tweets (von allen Modelle): 8 / 498 | Anteil:  1.61 %\n",
      "-- davon Label 0: 6\n",
      "-- davon Label 1: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n81             1  Man just wait till the US leaves Afghanistan s...   0.86   \n2              0  Those fucker give true muslims a bad name, kil...   0.22   \n12             0                           Your gf is a whore I bet   0.21   \n15             0  Somebody find me this fucking pussy ass bitch URL   0.29   \n65             0                      Get the fuck out stupid bitch   0.35   \n57             0  You're a retard too so what's one retard repla...   0.23   \n70             1  RT @user: Ô∏èObama swindling future generation...   0.82   \n73             0  do you have autism or something? why do you ta...   0.04   \n\n    1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n81   0.14         0  0.563057  0.436943        0      0      0  ...   \n2    0.78         1  0.255596  0.744404        1      0      0  ...   \n12   0.79         1  0.114762  0.885238        1      0      0  ...   \n15   0.71         1  0.390066  0.609934        1      0      0  ...   \n65   0.65         1  0.292034  0.707966        1      0      0  ...   \n57   0.77         1  0.252714  0.747286        1      0      0  ...   \n70   0.18         0  0.514828  0.485172        0      0      0  ...   \n73   0.96         1  0.392299  0.607701        1      0      0  ...   \n\n    pred_lstm     0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert  \\\n81          0  0.821766  0.178234         0  0.565452  0.434548          0   \n2           1  0.424501  0.575499         1  0.241992  0.758008          1   \n12          1  0.036421  0.963579         1  0.297317  0.702683          1   \n15          1  0.032229  0.967771         1  0.264960  0.735040          1   \n65          1  0.073379  0.926621         1  0.427763  0.572237          1   \n57          1  0.152197  0.847803         1  0.346516  0.653484          1   \n70          0  0.979549  0.020451         0  0.956755  0.043245          0   \n73          1  0.019523  0.980477         1  0.475986  0.524014          1   \n\n       0_rob     1_rob  pred_rob  \n81  0.990371  0.009629         0  \n2   0.036360  0.963640         1  \n12  0.039591  0.960409         1  \n15  0.272777  0.727223         1  \n65  0.441481  0.558519         1  \n57  0.198952  0.801048         1  \n70  0.831532  0.168468         0  \n73  0.047550  0.952450         1  \n\n[8 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>pred_lstm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>81</th>\n      <td>1</td>\n      <td>Man just wait till the US leaves Afghanistan s...</td>\n      <td>0.86</td>\n      <td>0.14</td>\n      <td>0</td>\n      <td>0.563057</td>\n      <td>0.436943</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.821766</td>\n      <td>0.178234</td>\n      <td>0</td>\n      <td>0.565452</td>\n      <td>0.434548</td>\n      <td>0</td>\n      <td>0.990371</td>\n      <td>0.009629</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Those fucker give true muslims a bad name, kil...</td>\n      <td>0.22</td>\n      <td>0.78</td>\n      <td>1</td>\n      <td>0.255596</td>\n      <td>0.744404</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.424501</td>\n      <td>0.575499</td>\n      <td>1</td>\n      <td>0.241992</td>\n      <td>0.758008</td>\n      <td>1</td>\n      <td>0.036360</td>\n      <td>0.963640</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>Your gf is a whore I bet</td>\n      <td>0.21</td>\n      <td>0.79</td>\n      <td>1</td>\n      <td>0.114762</td>\n      <td>0.885238</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.036421</td>\n      <td>0.963579</td>\n      <td>1</td>\n      <td>0.297317</td>\n      <td>0.702683</td>\n      <td>1</td>\n      <td>0.039591</td>\n      <td>0.960409</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>Somebody find me this fucking pussy ass bitch URL</td>\n      <td>0.29</td>\n      <td>0.71</td>\n      <td>1</td>\n      <td>0.390066</td>\n      <td>0.609934</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.032229</td>\n      <td>0.967771</td>\n      <td>1</td>\n      <td>0.264960</td>\n      <td>0.735040</td>\n      <td>1</td>\n      <td>0.272777</td>\n      <td>0.727223</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>0</td>\n      <td>Get the fuck out stupid bitch</td>\n      <td>0.35</td>\n      <td>0.65</td>\n      <td>1</td>\n      <td>0.292034</td>\n      <td>0.707966</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.073379</td>\n      <td>0.926621</td>\n      <td>1</td>\n      <td>0.427763</td>\n      <td>0.572237</td>\n      <td>1</td>\n      <td>0.441481</td>\n      <td>0.558519</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>0</td>\n      <td>You're a retard too so what's one retard repla...</td>\n      <td>0.23</td>\n      <td>0.77</td>\n      <td>1</td>\n      <td>0.252714</td>\n      <td>0.747286</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.152197</td>\n      <td>0.847803</td>\n      <td>1</td>\n      <td>0.346516</td>\n      <td>0.653484</td>\n      <td>1</td>\n      <td>0.198952</td>\n      <td>0.801048</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>1</td>\n      <td>RT @user: Ô∏èObama swindling future generation...</td>\n      <td>0.82</td>\n      <td>0.18</td>\n      <td>0</td>\n      <td>0.514828</td>\n      <td>0.485172</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.979549</td>\n      <td>0.020451</td>\n      <td>0</td>\n      <td>0.956755</td>\n      <td>0.043245</td>\n      <td>0</td>\n      <td>0.831532</td>\n      <td>0.168468</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0</td>\n      <td>do you have autism or something? why do you ta...</td>\n      <td>0.04</td>\n      <td>0.96</td>\n      <td>1</td>\n      <td>0.392299</td>\n      <td>0.607701</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.019523</td>\n      <td>0.980477</td>\n      <td>1</td>\n      <td>0.475986</td>\n      <td>0.524014</td>\n      <td>1</td>\n      <td>0.047550</td>\n      <td>0.952450</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_false_merged_manual1 = get_all_false_merged(merged_false_manual1, label_col=\"label_manual\")\n",
    "all_false_merged_manual1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:07:43.401537Z",
     "start_time": "2025-03-13T23:07:43.338248800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl falsch vorhergesagter Tweets (4/7 Modelle falsch): 81 / 498 | Anteil:  16.27 %\n",
      "-- davon Label 0: 42\n",
      "-- davon Label 1: 39\n",
      "Modelle:\n",
      "-- Ensemble: \t 67 / 81  -  82.72 %\n",
      "-- NB: \t\t\t 48 / 81  -  59.26 %\n",
      "-- SVM: \t\t 59 / 81  -  72.84 %\n",
      "-- GRU: \t\t 52 / 81  -  64.2 %\n",
      "-- LSTM: \t\t 62 / 81  -  76.54 %\n",
      "-- BERT: \t\t 57 / 81  -  70.37 %\n",
      "-- ROBERTA: \t 35 / 81  -  43.21 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n10             1  Close your fucking legs, hoe. Use birth contro...   0.60   \n11             1  @user @user Please take away their license to ...   0.70   \n23             1  My God look at these BARBARIC PPL. And these p...   0.93   \n81             1  Man just wait till the US leaves Afghanistan s...   0.86   \n21             0  unironic incel parties will start to form. no ...   0.75   \n..           ...                                                ...    ...   \n60             1       This is what happens when you let gays Marry   0.92   \n77             0  Never ask your gay friends to hide their ident...   0.18   \n84             0  I'm delighted no one should bye anything from ...   0.67   \n85             0  John Marksman wtf she's a little girl. Fucking...   0.18   \n94             0  You want genocide? Cause this is how genocide ...   0.61   \n\n    1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...     0_gru  \\\n10   0.40         0  0.527259  0.472741        0      0      0  ...  0.006292   \n11   0.30         0  0.450629  0.549371        1      0      0  ...  0.997577   \n23   0.07         0  0.376031  0.623969        1      0      0  ...  0.942953   \n81   0.14         0  0.563057  0.436943        0      0      0  ...  0.821766   \n21   0.25         0  0.556272  0.443728        0      0      0  ...  0.036047   \n..    ...       ...       ...       ...      ...    ...    ...  ...       ...   \n60   0.08         0  0.426424  0.573576        1      0      0  ...  0.998126   \n77   0.82         1  0.451460  0.548540        1      0      0  ...  0.128082   \n84   0.33         0  0.302098  0.697902        1      0      0  ...  0.241194   \n85   0.82         1  0.263713  0.736287        1      0      0  ...  0.288606   \n94   0.39         0  0.319353  0.680647        1      0      0  ...  0.306345   \n\n       1_gru  pred_gru    0_bert    1_bert  pred_bert     0_rob     1_rob  \\\n10  0.993708         1  0.713035  0.286965          0  0.158761  0.841239   \n11  0.002423         0  0.865542  0.134458          0  0.961045  0.038955   \n23  0.057047         0  0.188737  0.811263          1  0.013796  0.986204   \n81  0.178234         0  0.565452  0.434548          0  0.990371  0.009629   \n21  0.963953         1  0.194741  0.805259          1  0.442455  0.557545   \n..       ...       ...       ...       ...        ...       ...       ...   \n60  0.001874         0  0.358095  0.641905          1  0.985978  0.014022   \n77  0.871918         1  0.356391  0.643609          1  0.990366  0.009634   \n84  0.758806         1  0.571151  0.428849          0  0.606780  0.393220   \n85  0.711394         1  0.588637  0.411363          0  0.932846  0.067154   \n94  0.693655         1  0.525672  0.474328          0  0.667509  0.332491   \n\n    pred_rob  preds  \n10         1      3  \n11         0      2  \n23         1      4  \n81         0      0  \n21         1      4  \n..       ...    ...  \n60         0      2  \n77         0      6  \n84         0      4  \n85         0      5  \n94         0      4  \n\n[81 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>Close your fucking legs, hoe. Use birth contro...</td>\n      <td>0.60</td>\n      <td>0.40</td>\n      <td>0</td>\n      <td>0.527259</td>\n      <td>0.472741</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.006292</td>\n      <td>0.993708</td>\n      <td>1</td>\n      <td>0.713035</td>\n      <td>0.286965</td>\n      <td>0</td>\n      <td>0.158761</td>\n      <td>0.841239</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>@user @user Please take away their license to ...</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>0.450629</td>\n      <td>0.549371</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.997577</td>\n      <td>0.002423</td>\n      <td>0</td>\n      <td>0.865542</td>\n      <td>0.134458</td>\n      <td>0</td>\n      <td>0.961045</td>\n      <td>0.038955</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1</td>\n      <td>My God look at these BARBARIC PPL. And these p...</td>\n      <td>0.93</td>\n      <td>0.07</td>\n      <td>0</td>\n      <td>0.376031</td>\n      <td>0.623969</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.942953</td>\n      <td>0.057047</td>\n      <td>0</td>\n      <td>0.188737</td>\n      <td>0.811263</td>\n      <td>1</td>\n      <td>0.013796</td>\n      <td>0.986204</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>1</td>\n      <td>Man just wait till the US leaves Afghanistan s...</td>\n      <td>0.86</td>\n      <td>0.14</td>\n      <td>0</td>\n      <td>0.563057</td>\n      <td>0.436943</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.821766</td>\n      <td>0.178234</td>\n      <td>0</td>\n      <td>0.565452</td>\n      <td>0.434548</td>\n      <td>0</td>\n      <td>0.990371</td>\n      <td>0.009629</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>unironic incel parties will start to form. no ...</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0</td>\n      <td>0.556272</td>\n      <td>0.443728</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.036047</td>\n      <td>0.963953</td>\n      <td>1</td>\n      <td>0.194741</td>\n      <td>0.805259</td>\n      <td>1</td>\n      <td>0.442455</td>\n      <td>0.557545</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>1</td>\n      <td>This is what happens when you let gays Marry</td>\n      <td>0.92</td>\n      <td>0.08</td>\n      <td>0</td>\n      <td>0.426424</td>\n      <td>0.573576</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.998126</td>\n      <td>0.001874</td>\n      <td>0</td>\n      <td>0.358095</td>\n      <td>0.641905</td>\n      <td>1</td>\n      <td>0.985978</td>\n      <td>0.014022</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0</td>\n      <td>Never ask your gay friends to hide their ident...</td>\n      <td>0.18</td>\n      <td>0.82</td>\n      <td>1</td>\n      <td>0.451460</td>\n      <td>0.548540</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.128082</td>\n      <td>0.871918</td>\n      <td>1</td>\n      <td>0.356391</td>\n      <td>0.643609</td>\n      <td>1</td>\n      <td>0.990366</td>\n      <td>0.009634</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>0</td>\n      <td>I'm delighted no one should bye anything from ...</td>\n      <td>0.67</td>\n      <td>0.33</td>\n      <td>0</td>\n      <td>0.302098</td>\n      <td>0.697902</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.241194</td>\n      <td>0.758806</td>\n      <td>1</td>\n      <td>0.571151</td>\n      <td>0.428849</td>\n      <td>0</td>\n      <td>0.606780</td>\n      <td>0.393220</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>0</td>\n      <td>John Marksman wtf she's a little girl. Fucking...</td>\n      <td>0.18</td>\n      <td>0.82</td>\n      <td>1</td>\n      <td>0.263713</td>\n      <td>0.736287</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.288606</td>\n      <td>0.711394</td>\n      <td>1</td>\n      <td>0.588637</td>\n      <td>0.411363</td>\n      <td>0</td>\n      <td>0.932846</td>\n      <td>0.067154</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0</td>\n      <td>You want genocide? Cause this is how genocide ...</td>\n      <td>0.61</td>\n      <td>0.39</td>\n      <td>0</td>\n      <td>0.319353</td>\n      <td>0.680647</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.306345</td>\n      <td>0.693655</td>\n      <td>1</td>\n      <td>0.525672</td>\n      <td>0.474328</td>\n      <td>0</td>\n      <td>0.667509</td>\n      <td>0.332491</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostly_false_merged_manual1 = get_mostly_false_merged(merged_false_manual1, label_col=\"label_manual\")\n",
    "mostly_false_merged_manual1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:07:43.467596300Z",
     "start_time": "2025-03-13T23:07:43.356605900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "merged_false_manual1.to_csv(\"evaluation_data/merged_false_manual1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:07:44.190140900Z",
     "start_time": "2025-03-13T23:07:44.185214400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 manuell gelabelte Tweets (new) - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:01:07 (h:mm:ss)\n",
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:01:06 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "merged_false_manual2 = create_false_tweet_df(tweet_col=\"tweet\", label_col=\"label_manual\",\n",
    "                                             original_df=df_mixed_manual_uncleaned_new,\n",
    "                                             threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:10:00.662176900Z",
     "start_time": "2025-03-13T23:07:44.191141900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n0              1              Post the shit or kill yourself faggot   0.06   \n2              1  i hate jews so much i wish the holocaust actua...   0.16   \n3              1  Poor kid would have been better off with his h...   0.48   \n10             1  Close your fucking legs, hoe. Use birth contro...   0.60   \n11             1  @user @user Please take away their license to ...   0.70   \n..           ...                                                ...    ...   \n94             0  You want genocide? Cause this is how genocide ...   0.61   \n95             0                        The black girl is gorgeous.   0.83   \n96             0  God help us Africans have mercy on us in the n...   0.95   \n97             0  India not only exporting goods and services, A...   0.73   \n98             0  There a lot of marriages in Ghana in which wom...   0.91   \n\n    1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n0    0.94         1  0.104995  0.895005        1      0      0  ...   \n2    0.84         1  0.273041  0.726959        1      0      0  ...   \n3    0.52         1  0.343098  0.656902        1      0      0  ...   \n10   0.40         1  0.527259  0.472741        1      0      0  ...   \n11   0.30         0  0.450629  0.549371        1      0      0  ...   \n..    ...       ...       ...       ...      ...    ...    ...  ...   \n94   0.39         1  0.319353  0.680647        1      0      0  ...   \n95   0.17         0  0.466069  0.533931        1      0      0  ...   \n96   0.05         0  0.462962  0.537038        1      0      0  ...   \n97   0.27         0  0.694790  0.305210        0      0      0  ...   \n98   0.09         0  0.516557  0.483443        1      0      0  ...   \n\n    pred_lstm     0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert  \\\n0           1  0.011137  0.988863         1  0.180920  0.819080          1   \n2           1  0.195016  0.804984         1  0.512623  0.487377          1   \n3           1  0.036294  0.963706         1  0.157057  0.842943          1   \n10          1  0.006292  0.993708         1  0.713035  0.286965          0   \n11          0  0.997577  0.002423         0  0.865542  0.134458          0   \n..        ...       ...       ...       ...       ...       ...        ...   \n94          1  0.306345  0.693655         1  0.525672  0.474328          1   \n95          0  0.999834  0.000166         0  0.951984  0.048016          0   \n96          0  0.996012  0.003988         0  0.994697  0.005303          0   \n97          0  0.985596  0.014404         0  0.994159  0.005841          0   \n98          0  0.999959  0.000041         0  0.977965  0.022035          0   \n\n       0_rob     1_rob  pred_rob  \n0   0.192266  0.807734         1  \n2   0.023317  0.976683         1  \n3   0.221822  0.778178         1  \n10  0.158761  0.841239         1  \n11  0.961045  0.038955         0  \n..       ...       ...       ...  \n94  0.667509  0.332491         0  \n95  0.999379  0.000621         0  \n96  0.999194  0.000806         0  \n97  0.999075  0.000925         0  \n98  0.998708  0.001292         0  \n\n[498 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>pred_lstm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Post the shit or kill yourself faggot</td>\n      <td>0.06</td>\n      <td>0.94</td>\n      <td>1</td>\n      <td>0.104995</td>\n      <td>0.895005</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.011137</td>\n      <td>0.988863</td>\n      <td>1</td>\n      <td>0.180920</td>\n      <td>0.819080</td>\n      <td>1</td>\n      <td>0.192266</td>\n      <td>0.807734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>i hate jews so much i wish the holocaust actua...</td>\n      <td>0.16</td>\n      <td>0.84</td>\n      <td>1</td>\n      <td>0.273041</td>\n      <td>0.726959</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.195016</td>\n      <td>0.804984</td>\n      <td>1</td>\n      <td>0.512623</td>\n      <td>0.487377</td>\n      <td>1</td>\n      <td>0.023317</td>\n      <td>0.976683</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Poor kid would have been better off with his h...</td>\n      <td>0.48</td>\n      <td>0.52</td>\n      <td>1</td>\n      <td>0.343098</td>\n      <td>0.656902</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.036294</td>\n      <td>0.963706</td>\n      <td>1</td>\n      <td>0.157057</td>\n      <td>0.842943</td>\n      <td>1</td>\n      <td>0.221822</td>\n      <td>0.778178</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>Close your fucking legs, hoe. Use birth contro...</td>\n      <td>0.60</td>\n      <td>0.40</td>\n      <td>1</td>\n      <td>0.527259</td>\n      <td>0.472741</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.006292</td>\n      <td>0.993708</td>\n      <td>1</td>\n      <td>0.713035</td>\n      <td>0.286965</td>\n      <td>0</td>\n      <td>0.158761</td>\n      <td>0.841239</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>@user @user Please take away their license to ...</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>0.450629</td>\n      <td>0.549371</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.997577</td>\n      <td>0.002423</td>\n      <td>0</td>\n      <td>0.865542</td>\n      <td>0.134458</td>\n      <td>0</td>\n      <td>0.961045</td>\n      <td>0.038955</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0</td>\n      <td>You want genocide? Cause this is how genocide ...</td>\n      <td>0.61</td>\n      <td>0.39</td>\n      <td>1</td>\n      <td>0.319353</td>\n      <td>0.680647</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.306345</td>\n      <td>0.693655</td>\n      <td>1</td>\n      <td>0.525672</td>\n      <td>0.474328</td>\n      <td>1</td>\n      <td>0.667509</td>\n      <td>0.332491</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>The black girl is gorgeous.</td>\n      <td>0.83</td>\n      <td>0.17</td>\n      <td>0</td>\n      <td>0.466069</td>\n      <td>0.533931</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999834</td>\n      <td>0.000166</td>\n      <td>0</td>\n      <td>0.951984</td>\n      <td>0.048016</td>\n      <td>0</td>\n      <td>0.999379</td>\n      <td>0.000621</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0</td>\n      <td>God help us Africans have mercy on us in the n...</td>\n      <td>0.95</td>\n      <td>0.05</td>\n      <td>0</td>\n      <td>0.462962</td>\n      <td>0.537038</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.996012</td>\n      <td>0.003988</td>\n      <td>0</td>\n      <td>0.994697</td>\n      <td>0.005303</td>\n      <td>0</td>\n      <td>0.999194</td>\n      <td>0.000806</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>India not only exporting goods and services, A...</td>\n      <td>0.73</td>\n      <td>0.27</td>\n      <td>0</td>\n      <td>0.694790</td>\n      <td>0.305210</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.985596</td>\n      <td>0.014404</td>\n      <td>0</td>\n      <td>0.994159</td>\n      <td>0.005841</td>\n      <td>0</td>\n      <td>0.999075</td>\n      <td>0.000925</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0</td>\n      <td>There a lot of marriages in Ghana in which wom...</td>\n      <td>0.91</td>\n      <td>0.09</td>\n      <td>0</td>\n      <td>0.516557</td>\n      <td>0.483443</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999959</td>\n      <td>0.000041</td>\n      <td>0</td>\n      <td>0.977965</td>\n      <td>0.022035</td>\n      <td>0</td>\n      <td>0.998708</td>\n      <td>0.001292</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>498 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_false_manual2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:10:00.677676700Z",
     "start_time": "2025-03-13T23:10:00.657173600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl falsch vorhergesagter Tweets (von allen Modelle): 8 / 498 | Anteil:  1.61 %\n",
      "-- davon Label 0: 8\n",
      "-- davon Label 1: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n66             0  RT @user: We Muslims have no military honour w...   0.46   \n2              0  Those fucker give true muslims a bad name, kil...   0.22   \n12             0                           Your gf is a whore I bet   0.21   \n15             0  Somebody find me this fucking pussy ass bitch URL   0.29   \n65             0                      Get the fuck out stupid bitch   0.35   \n74             0  RT @user: Wat type of bitch ass nigga rape a i...   0.38   \n57             0  You're a retard too so what's one retard repla...   0.23   \n73             0  do you have autism or something? why do you ta...   0.04   \n\n    1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n66   0.54         1  0.214399  0.785601        1      0      0  ...   \n2    0.78         1  0.255596  0.744404        1      0      0  ...   \n12   0.79         1  0.114762  0.885238        1      0      0  ...   \n15   0.71         1  0.390066  0.609934        1      0      0  ...   \n65   0.65         1  0.292034  0.707966        1      0      0  ...   \n74   0.62         1  0.450220  0.549780        1      0      0  ...   \n57   0.77         1  0.252714  0.747286        1      0      0  ...   \n73   0.96         1  0.392299  0.607701        1      0      0  ...   \n\n    pred_lstm     0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert  \\\n66          1  0.006515  0.993485         1  0.596255  0.403745          1   \n2           1  0.424501  0.575499         1  0.241992  0.758008          1   \n12          1  0.036421  0.963579         1  0.297317  0.702683          1   \n15          1  0.032229  0.967771         1  0.264960  0.735040          1   \n65          1  0.073379  0.926621         1  0.427763  0.572237          1   \n74          1  0.505137  0.494863         1  0.359640  0.640360          1   \n57          1  0.152197  0.847803         1  0.346516  0.653484          1   \n73          1  0.019523  0.980477         1  0.475986  0.524014          1   \n\n       0_rob     1_rob  pred_rob  \n66  0.008101  0.991899         1  \n2   0.036360  0.963640         1  \n12  0.039591  0.960409         1  \n15  0.272777  0.727223         1  \n65  0.441481  0.558519         1  \n74  0.085985  0.914015         1  \n57  0.198952  0.801048         1  \n73  0.047550  0.952450         1  \n\n[8 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>pred_lstm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>66</th>\n      <td>0</td>\n      <td>RT @user: We Muslims have no military honour w...</td>\n      <td>0.46</td>\n      <td>0.54</td>\n      <td>1</td>\n      <td>0.214399</td>\n      <td>0.785601</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.006515</td>\n      <td>0.993485</td>\n      <td>1</td>\n      <td>0.596255</td>\n      <td>0.403745</td>\n      <td>1</td>\n      <td>0.008101</td>\n      <td>0.991899</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Those fucker give true muslims a bad name, kil...</td>\n      <td>0.22</td>\n      <td>0.78</td>\n      <td>1</td>\n      <td>0.255596</td>\n      <td>0.744404</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.424501</td>\n      <td>0.575499</td>\n      <td>1</td>\n      <td>0.241992</td>\n      <td>0.758008</td>\n      <td>1</td>\n      <td>0.036360</td>\n      <td>0.963640</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>Your gf is a whore I bet</td>\n      <td>0.21</td>\n      <td>0.79</td>\n      <td>1</td>\n      <td>0.114762</td>\n      <td>0.885238</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.036421</td>\n      <td>0.963579</td>\n      <td>1</td>\n      <td>0.297317</td>\n      <td>0.702683</td>\n      <td>1</td>\n      <td>0.039591</td>\n      <td>0.960409</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>Somebody find me this fucking pussy ass bitch URL</td>\n      <td>0.29</td>\n      <td>0.71</td>\n      <td>1</td>\n      <td>0.390066</td>\n      <td>0.609934</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.032229</td>\n      <td>0.967771</td>\n      <td>1</td>\n      <td>0.264960</td>\n      <td>0.735040</td>\n      <td>1</td>\n      <td>0.272777</td>\n      <td>0.727223</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>0</td>\n      <td>Get the fuck out stupid bitch</td>\n      <td>0.35</td>\n      <td>0.65</td>\n      <td>1</td>\n      <td>0.292034</td>\n      <td>0.707966</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.073379</td>\n      <td>0.926621</td>\n      <td>1</td>\n      <td>0.427763</td>\n      <td>0.572237</td>\n      <td>1</td>\n      <td>0.441481</td>\n      <td>0.558519</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0</td>\n      <td>RT @user: Wat type of bitch ass nigga rape a i...</td>\n      <td>0.38</td>\n      <td>0.62</td>\n      <td>1</td>\n      <td>0.450220</td>\n      <td>0.549780</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.505137</td>\n      <td>0.494863</td>\n      <td>1</td>\n      <td>0.359640</td>\n      <td>0.640360</td>\n      <td>1</td>\n      <td>0.085985</td>\n      <td>0.914015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>0</td>\n      <td>You're a retard too so what's one retard repla...</td>\n      <td>0.23</td>\n      <td>0.77</td>\n      <td>1</td>\n      <td>0.252714</td>\n      <td>0.747286</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.152197</td>\n      <td>0.847803</td>\n      <td>1</td>\n      <td>0.346516</td>\n      <td>0.653484</td>\n      <td>1</td>\n      <td>0.198952</td>\n      <td>0.801048</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0</td>\n      <td>do you have autism or something? why do you ta...</td>\n      <td>0.04</td>\n      <td>0.96</td>\n      <td>1</td>\n      <td>0.392299</td>\n      <td>0.607701</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.019523</td>\n      <td>0.980477</td>\n      <td>1</td>\n      <td>0.475986</td>\n      <td>0.524014</td>\n      <td>1</td>\n      <td>0.047550</td>\n      <td>0.952450</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_false_merged_manual2 = get_all_false_merged(merged_false_manual2, label_col=\"label_manual\")\n",
    "all_false_merged_manual2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:10:00.734348600Z",
     "start_time": "2025-03-13T23:10:00.673673600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl falsch vorhergesagter Tweets (4/7 Modelle falsch): 87 / 498 | Anteil:  17.47 %\n",
      "-- davon Label 0: 57\n",
      "-- davon Label 1: 30\n",
      "Modelle:\n",
      "-- Ensemble: \t 67 / 87  -  77.01 %\n",
      "-- NB: \t\t\t 59 / 87  -  67.82 %\n",
      "-- SVM: \t\t 58 / 87  -  66.67 %\n",
      "-- GRU: \t\t 59 / 87  -  67.82 %\n",
      "-- LSTM: \t\t 69 / 87  -  79.31 %\n",
      "-- BERT: \t\t 64 / 87  -  73.56 %\n",
      "-- ROBERTA: \t 37 / 87  -  42.53 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n11             1  @user @user Please take away their license to ...   0.70   \n23             1  My God look at these BARBARIC PPL. And these p...   0.93   \n81             1  Man just wait till the US leaves Afghanistan s...   0.86   \n16             0  illegal immigrants =/= legal immigrants. in ev...   0.59   \n21             0  unironic incel parties will start to form. no ...   0.75   \n..           ...                                                ...    ...   \n60             1       This is what happens when you let gays Marry   0.92   \n77             0  Never ask your gay friends to hide their ident...   0.18   \n84             0  I'm delighted no one should bye anything from ...   0.67   \n85             0  John Marksman wtf she's a little girl. Fucking...   0.18   \n94             0  You want genocide? Cause this is how genocide ...   0.61   \n\n    1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...     0_gru  \\\n11   0.30         0  0.450629  0.549371        1      0      0  ...  0.997577   \n23   0.07         0  0.376031  0.623969        1      0      0  ...  0.942953   \n81   0.14         0  0.563057  0.436943        1      0      0  ...  0.821766   \n16   0.41         1  0.398594  0.601406        1      0      0  ...  0.497590   \n21   0.25         0  0.556272  0.443728        1      0      0  ...  0.036047   \n..    ...       ...       ...       ...      ...    ...    ...  ...       ...   \n60   0.08         0  0.426424  0.573576        1      0      0  ...  0.998126   \n77   0.82         1  0.451460  0.548540        1      0      0  ...  0.128082   \n84   0.33         0  0.302098  0.697902        1      0      0  ...  0.241194   \n85   0.82         1  0.263713  0.736287        1      0      0  ...  0.288606   \n94   0.39         1  0.319353  0.680647        1      0      0  ...  0.306345   \n\n       1_gru  pred_gru    0_bert    1_bert  pred_bert     0_rob     1_rob  \\\n11  0.002423         0  0.865542  0.134458          0  0.961045  0.038955   \n23  0.057047         0  0.188737  0.811263          1  0.013796  0.986204   \n81  0.178234         0  0.565452  0.434548          1  0.990371  0.009629   \n16  0.502410         1  0.780791  0.219209          0  0.975723  0.024277   \n21  0.963953         1  0.194741  0.805259          1  0.442455  0.557545   \n..       ...       ...       ...       ...        ...       ...       ...   \n60  0.001874         0  0.358095  0.641905          1  0.985978  0.014022   \n77  0.871918         1  0.356391  0.643609          1  0.990366  0.009634   \n84  0.758806         1  0.571151  0.428849          1  0.606780  0.393220   \n85  0.711394         1  0.588637  0.411363          1  0.932846  0.067154   \n94  0.693655         1  0.525672  0.474328          1  0.667509  0.332491   \n\n    pred_rob  preds  \n11         0      2  \n23         1      4  \n81         0      2  \n16         0      4  \n21         1      5  \n..       ...    ...  \n60         0      2  \n77         0      6  \n84         1      6  \n85         0      6  \n94         0      6  \n\n[87 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>@user @user Please take away their license to ...</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>0.450629</td>\n      <td>0.549371</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.997577</td>\n      <td>0.002423</td>\n      <td>0</td>\n      <td>0.865542</td>\n      <td>0.134458</td>\n      <td>0</td>\n      <td>0.961045</td>\n      <td>0.038955</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1</td>\n      <td>My God look at these BARBARIC PPL. And these p...</td>\n      <td>0.93</td>\n      <td>0.07</td>\n      <td>0</td>\n      <td>0.376031</td>\n      <td>0.623969</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.942953</td>\n      <td>0.057047</td>\n      <td>0</td>\n      <td>0.188737</td>\n      <td>0.811263</td>\n      <td>1</td>\n      <td>0.013796</td>\n      <td>0.986204</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>1</td>\n      <td>Man just wait till the US leaves Afghanistan s...</td>\n      <td>0.86</td>\n      <td>0.14</td>\n      <td>0</td>\n      <td>0.563057</td>\n      <td>0.436943</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.821766</td>\n      <td>0.178234</td>\n      <td>0</td>\n      <td>0.565452</td>\n      <td>0.434548</td>\n      <td>1</td>\n      <td>0.990371</td>\n      <td>0.009629</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>illegal immigrants =/= legal immigrants. in ev...</td>\n      <td>0.59</td>\n      <td>0.41</td>\n      <td>1</td>\n      <td>0.398594</td>\n      <td>0.601406</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.497590</td>\n      <td>0.502410</td>\n      <td>1</td>\n      <td>0.780791</td>\n      <td>0.219209</td>\n      <td>0</td>\n      <td>0.975723</td>\n      <td>0.024277</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>unironic incel parties will start to form. no ...</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0</td>\n      <td>0.556272</td>\n      <td>0.443728</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.036047</td>\n      <td>0.963953</td>\n      <td>1</td>\n      <td>0.194741</td>\n      <td>0.805259</td>\n      <td>1</td>\n      <td>0.442455</td>\n      <td>0.557545</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>1</td>\n      <td>This is what happens when you let gays Marry</td>\n      <td>0.92</td>\n      <td>0.08</td>\n      <td>0</td>\n      <td>0.426424</td>\n      <td>0.573576</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.998126</td>\n      <td>0.001874</td>\n      <td>0</td>\n      <td>0.358095</td>\n      <td>0.641905</td>\n      <td>1</td>\n      <td>0.985978</td>\n      <td>0.014022</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0</td>\n      <td>Never ask your gay friends to hide their ident...</td>\n      <td>0.18</td>\n      <td>0.82</td>\n      <td>1</td>\n      <td>0.451460</td>\n      <td>0.548540</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.128082</td>\n      <td>0.871918</td>\n      <td>1</td>\n      <td>0.356391</td>\n      <td>0.643609</td>\n      <td>1</td>\n      <td>0.990366</td>\n      <td>0.009634</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>0</td>\n      <td>I'm delighted no one should bye anything from ...</td>\n      <td>0.67</td>\n      <td>0.33</td>\n      <td>0</td>\n      <td>0.302098</td>\n      <td>0.697902</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.241194</td>\n      <td>0.758806</td>\n      <td>1</td>\n      <td>0.571151</td>\n      <td>0.428849</td>\n      <td>1</td>\n      <td>0.606780</td>\n      <td>0.393220</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>0</td>\n      <td>John Marksman wtf she's a little girl. Fucking...</td>\n      <td>0.18</td>\n      <td>0.82</td>\n      <td>1</td>\n      <td>0.263713</td>\n      <td>0.736287</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.288606</td>\n      <td>0.711394</td>\n      <td>1</td>\n      <td>0.588637</td>\n      <td>0.411363</td>\n      <td>1</td>\n      <td>0.932846</td>\n      <td>0.067154</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0</td>\n      <td>You want genocide? Cause this is how genocide ...</td>\n      <td>0.61</td>\n      <td>0.39</td>\n      <td>1</td>\n      <td>0.319353</td>\n      <td>0.680647</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.306345</td>\n      <td>0.693655</td>\n      <td>1</td>\n      <td>0.525672</td>\n      <td>0.474328</td>\n      <td>1</td>\n      <td>0.667509</td>\n      <td>0.332491</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>87 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostly_false_merged_manual2 = get_mostly_false_merged(merged_false_manual2, label_col=\"label_manual\")\n",
    "mostly_false_merged_manual2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:10:00.762373800Z",
     "start_time": "2025-03-13T23:10:00.694925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "merged_false_manual2.to_csv(\"evaluation_data/merged_false_manual2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T23:10:01.961121400Z",
     "start_time": "2025-03-13T23:10:01.953568400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3 Mixed-Test cleaned - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1015/1015\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 7ms/step\n",
      "\u001B[1m1015/1015\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 1:19:42 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 1:15:56 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "merged_false_tweet_cleaned1 = create_false_tweet_df(tweet_col=\"tweet_cleaned\", label_col=\"label\",\n",
    "                                                    original_df=df_mixed_test_cleaned,\n",
    "                                                    threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T10:43:00.052403Z",
     "start_time": "2025-03-15T08:05:10.765094300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "        label                                      tweet_cleaned  0_ens  \\\n8886        0       final gear evening butterfly stage hope like   0.75   \n27613       0           amazing weather musical london weekend …   1.00   \n18952       0                child attack alligator disney world   0.81   \n12485       0                            right cause school soon   0.70   \n5879        0                              good sleep good sleep   0.83   \n...       ...                                                ...    ...   \n176360      0  even liberal humiliate charlie claim gop back ...   0.69   \n176366      0                                      photoshop nig   0.71   \n176384      0            mad hoe ask beavis get nothing butthead   0.78   \n176385      0  child concentration camp bad enough trump admi...   0.64   \n176387      1         recognize irony use method ignorant muslim   0.14   \n\n        1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n8886     0.25         0  0.836110  0.163890        0      0      0  ...   \n27613    0.00         0  0.991430  0.008570        0      0      0  ...   \n18952    0.19         0  0.825607  0.174393        0      0      0  ...   \n12485    0.30         0  0.592160  0.407840        0      0      0  ...   \n5879     0.17         0  0.649481  0.350519        0      0      0  ...   \n...       ...       ...       ...       ...      ...    ...    ...  ...   \n176360   0.31         0  0.548318  0.451682        0      0      0  ...   \n176366   0.29         0  0.363628  0.636372        1      0      0  ...   \n176384   0.22         0  0.473839  0.526161        1      0      0  ...   \n176385   0.36         0  0.624282  0.375718        0      0      0  ...   \n176387   0.86         1  0.280625  0.719375        1      0      0  ...   \n\n        pred_lstm     0_gru     1_gru  pred_gru    0_bert    1_bert  \\\n8886            0  0.999995  0.000005         0  0.998820  0.001180   \n27613           0  0.999929  0.000071         0  0.998384  0.001616   \n18952           0  0.924563  0.075437         0  0.985559  0.014441   \n12485           0  0.995754  0.004246         0  0.917947  0.082052   \n5879            0  0.999758  0.000242         0  0.996236  0.003764   \n...           ...       ...       ...       ...       ...       ...   \n176360          1  0.896264  0.103736         0  0.274048  0.725952   \n176366          1  0.990894  0.009106         0  0.943315  0.056685   \n176384          1  0.998860  0.001140         0  0.350978  0.649022   \n176385          0  0.887528  0.112472         0  0.927335  0.072665   \n176387          1  0.698190  0.301810         0  0.258612  0.741388   \n\n        pred_bert     0_rob     1_rob  pred_rob  \n8886            0  0.999381  0.000619         0  \n27613           0  0.999394  0.000606         0  \n18952           0  0.999216  0.000784         0  \n12485           0  0.996966  0.003034         0  \n5879            0  0.997868  0.002132         0  \n...           ...       ...       ...       ...  \n176360          1  0.904447  0.095553         0  \n176366          0  0.976689  0.023311         0  \n176384          1  0.997482  0.002518         0  \n176385          0  0.981390  0.018610         0  \n176387          1  0.036071  0.963929         1  \n\n[32466 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet_cleaned</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>pred_lstm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8886</th>\n      <td>0</td>\n      <td>final gear evening butterfly stage hope like</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0</td>\n      <td>0.836110</td>\n      <td>0.163890</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999995</td>\n      <td>0.000005</td>\n      <td>0</td>\n      <td>0.998820</td>\n      <td>0.001180</td>\n      <td>0</td>\n      <td>0.999381</td>\n      <td>0.000619</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27613</th>\n      <td>0</td>\n      <td>amazing weather musical london weekend …</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0.991430</td>\n      <td>0.008570</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999929</td>\n      <td>0.000071</td>\n      <td>0</td>\n      <td>0.998384</td>\n      <td>0.001616</td>\n      <td>0</td>\n      <td>0.999394</td>\n      <td>0.000606</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18952</th>\n      <td>0</td>\n      <td>child attack alligator disney world</td>\n      <td>0.81</td>\n      <td>0.19</td>\n      <td>0</td>\n      <td>0.825607</td>\n      <td>0.174393</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.924563</td>\n      <td>0.075437</td>\n      <td>0</td>\n      <td>0.985559</td>\n      <td>0.014441</td>\n      <td>0</td>\n      <td>0.999216</td>\n      <td>0.000784</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12485</th>\n      <td>0</td>\n      <td>right cause school soon</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>0.592160</td>\n      <td>0.407840</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.995754</td>\n      <td>0.004246</td>\n      <td>0</td>\n      <td>0.917947</td>\n      <td>0.082052</td>\n      <td>0</td>\n      <td>0.996966</td>\n      <td>0.003034</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5879</th>\n      <td>0</td>\n      <td>good sleep good sleep</td>\n      <td>0.83</td>\n      <td>0.17</td>\n      <td>0</td>\n      <td>0.649481</td>\n      <td>0.350519</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999758</td>\n      <td>0.000242</td>\n      <td>0</td>\n      <td>0.996236</td>\n      <td>0.003764</td>\n      <td>0</td>\n      <td>0.997868</td>\n      <td>0.002132</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176360</th>\n      <td>0</td>\n      <td>even liberal humiliate charlie claim gop back ...</td>\n      <td>0.69</td>\n      <td>0.31</td>\n      <td>0</td>\n      <td>0.548318</td>\n      <td>0.451682</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.896264</td>\n      <td>0.103736</td>\n      <td>0</td>\n      <td>0.274048</td>\n      <td>0.725952</td>\n      <td>1</td>\n      <td>0.904447</td>\n      <td>0.095553</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176366</th>\n      <td>0</td>\n      <td>photoshop nig</td>\n      <td>0.71</td>\n      <td>0.29</td>\n      <td>0</td>\n      <td>0.363628</td>\n      <td>0.636372</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.990894</td>\n      <td>0.009106</td>\n      <td>0</td>\n      <td>0.943315</td>\n      <td>0.056685</td>\n      <td>0</td>\n      <td>0.976689</td>\n      <td>0.023311</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176384</th>\n      <td>0</td>\n      <td>mad hoe ask beavis get nothing butthead</td>\n      <td>0.78</td>\n      <td>0.22</td>\n      <td>0</td>\n      <td>0.473839</td>\n      <td>0.526161</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.998860</td>\n      <td>0.001140</td>\n      <td>0</td>\n      <td>0.350978</td>\n      <td>0.649022</td>\n      <td>1</td>\n      <td>0.997482</td>\n      <td>0.002518</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176385</th>\n      <td>0</td>\n      <td>child concentration camp bad enough trump admi...</td>\n      <td>0.64</td>\n      <td>0.36</td>\n      <td>0</td>\n      <td>0.624282</td>\n      <td>0.375718</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.887528</td>\n      <td>0.112472</td>\n      <td>0</td>\n      <td>0.927335</td>\n      <td>0.072665</td>\n      <td>0</td>\n      <td>0.981390</td>\n      <td>0.018610</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176387</th>\n      <td>1</td>\n      <td>recognize irony use method ignorant muslim</td>\n      <td>0.14</td>\n      <td>0.86</td>\n      <td>1</td>\n      <td>0.280625</td>\n      <td>0.719375</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.698190</td>\n      <td>0.301810</td>\n      <td>0</td>\n      <td>0.258612</td>\n      <td>0.741388</td>\n      <td>1</td>\n      <td>0.036071</td>\n      <td>0.963929</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>32466 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_false_tweet_cleaned1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T10:43:00.114917500Z",
     "start_time": "2025-03-15T10:43:00.067418400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl falsch vorhergesagter Tweets (von allen Modelle): 1492 / 32466 | Anteil:  4.6 %\n",
      "-- davon Label 0: 1061\n",
      "-- davon Label 1: 431\n"
     ]
    },
    {
     "data": {
      "text/plain": "        label                                      tweet_cleaned  0_ens  \\\n24456       1  sleep night terrible person sir represent ever...   0.83   \n17424       1                            peek nyc come back holy   0.88   \n5087        1  \" workplace family responsibility add pressure...   0.92   \n21727       1                       note able pop neck day day …   0.92   \n22001       1  ya prince charles - issue warning trump return...   0.61   \n...       ...                                                ...    ...   \n175707      0  drown hypocrisy show empathy woman provide sou...   0.22   \n175755      0                                   pussy ass niggas   0.31   \n176221      0  well woman deserve murder incel never conseque...   0.17   \n176224      1  another subreddit outcome beautiful woman need...   0.81   \n176325      0  retweet way act ugh chief boy nigger absolute ...   0.19   \n\n        1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n24456    0.17         0  0.680407  0.319593        0      0      0  ...   \n17424    0.12         0  0.515980  0.484020        0      0      0  ...   \n5087     0.08         0  0.713795  0.286205        0      0      0  ...   \n21727    0.08         0  0.812397  0.187603        0      0      0  ...   \n22001    0.39         0  0.606323  0.393677        0      0      0  ...   \n...       ...       ...       ...       ...      ...    ...    ...  ...   \n175707   0.78         1  0.357373  0.642627        1      0      0  ...   \n175755   0.69         1  0.255930  0.744070        1      0      0  ...   \n176221   0.83         1  0.201791  0.798209        1      0      0  ...   \n176224   0.19         0  0.670378  0.329622        0      0      0  ...   \n176325   0.81         1  0.260187  0.739813        1      0      0  ...   \n\n        pred_lstm     0_gru     1_gru  pred_gru    0_bert    1_bert  \\\n24456           0  0.961663  0.038337         0  0.957003  0.042997   \n17424           0  0.999588  0.000412         0  0.997054  0.002946   \n5087            0  0.997584  0.002416         0  0.794114  0.205886   \n21727           0  0.994909  0.005091         0  0.998480  0.001520   \n22001           0  0.999924  0.000076         0  0.966566  0.033434   \n...           ...       ...       ...       ...       ...       ...   \n175707          1  0.466319  0.533681         1  0.338639  0.661361   \n175755          1  0.292038  0.707962         1  0.242580  0.757420   \n176221          1  0.168841  0.831159         1  0.283943  0.716057   \n176224          0  0.999822  0.000178         0  0.997102  0.002898   \n176325          1  0.186607  0.813393         1  0.122462  0.877538   \n\n        pred_bert     0_rob     1_rob  pred_rob  \n24456           0  0.995046  0.004954         0  \n17424           0  0.999180  0.000820         0  \n5087            0  0.999021  0.000979         0  \n21727           0  0.999331  0.000669         0  \n22001           0  0.899878  0.100122         0  \n...           ...       ...       ...       ...  \n175707          1  0.133942  0.866058         1  \n175755          1  0.092577  0.907423         1  \n176221          1  0.425188  0.574812         1  \n176224          0  0.999110  0.000890         0  \n176325          1  0.117280  0.882721         1  \n\n[1492 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet_cleaned</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>pred_lstm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24456</th>\n      <td>1</td>\n      <td>sleep night terrible person sir represent ever...</td>\n      <td>0.83</td>\n      <td>0.17</td>\n      <td>0</td>\n      <td>0.680407</td>\n      <td>0.319593</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.961663</td>\n      <td>0.038337</td>\n      <td>0</td>\n      <td>0.957003</td>\n      <td>0.042997</td>\n      <td>0</td>\n      <td>0.995046</td>\n      <td>0.004954</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17424</th>\n      <td>1</td>\n      <td>peek nyc come back holy</td>\n      <td>0.88</td>\n      <td>0.12</td>\n      <td>0</td>\n      <td>0.515980</td>\n      <td>0.484020</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999588</td>\n      <td>0.000412</td>\n      <td>0</td>\n      <td>0.997054</td>\n      <td>0.002946</td>\n      <td>0</td>\n      <td>0.999180</td>\n      <td>0.000820</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5087</th>\n      <td>1</td>\n      <td>\" workplace family responsibility add pressure...</td>\n      <td>0.92</td>\n      <td>0.08</td>\n      <td>0</td>\n      <td>0.713795</td>\n      <td>0.286205</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.997584</td>\n      <td>0.002416</td>\n      <td>0</td>\n      <td>0.794114</td>\n      <td>0.205886</td>\n      <td>0</td>\n      <td>0.999021</td>\n      <td>0.000979</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21727</th>\n      <td>1</td>\n      <td>note able pop neck day day …</td>\n      <td>0.92</td>\n      <td>0.08</td>\n      <td>0</td>\n      <td>0.812397</td>\n      <td>0.187603</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.994909</td>\n      <td>0.005091</td>\n      <td>0</td>\n      <td>0.998480</td>\n      <td>0.001520</td>\n      <td>0</td>\n      <td>0.999331</td>\n      <td>0.000669</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22001</th>\n      <td>1</td>\n      <td>ya prince charles - issue warning trump return...</td>\n      <td>0.61</td>\n      <td>0.39</td>\n      <td>0</td>\n      <td>0.606323</td>\n      <td>0.393677</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999924</td>\n      <td>0.000076</td>\n      <td>0</td>\n      <td>0.966566</td>\n      <td>0.033434</td>\n      <td>0</td>\n      <td>0.899878</td>\n      <td>0.100122</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175707</th>\n      <td>0</td>\n      <td>drown hypocrisy show empathy woman provide sou...</td>\n      <td>0.22</td>\n      <td>0.78</td>\n      <td>1</td>\n      <td>0.357373</td>\n      <td>0.642627</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.466319</td>\n      <td>0.533681</td>\n      <td>1</td>\n      <td>0.338639</td>\n      <td>0.661361</td>\n      <td>1</td>\n      <td>0.133942</td>\n      <td>0.866058</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>175755</th>\n      <td>0</td>\n      <td>pussy ass niggas</td>\n      <td>0.31</td>\n      <td>0.69</td>\n      <td>1</td>\n      <td>0.255930</td>\n      <td>0.744070</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.292038</td>\n      <td>0.707962</td>\n      <td>1</td>\n      <td>0.242580</td>\n      <td>0.757420</td>\n      <td>1</td>\n      <td>0.092577</td>\n      <td>0.907423</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>176221</th>\n      <td>0</td>\n      <td>well woman deserve murder incel never conseque...</td>\n      <td>0.17</td>\n      <td>0.83</td>\n      <td>1</td>\n      <td>0.201791</td>\n      <td>0.798209</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.168841</td>\n      <td>0.831159</td>\n      <td>1</td>\n      <td>0.283943</td>\n      <td>0.716057</td>\n      <td>1</td>\n      <td>0.425188</td>\n      <td>0.574812</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>176224</th>\n      <td>1</td>\n      <td>another subreddit outcome beautiful woman need...</td>\n      <td>0.81</td>\n      <td>0.19</td>\n      <td>0</td>\n      <td>0.670378</td>\n      <td>0.329622</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.999822</td>\n      <td>0.000178</td>\n      <td>0</td>\n      <td>0.997102</td>\n      <td>0.002898</td>\n      <td>0</td>\n      <td>0.999110</td>\n      <td>0.000890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176325</th>\n      <td>0</td>\n      <td>retweet way act ugh chief boy nigger absolute ...</td>\n      <td>0.19</td>\n      <td>0.81</td>\n      <td>1</td>\n      <td>0.260187</td>\n      <td>0.739813</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.186607</td>\n      <td>0.813393</td>\n      <td>1</td>\n      <td>0.122462</td>\n      <td>0.877538</td>\n      <td>1</td>\n      <td>0.117280</td>\n      <td>0.882721</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1492 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_false_merged_tweet_cleaned1 = get_all_false_merged(merged_false_tweet_cleaned1, label_col=\"label\")\n",
    "all_false_merged_tweet_cleaned1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T10:43:00.140936800Z",
     "start_time": "2025-03-15T10:43:00.116919200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl falsch vorhergesagter Tweets (4/7 Modelle falsch): 7648 / 32466 | Anteil:  23.56 %\n",
      "-- davon Label 0: 5198\n",
      "-- davon Label 1: 2450\n",
      "Modelle:\n",
      "-- Ensemble: \t 5919 / 7648  -  77.39 %\n",
      "-- NB: \t\t\t 6099 / 7648  -  79.75 %\n",
      "-- SVM: \t\t 6323 / 7648  -  82.68 %\n",
      "-- GRU: \t\t 5634 / 7648  -  73.67 %\n",
      "-- LSTM: \t\t 6002 / 7648  -  78.48 %\n",
      "-- BERT: \t\t 4942 / 7648  -  64.62 %\n",
      "-- ROBERTA: \t 4306 / 7648  -  56.3 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "        label                                      tweet_cleaned  0_ens  \\\n6640        1            misogyny alive well left never let tell   0.41   \n26538       1     never room school board ever kid school future   0.70   \n13046       0                    oh gosh freaking kill president   0.35   \n24456       1  sleep night terrible person sir represent ever...   0.83   \n168         1          point one finger million point right back   0.54   \n...       ...                                                ...    ...   \n176224      1  another subreddit outcome beautiful woman need...   0.81   \n176252      0  little bitch would masturbate cus nonce stupid...   0.54   \n176287      0  white school teacher back elementary know give...   0.28   \n176290      0                                      kill religion   0.43   \n176325      0  retweet way act ugh chief boy nigger absolute ...   0.19   \n\n        1_ens  pred_ens      0_nb      1_nb  pred_nb  0_svm  1_svm  ...  \\\n6640     0.59         1  0.447158  0.552842        1      0      0  ...   \n26538    0.30         0  0.572453  0.427547        0      0      0  ...   \n13046    0.65         1  0.399097  0.600903        1      0      0  ...   \n24456    0.17         0  0.680407  0.319593        0      0      0  ...   \n168      0.46         0  0.551959  0.448041        0      0      0  ...   \n...       ...       ...       ...       ...      ...    ...    ...  ...   \n176224   0.19         0  0.670378  0.329622        0      0      0  ...   \n176252   0.46         0  0.324064  0.675936        1      0      0  ...   \n176287   0.72         1  0.631280  0.368720        0      0      0  ...   \n176290   0.57         1  0.328023  0.671977        1      0      0  ...   \n176325   0.81         1  0.260187  0.739813        1      0      0  ...   \n\n           0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert     0_rob  \\\n6640    0.900734  0.099266         0  0.658825  0.341175          0  0.985618   \n26538   0.818643  0.181357         0  0.990094  0.009906          0  0.948021   \n13046   0.194005  0.805995         1  0.587686  0.412314          0  0.560537   \n24456   0.961663  0.038337         0  0.957003  0.042997          0  0.995046   \n168     0.230771  0.769229         1  0.870135  0.129865          0  0.998511   \n...          ...       ...       ...       ...       ...        ...       ...   \n176224  0.999822  0.000178         0  0.997102  0.002898          0  0.999110   \n176252  0.085027  0.914973         1  0.589835  0.410165          0  0.827502   \n176287  0.043912  0.956088         1  0.744024  0.255976          0  0.884535   \n176290  0.627487  0.372513         0  0.592711  0.407289          0  0.965532   \n176325  0.186607  0.813393         1  0.122462  0.877538          1  0.117280   \n\n           1_rob  pred_rob  preds  \n6640    0.014382         0      4  \n26538   0.051978         0      1  \n13046   0.439463         0      5  \n24456   0.004954         0      0  \n168     0.001489         0      1  \n...          ...       ...    ...  \n176224  0.000890         0      0  \n176252  0.172498         0      4  \n176287  0.115465         0      4  \n176290  0.034468         0      4  \n176325  0.882721         1      7  \n\n[7648 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet_cleaned</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>...</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6640</th>\n      <td>1</td>\n      <td>misogyny alive well left never let tell</td>\n      <td>0.41</td>\n      <td>0.59</td>\n      <td>1</td>\n      <td>0.447158</td>\n      <td>0.552842</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.900734</td>\n      <td>0.099266</td>\n      <td>0</td>\n      <td>0.658825</td>\n      <td>0.341175</td>\n      <td>0</td>\n      <td>0.985618</td>\n      <td>0.014382</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>26538</th>\n      <td>1</td>\n      <td>never room school board ever kid school future</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>0.572453</td>\n      <td>0.427547</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.818643</td>\n      <td>0.181357</td>\n      <td>0</td>\n      <td>0.990094</td>\n      <td>0.009906</td>\n      <td>0</td>\n      <td>0.948021</td>\n      <td>0.051978</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13046</th>\n      <td>0</td>\n      <td>oh gosh freaking kill president</td>\n      <td>0.35</td>\n      <td>0.65</td>\n      <td>1</td>\n      <td>0.399097</td>\n      <td>0.600903</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.194005</td>\n      <td>0.805995</td>\n      <td>1</td>\n      <td>0.587686</td>\n      <td>0.412314</td>\n      <td>0</td>\n      <td>0.560537</td>\n      <td>0.439463</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>24456</th>\n      <td>1</td>\n      <td>sleep night terrible person sir represent ever...</td>\n      <td>0.83</td>\n      <td>0.17</td>\n      <td>0</td>\n      <td>0.680407</td>\n      <td>0.319593</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.961663</td>\n      <td>0.038337</td>\n      <td>0</td>\n      <td>0.957003</td>\n      <td>0.042997</td>\n      <td>0</td>\n      <td>0.995046</td>\n      <td>0.004954</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>1</td>\n      <td>point one finger million point right back</td>\n      <td>0.54</td>\n      <td>0.46</td>\n      <td>0</td>\n      <td>0.551959</td>\n      <td>0.448041</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.230771</td>\n      <td>0.769229</td>\n      <td>1</td>\n      <td>0.870135</td>\n      <td>0.129865</td>\n      <td>0</td>\n      <td>0.998511</td>\n      <td>0.001489</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176224</th>\n      <td>1</td>\n      <td>another subreddit outcome beautiful woman need...</td>\n      <td>0.81</td>\n      <td>0.19</td>\n      <td>0</td>\n      <td>0.670378</td>\n      <td>0.329622</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.999822</td>\n      <td>0.000178</td>\n      <td>0</td>\n      <td>0.997102</td>\n      <td>0.002898</td>\n      <td>0</td>\n      <td>0.999110</td>\n      <td>0.000890</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176252</th>\n      <td>0</td>\n      <td>little bitch would masturbate cus nonce stupid...</td>\n      <td>0.54</td>\n      <td>0.46</td>\n      <td>0</td>\n      <td>0.324064</td>\n      <td>0.675936</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.085027</td>\n      <td>0.914973</td>\n      <td>1</td>\n      <td>0.589835</td>\n      <td>0.410165</td>\n      <td>0</td>\n      <td>0.827502</td>\n      <td>0.172498</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>176287</th>\n      <td>0</td>\n      <td>white school teacher back elementary know give...</td>\n      <td>0.28</td>\n      <td>0.72</td>\n      <td>1</td>\n      <td>0.631280</td>\n      <td>0.368720</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.043912</td>\n      <td>0.956088</td>\n      <td>1</td>\n      <td>0.744024</td>\n      <td>0.255976</td>\n      <td>0</td>\n      <td>0.884535</td>\n      <td>0.115465</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>176290</th>\n      <td>0</td>\n      <td>kill religion</td>\n      <td>0.43</td>\n      <td>0.57</td>\n      <td>1</td>\n      <td>0.328023</td>\n      <td>0.671977</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.627487</td>\n      <td>0.372513</td>\n      <td>0</td>\n      <td>0.592711</td>\n      <td>0.407289</td>\n      <td>0</td>\n      <td>0.965532</td>\n      <td>0.034468</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>176325</th>\n      <td>0</td>\n      <td>retweet way act ugh chief boy nigger absolute ...</td>\n      <td>0.19</td>\n      <td>0.81</td>\n      <td>1</td>\n      <td>0.260187</td>\n      <td>0.739813</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.186607</td>\n      <td>0.813393</td>\n      <td>1</td>\n      <td>0.122462</td>\n      <td>0.877538</td>\n      <td>1</td>\n      <td>0.117280</td>\n      <td>0.882721</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>7648 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostly_false_merged_tweet_cleaned1 = get_mostly_false_merged(merged_false_tweet_cleaned1, label_col=\"label\")\n",
    "mostly_false_merged_tweet_cleaned1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T10:43:00.239700600Z",
     "start_time": "2025-03-15T10:43:00.142938300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "merged_false_tweet_cleaned1.to_csv(\"evaluation_data/merged_false_tweet_cleaned1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-15T10:43:00.694171500Z",
     "start_time": "2025-03-15T10:43:00.187653600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4 Mixed-Test cleaned - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1015/1015\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 7ms/step\n",
      "\u001B[1m1015/1015\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 1:22:24 (h:mm:ss)\n",
      "Prediction start.\n"
     ]
    }
   ],
   "source": [
    "merged_false_tweet_cleaned2 = create_false_tweet_df(tweet_col=\"tweet_cleaned\", label_col=\"label\",\n",
    "                                                    original_df=df_mixed_test_cleaned,\n",
    "                                                    threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-15T10:43:00.694171500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_false_tweet_cleaned2"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_false_merged_tweet_cleaned2 = get_all_false_merged(merged_false_tweet_cleaned2, label_col=\"label\")\n",
    "all_false_merged_tweet_cleaned2"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mostly_false_merged_tweet_cleaned2 = get_mostly_false_merged(merged_false_tweet_cleaned2, label_col=\"label\")\n",
    "mostly_false_merged_tweet_cleaned2"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_false_tweet_cleaned2.to_csv(\"evaluation_data/merged_false_tweet_cleaned2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
