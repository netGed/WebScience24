{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.519651900Z",
     "start_time": "2025-03-05T19:29:42.776056Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.src.saving import load_model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer\n",
    "from nltk import word_tokenize\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.src.utils import pad_sequences\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.520158400Z",
     "start_time": "2025-03-05T19:29:52.516678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.526637800Z",
     "start_time": "2025-03-05T19:29:52.520158400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funktionen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datenvorbereitung etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_dataset(tokenizer, max_len, labels_data, tweets_data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for tweet in tweets_data:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels_data)\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.531542100Z",
     "start_time": "2025-03-05T19:29:52.526637800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, dataset, sampler):\n",
    "    if sampler == \"random\":\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            sampler=RandomSampler(dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    if sampler == \"sequential\":\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            sampler=SequentialSampler(dataset),\n",
    "            batch_size=batch_size\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.536096100Z",
     "start_time": "2025-03-05T19:29:52.534058400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_max_len(tweets, tokenizer):\n",
    "    max_len = 0\n",
    "\n",
    "    for sent in tweets:\n",
    "        input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "        max_len = max(max_len, len(input_ids))\n",
    "    return max_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.539970300Z",
     "start_time": "2025-03-05T19:29:52.536096100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.544485300Z",
     "start_time": "2025-03-05T19:29:52.539970300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def vectorize_w2v(tweets, loaded_vectorizer, vector_size=300):\n",
    "    x_tokenized = tweets.map(word_tokenize)\n",
    "\n",
    "    def w2v_vector(x_tokenized, vector_size):\n",
    "        vec = np.zeros(vector_size).reshape((1, vector_size))\n",
    "        count = 0\n",
    "        for word in x_tokenized:\n",
    "            try:\n",
    "                vec += loaded_vectorizer.wv[word].reshape((1, vector_size))\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        return vec\n",
    "\n",
    "    tweets_w2v = np.zeros((len(x_tokenized), 300))\n",
    "    for i in range(len(x_tokenized)):\n",
    "        tweets_w2v[i, :] = w2v_vector(x_tokenized.iloc[i], 300)\n",
    "\n",
    "    return tweets_w2v"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.608918400Z",
     "start_time": "2025-03-05T19:29:52.544485300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluationsfunktionen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Metriken"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_predictions_bert(test_dataloader, model):\n",
    "    predictions = []\n",
    "    print(\"Prediction start.\")\n",
    "    total_t0 = time.time()\n",
    "    batches_completed = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            predictions.extend(list(pred_flat))\n",
    "\n",
    "        batches_completed += 1\n",
    "\n",
    "    print(\"Total Prediction took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.628926400Z",
     "start_time": "2025-03-05T19:29:52.553208800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model_name, y_prediction, y_true, sample_size, df, dataset_name, threshold):\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_prediction)\n",
    "    precision = precision_score(y_true, y_prediction)\n",
    "    recall = recall_score(y_true, y_prediction)\n",
    "    f1 = f1_score(y_true, y_prediction)\n",
    "    mcc = matthews_corrcoef(y_true, y_prediction)\n",
    "\n",
    "    df.loc[len(df.index)] = [model_name, dataset_name, sample_size, threshold, accuracy, precision, recall, f1, mcc]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.628926400Z",
     "start_time": "2025-03-05T19:29:52.559840400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def eval_model_bert(tokenizer, model, model_name, labels, tweets, batch_size, data_size, df, dataset_name, threshold,\n",
    "                    max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = get_max_len(tweets, tokenizer)\n",
    "    dataset = create_dataset(tokenizer=tokenizer, max_len=max_len, labels_data=labels,\n",
    "                             tweets_data=tweets)\n",
    "    dataloader = get_dataloader(batch_size=batch_size, sampler=\"sequential\", dataset=dataset)\n",
    "    predictions = get_predictions_bert(test_dataloader=dataloader, model=model)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.628926400Z",
     "start_time": "2025-03-05T19:29:52.560350800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def eval_model_ensemble(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorizer.transform(tweets)\n",
    "    predictions = (model.predict_proba(X_vectorized)[:, 1] >= threshold)\n",
    "    # predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.632925400Z",
     "start_time": "2025-03-05T19:29:52.568935600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def eval_model_bayes(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorize_w2v(tweets, vectorizer)\n",
    "    predictions = (model.predict_proba(X_vectorized)[:, 1] >= threshold)\n",
    "    # predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.632925400Z",
     "start_time": "2025-03-05T19:29:52.571652900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def eval_model_svm(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorizer.transform(tweets)\n",
    "    predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.632925400Z",
     "start_time": "2025-03-05T19:29:52.575934100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def eval_model_gru(tokenizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold, max_len):\n",
    "    X_data = [str(x) for x in tweets]\n",
    "    tweets_seq = tokenizer.texts_to_sequences(X_data)\n",
    "    tweets_padded = pad_sequences(tweets_seq, padding='post', maxlen=max_len)\n",
    "    predictions = (model.predict(tweets_padded) > threshold).astype(int)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.632925400Z",
     "start_time": "2025-03-05T19:29:52.584651300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Wahrscheinlichkeiten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "def get_predictions_with_probabilities_bert(test_dataloader, model, threshold):\n",
    "    predictions = []\n",
    "    predictions_proba = []\n",
    "    print(\"Prediction start.\")\n",
    "    total_t0 = time.time()\n",
    "    batches_completed = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            pred_with_thresh = [1 if value[1] > threshold else 0 for value in output.logits.softmax(dim=-1).tolist()]\n",
    "            pred_with_thresh = np.array(pred_with_thresh)\n",
    "\n",
    "            predictions.extend(list(pred_with_thresh))\n",
    "            predictions_proba.extend(output.logits.softmax(dim=-1).tolist())\n",
    "\n",
    "        batches_completed += 1\n",
    "\n",
    "    print(\"Prediction finished.\")\n",
    "    print(\"Total Prediction took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "    return predictions, predictions_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:57:32.636926500Z",
     "start_time": "2025-03-05T20:57:32.628231300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "def add_to_detail_eval_df(dataframe, predictions, probabilities=None):\n",
    "    if probabilities is not None:\n",
    "        dataframe[\"zero_proba\"] = pd.Series((v[0] for v in probabilities), index=dataframe.index)\n",
    "        dataframe[\"one_proba\"] = pd.Series((v[1] for v in probabilities), index=dataframe.index)\n",
    "    else:\n",
    "        dataframe[\"zero_proba\"] = 0\n",
    "        dataframe[\"one_proba\"] = 0\n",
    "    dataframe[\"pred\"] = predictions\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:52:58.985026500Z",
     "start_time": "2025-03-05T20:52:58.983428300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_bert(model, tokenizer, data, label_name, tweet_name, batch_size, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "    y_data = data[label_name].values\n",
    "    max_len = get_max_len(x_data, tokenizer)\n",
    "    test_dataset = create_dataset(tokenizer=tokenizer, max_len=max_len, labels_data=y_data,\n",
    "                                  tweets_data=x_data)\n",
    "    test_dataloader = get_dataloader(batch_size=batch_size, sampler=\"sequential\", dataset=test_dataset)\n",
    "\n",
    "    predictions, predictions_proba = get_predictions_with_probabilities_bert(test_dataloader=test_dataloader,\n",
    "                                                                             model=model, threshold=threshold)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=predictions_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:52:59.160811800Z",
     "start_time": "2025-03-05T20:52:59.152337900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_ensemble(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_vectorized = vectorizer.transform(x_data)\n",
    "    probabilities = model.predict_proba(X_vectorized)\n",
    "    predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:52:59.352669300Z",
     "start_time": "2025-03-05T20:52:59.328231500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_nb(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name]\n",
    "\n",
    "    X_vectorized = vectorize_w2v(x_data, vectorizer)\n",
    "    probabilities = model.predict_proba(X_vectorized)\n",
    "    predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:52:59.761863500Z",
     "start_time": "2025-03-05T20:52:59.753272600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_svm(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_vectorized = vectorizer.transform(x_data)\n",
    "    predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:53:01.000168600Z",
     "start_time": "2025-03-05T20:53:00.995134600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_gru(model, tokenizer, data, tweet_name, threshold, max_len):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_data = [str(x) for x in x_data]\n",
    "    tweets_seq = tokenizer.texts_to_sequences(X_data)\n",
    "    tweets_padded = pad_sequences(tweets_seq, padding='post', maxlen=max_len)\n",
    "\n",
    "    probabilities = model.predict(tweets_padded)\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    new_array = []\n",
    "    for proba in probabilities:\n",
    "        complement = 1 - proba[0]\n",
    "        new_array.append([complement, proba[0]])\n",
    "    probabilities = pd.Series(new_array)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:53:02.009503400Z",
     "start_time": "2025-03-05T20:53:01.995005600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Modelle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "MODELS_PATH = \"../../webapp/backend/app/models\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.632925400Z",
     "start_time": "2025-03-05T19:29:52.588406800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "nb_vectorizer = joblib.load(MODELS_PATH + \"/bayes/vectorizer_w2v.joblib\")\n",
    "nb_model = joblib.load(MODELS_PATH + \"/bayes/model_nb_w2v.joblib\")\n",
    "nb_modelname = \"GaussianNB\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:52.726337200Z",
     "start_time": "2025-03-05T19:29:52.588917600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "ensemble_vectorizer = joblib.load(MODELS_PATH + \"/ensemble/tfidf_vectorizer_for_brf.joblib\")\n",
    "ensemble_model = joblib.load(MODELS_PATH + \"/ensemble/tfidf_balancedrandomforest.joblib\")\n",
    "ensemble_modelname = \"BalancedRandomForest\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:53.210692400Z",
     "start_time": "2025-03-05T19:29:52.710826800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "svm_vectorizer = joblib.load(MODELS_PATH + \"/svm/tfidf_vectorizer_svm.joblib\")\n",
    "svm_model = joblib.load(MODELS_PATH + \"/svm/model_svc.joblib\")\n",
    "svm_modelname = \"LinearSVC\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:53.244284500Z",
     "start_time": "2025-03-05T19:29:53.214215500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4 RNN-GRU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "max_len_gru = 40\n",
    "gru_model = load_model(MODELS_PATH + \"/gru/gru-model_mixed-dataset.keras\")\n",
    "with open(MODELS_PATH + \"/gru/tokenizer_mixed-dataset.pkl\", 'rb') as f:\n",
    "    gru_tokenizer = pickle.load(f)\n",
    "gru_modelname = \"RNN-GRU\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:53.484189900Z",
     "start_time": "2025-03-05T19:29:53.244284500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.5 RNN-LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# todo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:53.487293800Z",
     "start_time": "2025-03-05T19:29:53.484189900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.6 BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "PATH_BERT_TUNED = MODELS_PATH + \"/bert/bert_mixed_imran\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(PATH_BERT_TUNED, local_files_only=True)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(PATH_BERT_TUNED, local_files_only=True)\n",
    "bert_modelname = \"bert_tuned_uncased\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:53.697125900Z",
     "start_time": "2025-03-05T19:29:53.487293800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.7 RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "PATH_ROBERTA_TUNED = MODELS_PATH + \"/roberta/roberta_hate_mixed_cleaned\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(PATH_ROBERTA_TUNED, local_files_only=True)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(PATH_ROBERTA_TUNED, local_files_only=True)\n",
    "roberta_modelname = \"roberta_hate_mixed_cleaned\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:53.854314700Z",
     "start_time": "2025-03-05T19:29:53.697125900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Mixed-Train (cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "        label                                      tweet_cleaned\n165527      0  really go crazy guy sometimes feel sorry idiot...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>165527</th>\n      <td>0</td>\n      <td>really go crazy guy sometimes feel sorry idiot...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixed_train_cleaned = pd.read_csv(\"../../data/mixed_dataset/train_cleaned.csv\", index_col=0)\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned[df_mixed_train_cleaned.tweet_cleaned.notna()]\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned.sample(n=100)\n",
    "\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned[[\"label\", \"tweet_cleaned\"]]\n",
    "df_mixed_train_cleaned.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:54.218849200Z",
     "start_time": "2025-03-05T19:29:53.854314700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Mixed-Train (uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                              tweet\n",
      "21553      0   @user i can't believe how big my sons thing i...\n",
      "Daten: \t 100\n"
     ]
    }
   ],
   "source": [
    "df_mixed_train_uncleaned = pd.read_csv(\"../../data/mixed_dataset/train_cleaned.csv\", index_col=0)\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned[df_mixed_train_uncleaned.tweet.notna()]\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned.sample(n=100)\n",
    "\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned[[\"label\", \"tweet\"]]\n",
    "print(df_mixed_train_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_train_uncleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:54.540618Z",
     "start_time": "2025-03-05T19:29:54.214331Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Mixed-Test (cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                       tweet_cleaned\n",
      "87977      0  right bi girl love see tit ashamed\n",
      "Daten: \t 100\n"
     ]
    }
   ],
   "source": [
    "df_mixed_test_cleaned = pd.read_csv(\"../../data/mixed_dataset/test_cleaned.csv\", index_col=0)\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned[df_mixed_test_cleaned.tweet_cleaned.notna()]\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned.sample(n=100)\n",
    "\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned[[\"label\", \"tweet_cleaned\"]]\n",
    "print(df_mixed_test_cleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_cleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:54.664084800Z",
     "start_time": "2025-03-05T19:29:54.537596500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Mixed-Test (cleaned-RNN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label tweet_cleaned\n",
      "116414      0    bitch boys\n",
      "Daten: \t 100\n"
     ]
    }
   ],
   "source": [
    "df_mixed_test_cleaned_rnn = pd.read_csv(\"../../data/mixed_dataset/test_cleaned_rnn.csv\", index_col=0)\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn[df_mixed_test_cleaned_rnn.tweet_cleaned.notna()]\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn.sample(n=100)\n",
    "\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn[[\"label\", \"tweet_cleaned\"]]\n",
    "print(df_mixed_test_cleaned_rnn.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_cleaned_rnn))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:54.834858600Z",
     "start_time": "2025-03-05T19:29:54.662035200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.5 Mixed-Test (uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                              tweet\n",
      "50893      0  OMG oh yes I want borrow your Girl and I would...\n",
      "Daten: \t 100\n"
     ]
    }
   ],
   "source": [
    "df_mixed_test_uncleaned = pd.read_csv(\"../../data/mixed_dataset/test_cleaned.csv\", index_col=0)\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned[df_mixed_test_uncleaned.tweet.notna()]\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned.sample(n=100)\n",
    "\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned[[\"label\", \"tweet\", ]]\n",
    "print(df_mixed_test_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_uncleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:29:54.962324200Z",
     "start_time": "2025-03-05T19:29:54.834858600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.6 Mixed-Test (manual-labeled, uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label_manual                                  tweet\n",
      "0             1  Post the shit or kill yourself faggot\n",
      "Daten: \t 400\n"
     ]
    }
   ],
   "source": [
    "df_mixed_manual_uncleaned = pd.read_csv(\"../../data/manual_labeled/manual_labeled_group.csv\", index_col=0)\n",
    "df_mixed_manual_uncleaned = df_mixed_manual_uncleaned[df_mixed_manual_uncleaned.tweet.notna()]\n",
    "\n",
    "df_mixed_manual_uncleaned = df_mixed_manual_uncleaned[[\"label_manual\", \"tweet\", ]]\n",
    "print(df_mixed_manual_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_manual_uncleaned))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:42:14.835409400Z",
     "start_time": "2025-03-05T20:42:14.825872Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Allgemeine Evaluation - Metriken"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def evaluate(label_col, tweet_col, data, dataset_name, threshold):\n",
    "    evaluation_df = pd.DataFrame(\n",
    "        columns=[\"model\", \"dataset_name\", \"sample_size\", \"threshold\", \"accuracy\", \"precision\", \"recall\", \"f1_score\",\n",
    "                 \"mcc\"])\n",
    "    eval_model_ensemble(vectorizer=ensemble_vectorizer,\n",
    "                        model=ensemble_model,\n",
    "                        model_name=ensemble_modelname,\n",
    "                        labels=data[label_col],\n",
    "                        tweets=data[tweet_col],\n",
    "                        data_size=len(data),\n",
    "                        df=evaluation_df,\n",
    "                        dataset_name=dataset_name,\n",
    "                        threshold=threshold)\n",
    "\n",
    "    eval_model_bayes(vectorizer=nb_vectorizer,\n",
    "                     model=nb_model,\n",
    "                     model_name=nb_modelname,\n",
    "                     labels=data[label_col],\n",
    "                     tweets=data[tweet_col],\n",
    "                     data_size=len(data),\n",
    "                     df=evaluation_df,\n",
    "                     dataset_name=dataset_name,\n",
    "                     threshold=threshold)\n",
    "\n",
    "    eval_model_svm(vectorizer=svm_vectorizer,\n",
    "                   model=svm_model,\n",
    "                   model_name=svm_modelname,\n",
    "                   labels=data[label_col],\n",
    "                   tweets=data[tweet_col],\n",
    "                   data_size=len(data),\n",
    "                   df=evaluation_df,\n",
    "                   dataset_name=dataset_name,\n",
    "                   threshold=\"None\")\n",
    "\n",
    "    # LSTM todo\n",
    "\n",
    "    eval_model_gru(tokenizer=gru_tokenizer,\n",
    "                   model=gru_model,\n",
    "                   model_name=gru_modelname,\n",
    "                   labels=data[label_col],\n",
    "                   tweets=data[tweet_col],\n",
    "                   data_size=len(data),\n",
    "                   df=evaluation_df,\n",
    "                   dataset_name=dataset_name,\n",
    "                   threshold=threshold,\n",
    "                   max_len=40)\n",
    "\n",
    "    eval_model_bert(tokenizer=bert_tokenizer,\n",
    "                    model=bert_model,\n",
    "                    model_name=bert_modelname,\n",
    "                    labels=data[label_col].values,\n",
    "                    tweets=data[tweet_col].values,\n",
    "                    batch_size=16,\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    eval_model_bert(tokenizer=roberta_tokenizer,\n",
    "                    model=roberta_model,\n",
    "                    model_name=roberta_modelname,\n",
    "                    labels=data[label_col].values,\n",
    "                    tweets=data[tweet_col].values,\n",
    "                    batch_size=16,\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    return evaluation_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:31:09.273836300Z",
     "start_time": "2025-03-05T19:31:09.262526600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1 Alle Datensätze - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.1 Mixed-Train (cleaned) - df_mixed_train_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:13 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned = evaluate(label_col=\"label\",\n",
    "                                          tweet_col=\"tweet_cleaned\",\n",
    "                                          data=df_mixed_train_cleaned,\n",
    "                                          dataset_name=\"df_mixed_train_cleaned\",\n",
    "                                          threshold=0.5,\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:31:53.388477400Z",
     "start_time": "2025-03-05T19:31:24.755360700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model            dataset_name  sample_size threshold  \\\n4          bert_tuned_uncased  df_mixed_train_cleaned          100       0.5   \n5  roberta_hate_mixed_cleaned  df_mixed_train_cleaned          100       0.5   \n0        BalancedRandomForest  df_mixed_train_cleaned          100       0.5   \n3                     RNN-GRU  df_mixed_train_cleaned          100       0.5   \n2                   LinearSVC  df_mixed_train_cleaned          100      None   \n1                  GaussianNB  df_mixed_train_cleaned          100       0.5   \n\n   accuracy  precision    recall  f1_score       mcc  \n4      0.94   0.764706  0.866667  0.812500  0.779108  \n5      0.93   0.722222  0.866667  0.787879  0.750825  \n0      0.78   0.393939  0.866667  0.541667  0.479453  \n3      0.77   0.382353  0.866667  0.530612  0.467047  \n2      0.71   0.333333  0.933333  0.491228  0.436915  \n1      0.59   0.229167  0.733333  0.349206  0.213013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.94</td>\n      <td>0.764706</td>\n      <td>0.866667</td>\n      <td>0.812500</td>\n      <td>0.779108</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.93</td>\n      <td>0.722222</td>\n      <td>0.866667</td>\n      <td>0.787879</td>\n      <td>0.750825</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.78</td>\n      <td>0.393939</td>\n      <td>0.866667</td>\n      <td>0.541667</td>\n      <td>0.479453</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.77</td>\n      <td>0.382353</td>\n      <td>0.866667</td>\n      <td>0.530612</td>\n      <td>0.467047</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.71</td>\n      <td>0.333333</td>\n      <td>0.933333</td>\n      <td>0.491228</td>\n      <td>0.436915</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.59</td>\n      <td>0.229167</td>\n      <td>0.733333</td>\n      <td>0.349206</td>\n      <td>0.213013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:31:53.399021900Z",
     "start_time": "2025-03-05T19:31:53.384479100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.2 Mixed-Train (uncleaned) - df_mixed_train_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_uncleaned = evaluate(label_col=\"label\",\n",
    "                                            tweet_col=\"tweet\",\n",
    "                                            data=df_mixed_train_uncleaned,\n",
    "                                            dataset_name=\"df_mixed_train_uncleaned\",\n",
    "                                            threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:32:38.115060200Z",
     "start_time": "2025-03-05T19:32:07.328218500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model              dataset_name  sample_size  \\\n3                     RNN-GRU  df_mixed_train_uncleaned          100   \n4          bert_tuned_uncased  df_mixed_train_uncleaned          100   \n5  roberta_hate_mixed_cleaned  df_mixed_train_uncleaned          100   \n2                   LinearSVC  df_mixed_train_uncleaned          100   \n0        BalancedRandomForest  df_mixed_train_uncleaned          100   \n1                  GaussianNB  df_mixed_train_uncleaned          100   \n\n  threshold  accuracy  precision    recall  f1_score       mcc  \n3       0.5      0.93   0.750000  0.947368  0.837209  0.802172  \n4       0.5      0.88   0.640000  0.842105  0.727273  0.662266  \n5       0.5      0.88   0.652174  0.789474  0.714286  0.643880  \n2      None      0.84   0.555556  0.789474  0.652174  0.566702  \n0       0.5      0.85   0.583333  0.736842  0.651163  0.563430  \n1       0.5      0.70   0.351351  0.684211  0.464286  0.315198  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.93</td>\n      <td>0.750000</td>\n      <td>0.947368</td>\n      <td>0.837209</td>\n      <td>0.802172</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.88</td>\n      <td>0.640000</td>\n      <td>0.842105</td>\n      <td>0.727273</td>\n      <td>0.662266</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.88</td>\n      <td>0.652174</td>\n      <td>0.789474</td>\n      <td>0.714286</td>\n      <td>0.643880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.84</td>\n      <td>0.555556</td>\n      <td>0.789474</td>\n      <td>0.652174</td>\n      <td>0.566702</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.85</td>\n      <td>0.583333</td>\n      <td>0.736842</td>\n      <td>0.651163</td>\n      <td>0.563430</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.70</td>\n      <td>0.351351</td>\n      <td>0.684211</td>\n      <td>0.464286</td>\n      <td>0.315198</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_train_uncleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:32:38.127275100Z",
     "start_time": "2025-03-05T19:32:38.117086200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.3 Mixed-Test (cleaned) - df_mixed_test_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned = evaluate(label_col=\"label\",\n",
    "                                         tweet_col=\"tweet_cleaned\",\n",
    "                                         data=df_mixed_test_cleaned,\n",
    "                                         dataset_name=\"df_mixed_test_cleaned\",\n",
    "                                         threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:33:07.582564200Z",
     "start_time": "2025-03-05T19:32:38.127275100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model           dataset_name  sample_size threshold  \\\n4          bert_tuned_uncased  df_mixed_test_cleaned          100       0.5   \n5  roberta_hate_mixed_cleaned  df_mixed_test_cleaned          100       0.5   \n3                     RNN-GRU  df_mixed_test_cleaned          100       0.5   \n0        BalancedRandomForest  df_mixed_test_cleaned          100       0.5   \n2                   LinearSVC  df_mixed_test_cleaned          100      None   \n1                  GaussianNB  df_mixed_test_cleaned          100       0.5   \n\n   accuracy  precision    recall  f1_score       mcc  \n4      0.84   0.550000  0.611111  0.578947  0.481536  \n5      0.85   0.600000  0.500000  0.545455  0.459243  \n3      0.71   0.342857  0.666667  0.452830  0.311058  \n0      0.73   0.354839  0.611111  0.448980  0.305036  \n2      0.68   0.325000  0.722222  0.448276  0.308162  \n1      0.55   0.271186  0.888889  0.415584  0.284722  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.84</td>\n      <td>0.550000</td>\n      <td>0.611111</td>\n      <td>0.578947</td>\n      <td>0.481536</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.85</td>\n      <td>0.600000</td>\n      <td>0.500000</td>\n      <td>0.545455</td>\n      <td>0.459243</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.71</td>\n      <td>0.342857</td>\n      <td>0.666667</td>\n      <td>0.452830</td>\n      <td>0.311058</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.73</td>\n      <td>0.354839</td>\n      <td>0.611111</td>\n      <td>0.448980</td>\n      <td>0.305036</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.68</td>\n      <td>0.325000</td>\n      <td>0.722222</td>\n      <td>0.448276</td>\n      <td>0.308162</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.55</td>\n      <td>0.271186</td>\n      <td>0.888889</td>\n      <td>0.415584</td>\n      <td>0.284722</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:33:07.592810300Z",
     "start_time": "2025-03-05T19:33:07.582564200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.4 Mixed-Test (cleaned-RNN) - df_mixed_test_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned_rnn = evaluate(label_col=\"label\",\n",
    "                                             tweet_col=\"tweet_cleaned\",\n",
    "                                             data=df_mixed_test_cleaned_rnn,\n",
    "                                             dataset_name=\"df_mixed_test_cleaned_rnn\",\n",
    "                                             threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:33:36.058581Z",
     "start_time": "2025-03-05T19:33:07.592810300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model               dataset_name  sample_size  \\\n0        BalancedRandomForest  df_mixed_test_cleaned_rnn          100   \n2                   LinearSVC  df_mixed_test_cleaned_rnn          100   \n4          bert_tuned_uncased  df_mixed_test_cleaned_rnn          100   \n5  roberta_hate_mixed_cleaned  df_mixed_test_cleaned_rnn          100   \n3                     RNN-GRU  df_mixed_test_cleaned_rnn          100   \n1                  GaussianNB  df_mixed_test_cleaned_rnn          100   \n\n  threshold  accuracy  precision    recall  f1_score       mcc  \n0       0.5      0.88   0.625000  0.833333  0.714286  0.650902  \n2      None      0.86   0.571429  0.888889  0.695652  0.635363  \n4       0.5      0.85   0.555556  0.833333  0.666667  0.594499  \n5       0.5      0.85   0.560000  0.777778  0.651163  0.571057  \n3       0.5      0.80   0.466667  0.777778  0.583333  0.488479  \n1       0.5      0.63   0.297872  0.777778  0.430769  0.288921  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.88</td>\n      <td>0.625000</td>\n      <td>0.833333</td>\n      <td>0.714286</td>\n      <td>0.650902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.86</td>\n      <td>0.571429</td>\n      <td>0.888889</td>\n      <td>0.695652</td>\n      <td>0.635363</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.85</td>\n      <td>0.555556</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.594499</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.85</td>\n      <td>0.560000</td>\n      <td>0.777778</td>\n      <td>0.651163</td>\n      <td>0.571057</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.80</td>\n      <td>0.466667</td>\n      <td>0.777778</td>\n      <td>0.583333</td>\n      <td>0.488479</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.63</td>\n      <td>0.297872</td>\n      <td>0.777778</td>\n      <td>0.430769</td>\n      <td>0.288921</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned_rnn.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:33:36.069348300Z",
     "start_time": "2025-03-05T19:33:36.058581Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.5 Mixed-Test (uncleaned) - df_mixed_test_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_uncleaned = evaluate(label_col=\"label\",\n",
    "                                           tweet_col=\"tweet\",\n",
    "                                           data=df_mixed_test_uncleaned,\n",
    "                                           dataset_name=\"df_mixed_test_uncleaned\",\n",
    "                                           threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:34:04.311908900Z",
     "start_time": "2025-03-05T19:33:36.069348300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model             dataset_name  sample_size threshold  \\\n4          bert_tuned_uncased  df_mixed_test_uncleaned          100       0.5   \n5  roberta_hate_mixed_cleaned  df_mixed_test_uncleaned          100       0.5   \n0        BalancedRandomForest  df_mixed_test_uncleaned          100       0.5   \n2                   LinearSVC  df_mixed_test_uncleaned          100      None   \n3                     RNN-GRU  df_mixed_test_uncleaned          100       0.5   \n1                  GaussianNB  df_mixed_test_uncleaned          100       0.5   \n\n   accuracy  precision    recall  f1_score       mcc  \n4      0.79   0.400000  0.800000  0.533333  0.458349  \n5      0.78   0.379310  0.733333  0.500000  0.410429  \n0      0.78   0.360000  0.600000  0.450000  0.339550  \n2      0.72   0.314286  0.733333  0.440000  0.337615  \n3      0.75   0.321429  0.600000  0.418605  0.299392  \n1      0.65   0.205882  0.466667  0.285714  0.112328  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.79</td>\n      <td>0.400000</td>\n      <td>0.800000</td>\n      <td>0.533333</td>\n      <td>0.458349</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.78</td>\n      <td>0.379310</td>\n      <td>0.733333</td>\n      <td>0.500000</td>\n      <td>0.410429</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.78</td>\n      <td>0.360000</td>\n      <td>0.600000</td>\n      <td>0.450000</td>\n      <td>0.339550</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.72</td>\n      <td>0.314286</td>\n      <td>0.733333</td>\n      <td>0.440000</td>\n      <td>0.337615</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.75</td>\n      <td>0.321429</td>\n      <td>0.600000</td>\n      <td>0.418605</td>\n      <td>0.299392</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.5</td>\n      <td>0.65</td>\n      <td>0.205882</td>\n      <td>0.466667</td>\n      <td>0.285714</td>\n      <td>0.112328</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_test_uncleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:34:04.322233100Z",
     "start_time": "2025-03-05T19:34:04.311908900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.6 Mixed-Test (manual-labeled, uncleaned) - df_mixed_manual_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:55 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:55 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_manual_uncleaned = evaluate(label_col=\"label_manual\",\n",
    "                                             tweet_col=\"tweet\",\n",
    "                                             data=df_mixed_manual_uncleaned,\n",
    "                                             dataset_name=\"df_mixed_manual_uncleaned\",\n",
    "                                             threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:35:56.588166800Z",
     "start_time": "2025-03-05T19:34:04.322233100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model               dataset_name  sample_size  \\\n5  roberta_hate_mixed_cleaned  df_mixed_manual_uncleaned          400   \n2                   LinearSVC  df_mixed_manual_uncleaned          400   \n4          bert_tuned_uncased  df_mixed_manual_uncleaned          400   \n3                     RNN-GRU  df_mixed_manual_uncleaned          400   \n0        BalancedRandomForest  df_mixed_manual_uncleaned          400   \n1                  GaussianNB  df_mixed_manual_uncleaned          400   \n\n  threshold  accuracy  precision    recall  f1_score       mcc  \n5       0.5    0.8850   0.914439  0.850746  0.881443  0.771967  \n2      None    0.8325   0.828431  0.840796  0.834568  0.665041  \n4       0.5    0.8200   0.824121  0.815920  0.820000  0.640041  \n3       0.5    0.8150   0.862857  0.751244  0.803191  0.635618  \n0       0.5    0.7975   0.837079  0.741294  0.786280  0.599194  \n1       0.5    0.6925   0.682243  0.726368  0.703614  0.385601  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.5</td>\n      <td>0.8850</td>\n      <td>0.914439</td>\n      <td>0.850746</td>\n      <td>0.881443</td>\n      <td>0.771967</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>None</td>\n      <td>0.8325</td>\n      <td>0.828431</td>\n      <td>0.840796</td>\n      <td>0.834568</td>\n      <td>0.665041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.5</td>\n      <td>0.8200</td>\n      <td>0.824121</td>\n      <td>0.815920</td>\n      <td>0.820000</td>\n      <td>0.640041</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.5</td>\n      <td>0.8150</td>\n      <td>0.862857</td>\n      <td>0.751244</td>\n      <td>0.803191</td>\n      <td>0.635618</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.5</td>\n      <td>0.7975</td>\n      <td>0.837079</td>\n      <td>0.741294</td>\n      <td>0.786280</td>\n      <td>0.599194</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.5</td>\n      <td>0.6925</td>\n      <td>0.682243</td>\n      <td>0.726368</td>\n      <td>0.703614</td>\n      <td>0.385601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_manual_uncleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:35:56.594756600Z",
     "start_time": "2025-03-05T19:35:56.585144200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Alle Datensätze - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.1 Mixed-Train (cleaned) - df_mixed_train_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned2 = evaluate(label_col=\"label\",\n",
    "                                           tweet_col=\"tweet_cleaned\",\n",
    "                                           data=df_mixed_train_cleaned,\n",
    "                                           dataset_name=\"df_mixed_train_cleaned\",\n",
    "                                           threshold=0.35,\n",
    "                                           )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:40:33.876632300Z",
     "start_time": "2025-03-05T19:40:04.527491300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model            dataset_name  sample_size threshold  \\\n4          bert_tuned_uncased  df_mixed_train_cleaned          100      0.35   \n5  roberta_hate_mixed_cleaned  df_mixed_train_cleaned          100      0.35   \n0        BalancedRandomForest  df_mixed_train_cleaned          100      0.35   \n2                   LinearSVC  df_mixed_train_cleaned          100      None   \n3                     RNN-GRU  df_mixed_train_cleaned          100      0.35   \n1                  GaussianNB  df_mixed_train_cleaned          100      0.35   \n\n   accuracy  precision    recall  f1_score       mcc  \n4      0.94   0.764706  0.866667  0.812500  0.779108  \n5      0.93   0.722222  0.866667  0.787879  0.750825  \n0      0.71   0.333333  0.933333  0.491228  0.436915  \n2      0.71   0.333333  0.933333  0.491228  0.436915  \n3      0.72   0.333333  0.866667  0.481481  0.410538  \n1      0.58   0.224490  0.733333  0.343750  0.204482  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.94</td>\n      <td>0.764706</td>\n      <td>0.866667</td>\n      <td>0.812500</td>\n      <td>0.779108</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.93</td>\n      <td>0.722222</td>\n      <td>0.866667</td>\n      <td>0.787879</td>\n      <td>0.750825</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.71</td>\n      <td>0.333333</td>\n      <td>0.933333</td>\n      <td>0.491228</td>\n      <td>0.436915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.71</td>\n      <td>0.333333</td>\n      <td>0.933333</td>\n      <td>0.491228</td>\n      <td>0.436915</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.72</td>\n      <td>0.333333</td>\n      <td>0.866667</td>\n      <td>0.481481</td>\n      <td>0.410538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_train_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.58</td>\n      <td>0.224490</td>\n      <td>0.733333</td>\n      <td>0.343750</td>\n      <td>0.204482</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_train_cleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:40:33.887121900Z",
     "start_time": "2025-03-05T19:40:33.876632300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.2 Mixed-Train (uncleaned) - df_mixed_train_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_train_uncleaned2 = evaluate(label_col=\"label\",\n",
    "                                             tweet_col=\"tweet\",\n",
    "                                             data=df_mixed_train_uncleaned,\n",
    "                                             dataset_name=\"df_mixed_train_uncleaned\",\n",
    "                                             threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:41:01.751888700Z",
     "start_time": "2025-03-05T19:40:33.887121900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model              dataset_name  sample_size  \\\n3                     RNN-GRU  df_mixed_train_uncleaned          100   \n4          bert_tuned_uncased  df_mixed_train_uncleaned          100   \n5  roberta_hate_mixed_cleaned  df_mixed_train_uncleaned          100   \n2                   LinearSVC  df_mixed_train_uncleaned          100   \n0        BalancedRandomForest  df_mixed_train_uncleaned          100   \n1                  GaussianNB  df_mixed_train_uncleaned          100   \n\n  threshold  accuracy  precision    recall  f1_score       mcc  \n3      0.35      0.89   0.642857  0.947368  0.765957  0.719871  \n4      0.35      0.88   0.640000  0.842105  0.727273  0.662266  \n5      0.35      0.88   0.652174  0.789474  0.714286  0.643880  \n2      None      0.84   0.555556  0.789474  0.652174  0.566702  \n0      0.35      0.82   0.516129  0.842105  0.640000  0.557220  \n1      0.35      0.70   0.351351  0.684211  0.464286  0.315198  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.89</td>\n      <td>0.642857</td>\n      <td>0.947368</td>\n      <td>0.765957</td>\n      <td>0.719871</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.88</td>\n      <td>0.640000</td>\n      <td>0.842105</td>\n      <td>0.727273</td>\n      <td>0.662266</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.88</td>\n      <td>0.652174</td>\n      <td>0.789474</td>\n      <td>0.714286</td>\n      <td>0.643880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.84</td>\n      <td>0.555556</td>\n      <td>0.789474</td>\n      <td>0.652174</td>\n      <td>0.566702</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.82</td>\n      <td>0.516129</td>\n      <td>0.842105</td>\n      <td>0.640000</td>\n      <td>0.557220</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_train_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.70</td>\n      <td>0.351351</td>\n      <td>0.684211</td>\n      <td>0.464286</td>\n      <td>0.315198</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_train_uncleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:41:01.761475100Z",
     "start_time": "2025-03-05T19:41:01.751888700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.3 Mixed-Test (cleaned) - df_mixed_test_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned2 = evaluate(label_col=\"label\",\n",
    "                                          tweet_col=\"tweet_cleaned\",\n",
    "                                          data=df_mixed_test_cleaned,\n",
    "                                          dataset_name=\"df_mixed_test_cleaned\",\n",
    "                                          threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:41:32.131244900Z",
     "start_time": "2025-03-05T19:41:01.761475100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model           dataset_name  sample_size threshold  \\\n4          bert_tuned_uncased  df_mixed_test_cleaned          100      0.35   \n5  roberta_hate_mixed_cleaned  df_mixed_test_cleaned          100      0.35   \n3                     RNN-GRU  df_mixed_test_cleaned          100      0.35   \n2                   LinearSVC  df_mixed_test_cleaned          100      None   \n0        BalancedRandomForest  df_mixed_test_cleaned          100      0.35   \n1                  GaussianNB  df_mixed_test_cleaned          100      0.35   \n\n   accuracy  precision    recall  f1_score       mcc  \n4      0.84   0.550000  0.611111  0.578947  0.481536  \n5      0.85   0.600000  0.500000  0.545455  0.459243  \n3      0.69   0.333333  0.722222  0.456140  0.319125  \n2      0.68   0.325000  0.722222  0.448276  0.308162  \n0      0.59   0.274510  0.777778  0.405797  0.250969  \n1      0.53   0.262295  0.888889  0.405063  0.267894  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.84</td>\n      <td>0.550000</td>\n      <td>0.611111</td>\n      <td>0.578947</td>\n      <td>0.481536</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.85</td>\n      <td>0.600000</td>\n      <td>0.500000</td>\n      <td>0.545455</td>\n      <td>0.459243</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.69</td>\n      <td>0.333333</td>\n      <td>0.722222</td>\n      <td>0.456140</td>\n      <td>0.319125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.68</td>\n      <td>0.325000</td>\n      <td>0.722222</td>\n      <td>0.448276</td>\n      <td>0.308162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.59</td>\n      <td>0.274510</td>\n      <td>0.777778</td>\n      <td>0.405797</td>\n      <td>0.250969</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_test_cleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.53</td>\n      <td>0.262295</td>\n      <td>0.888889</td>\n      <td>0.405063</td>\n      <td>0.267894</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:41:32.141314200Z",
     "start_time": "2025-03-05T19:41:32.131244900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.4 Mixed-Test (cleaned-RNN) - df_mixed_test_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned_rnn2 = evaluate(label_col=\"label\",\n",
    "                                              tweet_col=\"tweet_cleaned\",\n",
    "                                              data=df_mixed_test_cleaned_rnn,\n",
    "                                              dataset_name=\"df_mixed_test_cleaned_rnn\",\n",
    "                                              threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:42:01.568319500Z",
     "start_time": "2025-03-05T19:41:32.141314200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model               dataset_name  sample_size  \\\n2                   LinearSVC  df_mixed_test_cleaned_rnn          100   \n4          bert_tuned_uncased  df_mixed_test_cleaned_rnn          100   \n5  roberta_hate_mixed_cleaned  df_mixed_test_cleaned_rnn          100   \n0        BalancedRandomForest  df_mixed_test_cleaned_rnn          100   \n3                     RNN-GRU  df_mixed_test_cleaned_rnn          100   \n1                  GaussianNB  df_mixed_test_cleaned_rnn          100   \n\n  threshold  accuracy  precision    recall  f1_score       mcc  \n2      None      0.86   0.571429  0.888889  0.695652  0.635363  \n4      0.35      0.85   0.555556  0.833333  0.666667  0.594499  \n5      0.35      0.85   0.560000  0.777778  0.651163  0.571057  \n0      0.35      0.81   0.485714  0.944444  0.641509  0.583915  \n3      0.35      0.78   0.441176  0.833333  0.576923  0.487931  \n1      0.35      0.62   0.300000  0.833333  0.441176  0.312348  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.86</td>\n      <td>0.571429</td>\n      <td>0.888889</td>\n      <td>0.695652</td>\n      <td>0.635363</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.85</td>\n      <td>0.555556</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.594499</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.85</td>\n      <td>0.560000</td>\n      <td>0.777778</td>\n      <td>0.651163</td>\n      <td>0.571057</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.81</td>\n      <td>0.485714</td>\n      <td>0.944444</td>\n      <td>0.641509</td>\n      <td>0.583915</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.78</td>\n      <td>0.441176</td>\n      <td>0.833333</td>\n      <td>0.576923</td>\n      <td>0.487931</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_test_cleaned_rnn</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.62</td>\n      <td>0.300000</td>\n      <td>0.833333</td>\n      <td>0.441176</td>\n      <td>0.312348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_test_cleaned_rnn2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:42:01.578127Z",
     "start_time": "2025-03-05T19:42:01.568319500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.5 Mixed-Test (uncleaned) - df_mixed_test_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:14 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:15 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_test_uncleaned2 = evaluate(label_col=\"label\",\n",
    "                                            tweet_col=\"tweet\",\n",
    "                                            data=df_mixed_test_uncleaned,\n",
    "                                            dataset_name=\"df_mixed_test_uncleaned\",\n",
    "                                            threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:42:31.270042500Z",
     "start_time": "2025-03-05T19:42:01.578127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model             dataset_name  sample_size threshold  \\\n4          bert_tuned_uncased  df_mixed_test_uncleaned          100      0.35   \n5  roberta_hate_mixed_cleaned  df_mixed_test_uncleaned          100      0.35   \n3                     RNN-GRU  df_mixed_test_uncleaned          100      0.35   \n2                   LinearSVC  df_mixed_test_uncleaned          100      None   \n0        BalancedRandomForest  df_mixed_test_uncleaned          100      0.35   \n1                  GaussianNB  df_mixed_test_uncleaned          100      0.35   \n\n   accuracy  precision    recall  f1_score       mcc  \n4      0.79   0.400000  0.800000  0.533333  0.458349  \n5      0.78   0.379310  0.733333  0.500000  0.410429  \n3      0.75   0.343750  0.733333  0.468085  0.372226  \n2      0.72   0.314286  0.733333  0.440000  0.337615  \n0      0.66   0.268293  0.733333  0.392857  0.276165  \n1      0.61   0.184211  0.466667  0.264151  0.075007  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.79</td>\n      <td>0.400000</td>\n      <td>0.800000</td>\n      <td>0.533333</td>\n      <td>0.458349</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.78</td>\n      <td>0.379310</td>\n      <td>0.733333</td>\n      <td>0.500000</td>\n      <td>0.410429</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.75</td>\n      <td>0.343750</td>\n      <td>0.733333</td>\n      <td>0.468085</td>\n      <td>0.372226</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>None</td>\n      <td>0.72</td>\n      <td>0.314286</td>\n      <td>0.733333</td>\n      <td>0.440000</td>\n      <td>0.337615</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.66</td>\n      <td>0.268293</td>\n      <td>0.733333</td>\n      <td>0.392857</td>\n      <td>0.276165</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_test_uncleaned</td>\n      <td>100</td>\n      <td>0.35</td>\n      <td>0.61</td>\n      <td>0.184211</td>\n      <td>0.466667</td>\n      <td>0.264151</td>\n      <td>0.075007</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_test_uncleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:42:31.280869900Z",
     "start_time": "2025-03-05T19:42:31.270042500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.6 Mixed-Test (manual-labeled, uncleaned) - df_mixed_manual_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:52 (h:mm:ss)\n",
      "Prediction start.\n",
      "Total Prediction took 0:00:56 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "evaluation_mixed_manual_uncleaned2 = evaluate(label_col=\"label_manual\",\n",
    "                                              tweet_col=\"tweet\",\n",
    "                                              data=df_mixed_manual_uncleaned,\n",
    "                                              dataset_name=\"df_mixed_manual_uncleaned\",\n",
    "                                              threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:44:22.070147800Z",
     "start_time": "2025-03-05T19:42:31.280869900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                        model               dataset_name  sample_size  \\\n5  roberta_hate_mixed_cleaned  df_mixed_manual_uncleaned          400   \n2                   LinearSVC  df_mixed_manual_uncleaned          400   \n4          bert_tuned_uncased  df_mixed_manual_uncleaned          400   \n0        BalancedRandomForest  df_mixed_manual_uncleaned          400   \n3                     RNN-GRU  df_mixed_manual_uncleaned          400   \n1                  GaussianNB  df_mixed_manual_uncleaned          400   \n\n  threshold  accuracy  precision    recall  f1_score       mcc  \n5      0.35    0.8850   0.914439  0.850746  0.881443  0.771967  \n2      None    0.8325   0.828431  0.840796  0.834568  0.665041  \n4      0.35    0.8200   0.824121  0.815920  0.820000  0.640041  \n0      0.35    0.8025   0.777273  0.850746  0.812352  0.607553  \n3      0.35    0.7900   0.806283  0.766169  0.785714  0.580821  \n1      0.35    0.6875   0.669643  0.746269  0.705882  0.377130  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset_name</th>\n      <th>sample_size</th>\n      <th>threshold</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>mcc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>roberta_hate_mixed_cleaned</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.35</td>\n      <td>0.8850</td>\n      <td>0.914439</td>\n      <td>0.850746</td>\n      <td>0.881443</td>\n      <td>0.771967</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVC</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>None</td>\n      <td>0.8325</td>\n      <td>0.828431</td>\n      <td>0.840796</td>\n      <td>0.834568</td>\n      <td>0.665041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bert_tuned_uncased</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.35</td>\n      <td>0.8200</td>\n      <td>0.824121</td>\n      <td>0.815920</td>\n      <td>0.820000</td>\n      <td>0.640041</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>BalancedRandomForest</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.35</td>\n      <td>0.8025</td>\n      <td>0.777273</td>\n      <td>0.850746</td>\n      <td>0.812352</td>\n      <td>0.607553</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNN-GRU</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.35</td>\n      <td>0.7900</td>\n      <td>0.806283</td>\n      <td>0.766169</td>\n      <td>0.785714</td>\n      <td>0.580821</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB</td>\n      <td>df_mixed_manual_uncleaned</td>\n      <td>400</td>\n      <td>0.35</td>\n      <td>0.6875</td>\n      <td>0.669643</td>\n      <td>0.746269</td>\n      <td>0.705882</td>\n      <td>0.377130</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_mixed_manual_uncleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:44:22.079256200Z",
     "start_time": "2025-03-05T19:44:22.070147800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Detaillierte Evaluation - Tweetbetrachtung\n",
    "\n",
    "Fragen:\n",
    "- gibt es Tweets, die von keinem Modell korrekt klassifiziert werden können? bzw. nur von wenigen? was haben diese Tweets gemeinsam?\n",
    "- gibt es Tweets, die von allen Modellen korrekt klassifiziert werden können? bzw. von vielen? was haben diese Tweets gemeinsam?\n",
    "-\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1 manuell gelabelte Tweets - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "merged_false = df_mixed_manual_uncleaned.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:59:45.843381600Z",
     "start_time": "2025-03-05T20:59:45.828247500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "add_pred_and_probas_ensemble(model=ensemble_model,\n",
    "                             vectorizer=ensemble_vectorizer,\n",
    "                             data=merged_false,\n",
    "                             tweet_name=\"tweet\",\n",
    "                             threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_ens',\n",
    "                             'one_proba': '1_ens',\n",
    "                             'pred': 'pred_ens'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:59:46.142195600Z",
     "start_time": "2025-03-05T20:59:46.067590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "add_pred_and_probas_nb(model=nb_model,\n",
    "                       vectorizer=nb_vectorizer,\n",
    "                       data=merged_false,\n",
    "                       tweet_name=\"tweet\",\n",
    "                       threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_nb',\n",
    "                             'one_proba': '1_nb',\n",
    "                             'pred': 'pred_nb'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:59:46.382044300Z",
     "start_time": "2025-03-05T20:59:46.290024800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "add_pred_and_probas_svm(model=svm_model,\n",
    "                        vectorizer=svm_vectorizer,\n",
    "                        data=merged_false,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_svm',\n",
    "                             'one_proba': '1_svm',\n",
    "                             'pred': 'pred_svm'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:59:47.571060600Z",
     "start_time": "2025-03-05T20:59:46.492187900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "# LSTM todo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:59:47.574590900Z",
     "start_time": "2025-03-05T20:59:47.574081400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "add_pred_and_probas_gru(model=gru_model,\n",
    "                        tokenizer=gru_tokenizer,\n",
    "                        data=merged_false,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.5,\n",
    "                        max_len=40)\n",
    "merged_false.rename(columns={'zero_proba': '0_gru',\n",
    "                             'one_proba': '1_gru',\n",
    "                             'pred': 'pred_gru'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T20:59:47.800366500Z",
     "start_time": "2025-03-05T20:59:47.574590900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:00:59 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "add_pred_and_probas_bert(model=bert_model,\n",
    "                         tokenizer=bert_tokenizer,\n",
    "                         data=merged_false,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_bert',\n",
    "                             'one_proba': '1_bert',\n",
    "                             'pred': 'pred_bert'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:00:47.275098800Z",
     "start_time": "2025-03-05T20:59:47.781802200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:01:03 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "add_pred_and_probas_bert(model=roberta_model,\n",
    "                         tokenizer=roberta_tokenizer,\n",
    "                         data=merged_false,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_rob',\n",
    "                             'one_proba': '1_rob',\n",
    "                             'pred': 'pred_rob'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:01:50.181902200Z",
     "start_time": "2025-03-05T21:00:47.275098800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n0              1              Post the shit or kill yourself faggot   0.06   \n2              1  i hate jews so much i wish the holocaust actua...   0.16   \n3              1  Poor kid would have been better off with his h...   0.48   \n10             1  Close your fucking legs, hoe. Use birth contro...   0.60   \n11             1  @user @user Please take away their license to ...   0.70   \n..           ...                                                ...    ...   \n95             1           wow men are fucking trash and disgusting   0.19   \n96             1  I hope your an anal only slut. No one should h...   0.17   \n97             1  do you have autism or something? why do you ta...   0.04   \n98             1  Stupid Asian Bitch You're an idiot and you sho...   0.20   \n99             1  RT @user: List of bitches who want my dick... ...   0.58   \n\n    1_ens  pred_ens          0_nb      1_nb  pred_nb  0_svm  1_svm  pred_svm  \\\n0    0.94         1  2.778007e-13  1.000000        1      0      0         1   \n2    0.84         1  9.101217e-02  0.908988        1      0      0         1   \n3    0.52         1  1.087948e-02  0.989121        1      0      0         1   \n10   0.40         0  7.472763e-08  1.000000        1      0      0         0   \n11   0.30         0  9.999939e-01  0.000006        0      0      0         1   \n..    ...       ...           ...       ...      ...    ...    ...       ...   \n95   0.81         1  6.262303e-09  1.000000        1      0      0         1   \n96   0.83         1  4.681266e-07  1.000000        1      0      0         1   \n97   0.96         1  8.632649e-08  1.000000        1      0      0         1   \n98   0.80         1  6.193825e-06  0.999994        1      0      0         1   \n99   0.42         0  9.999785e-01  0.000022        0      0      0         1   \n\n       0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert     0_rob  \\\n0   0.011137  0.988863         1  0.180920  0.819080          1  0.192266   \n2   0.195016  0.804984         1  0.512623  0.487377          0  0.023317   \n3   0.036294  0.963706         1  0.157057  0.842943          1  0.221822   \n10  0.006292  0.993708         1  0.713035  0.286965          0  0.158761   \n11  0.997577  0.002423         0  0.865542  0.134458          0  0.961045   \n..       ...       ...       ...       ...       ...        ...       ...   \n95  0.903850  0.096150         0  0.523429  0.476571          0  0.428509   \n96  0.012478  0.987522         1  0.265263  0.734737          1  0.052255   \n97  0.019523  0.980477         1  0.475986  0.524014          1  0.047550   \n98  0.011486  0.988514         1  0.222132  0.777868          1  0.057266   \n99  0.796263  0.203737         0  0.921312  0.078688          0  0.017409   \n\n       1_rob  pred_rob  \n0   0.807734         1  \n2   0.976683         1  \n3   0.778178         1  \n10  0.841239         1  \n11  0.038955         0  \n..       ...       ...  \n95  0.571491         1  \n96  0.947745         1  \n97  0.952450         1  \n98  0.942734         1  \n99  0.982591         1  \n\n[400 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>pred_svm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Post the shit or kill yourself faggot</td>\n      <td>0.06</td>\n      <td>0.94</td>\n      <td>1</td>\n      <td>2.778007e-13</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.011137</td>\n      <td>0.988863</td>\n      <td>1</td>\n      <td>0.180920</td>\n      <td>0.819080</td>\n      <td>1</td>\n      <td>0.192266</td>\n      <td>0.807734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>i hate jews so much i wish the holocaust actua...</td>\n      <td>0.16</td>\n      <td>0.84</td>\n      <td>1</td>\n      <td>9.101217e-02</td>\n      <td>0.908988</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.195016</td>\n      <td>0.804984</td>\n      <td>1</td>\n      <td>0.512623</td>\n      <td>0.487377</td>\n      <td>0</td>\n      <td>0.023317</td>\n      <td>0.976683</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Poor kid would have been better off with his h...</td>\n      <td>0.48</td>\n      <td>0.52</td>\n      <td>1</td>\n      <td>1.087948e-02</td>\n      <td>0.989121</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.036294</td>\n      <td>0.963706</td>\n      <td>1</td>\n      <td>0.157057</td>\n      <td>0.842943</td>\n      <td>1</td>\n      <td>0.221822</td>\n      <td>0.778178</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>Close your fucking legs, hoe. Use birth contro...</td>\n      <td>0.60</td>\n      <td>0.40</td>\n      <td>0</td>\n      <td>7.472763e-08</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.006292</td>\n      <td>0.993708</td>\n      <td>1</td>\n      <td>0.713035</td>\n      <td>0.286965</td>\n      <td>0</td>\n      <td>0.158761</td>\n      <td>0.841239</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>@user @user Please take away their license to ...</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>9.999939e-01</td>\n      <td>0.000006</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.997577</td>\n      <td>0.002423</td>\n      <td>0</td>\n      <td>0.865542</td>\n      <td>0.134458</td>\n      <td>0</td>\n      <td>0.961045</td>\n      <td>0.038955</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1</td>\n      <td>wow men are fucking trash and disgusting</td>\n      <td>0.19</td>\n      <td>0.81</td>\n      <td>1</td>\n      <td>6.262303e-09</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.903850</td>\n      <td>0.096150</td>\n      <td>0</td>\n      <td>0.523429</td>\n      <td>0.476571</td>\n      <td>0</td>\n      <td>0.428509</td>\n      <td>0.571491</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>I hope your an anal only slut. No one should h...</td>\n      <td>0.17</td>\n      <td>0.83</td>\n      <td>1</td>\n      <td>4.681266e-07</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.012478</td>\n      <td>0.987522</td>\n      <td>1</td>\n      <td>0.265263</td>\n      <td>0.734737</td>\n      <td>1</td>\n      <td>0.052255</td>\n      <td>0.947745</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1</td>\n      <td>do you have autism or something? why do you ta...</td>\n      <td>0.04</td>\n      <td>0.96</td>\n      <td>1</td>\n      <td>8.632649e-08</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.019523</td>\n      <td>0.980477</td>\n      <td>1</td>\n      <td>0.475986</td>\n      <td>0.524014</td>\n      <td>1</td>\n      <td>0.047550</td>\n      <td>0.952450</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>Stupid Asian Bitch You're an idiot and you sho...</td>\n      <td>0.20</td>\n      <td>0.80</td>\n      <td>1</td>\n      <td>6.193825e-06</td>\n      <td>0.999994</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.011486</td>\n      <td>0.988514</td>\n      <td>1</td>\n      <td>0.222132</td>\n      <td>0.777868</td>\n      <td>1</td>\n      <td>0.057266</td>\n      <td>0.942734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1</td>\n      <td>RT @user: List of bitches who want my dick... ...</td>\n      <td>0.58</td>\n      <td>0.42</td>\n      <td>0</td>\n      <td>9.999785e-01</td>\n      <td>0.000022</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.796263</td>\n      <td>0.203737</td>\n      <td>0</td>\n      <td>0.921312</td>\n      <td>0.078688</td>\n      <td>0</td>\n      <td>0.017409</td>\n      <td>0.982591</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_false"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:01:50.196551Z",
     "start_time": "2025-03-05T21:01:50.179887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_false_merged = merged_false[\n",
    "    (merged_false.pred_ens != merged_false.label_manual) &\n",
    "    (merged_false.pred_nb != merged_false.label_manual) &\n",
    "    (merged_false.pred_svm != merged_false.label_manual) &\n",
    "    (merged_false.pred_gru != merged_false.label_manual) &\n",
    "    (merged_false.pred_bert != merged_false.label_manual) &\n",
    "    (merged_false.pred_rob != merged_false.label_manual)]\n",
    "\n",
    "len(all_false_merged)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:08:21.956069800Z",
     "start_time": "2025-03-05T21:08:21.947887400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 manuell gelabelte Tweets - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "merged_false2 = df_mixed_manual_uncleaned.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:06:23.381603100Z",
     "start_time": "2025-03-05T21:06:23.342189900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "add_pred_and_probas_ensemble(model=ensemble_model,\n",
    "                             vectorizer=ensemble_vectorizer,\n",
    "                             data=merged_false2,\n",
    "                             tweet_name=\"tweet\",\n",
    "                             threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_ens',\n",
    "                             'one_proba': '1_ens',\n",
    "                             'pred': 'pred_ens'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:06:23.625377600Z",
     "start_time": "2025-03-05T21:06:23.561632700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "add_pred_and_probas_nb(model=nb_model,\n",
    "                       vectorizer=nb_vectorizer,\n",
    "                       data=merged_false2,\n",
    "                       tweet_name=\"tweet\",\n",
    "                       threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_nb',\n",
    "                             'one_proba': '1_nb',\n",
    "                             'pred': 'pred_nb'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:06:23.834532400Z",
     "start_time": "2025-03-05T21:06:23.744601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "add_pred_and_probas_svm(model=svm_model,\n",
    "                        vectorizer=svm_vectorizer,\n",
    "                        data=merged_false2,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_svm',\n",
    "                             'one_proba': '1_svm',\n",
    "                             'pred': 'pred_svm'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:06:25.077673500Z",
     "start_time": "2025-03-05T21:06:23.932071600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# LSTM todo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:06:25.079877700Z",
     "start_time": "2025-03-05T21:06:25.078187500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "add_pred_and_probas_gru(model=gru_model,\n",
    "                        tokenizer=gru_tokenizer,\n",
    "                        data=merged_false2,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.35,\n",
    "                        max_len=40)\n",
    "merged_false2.rename(columns={'zero_proba': '0_gru',\n",
    "                             'one_proba': '1_gru',\n",
    "                             'pred': 'pred_gru'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:06:25.317718800Z",
     "start_time": "2025-03-05T21:06:25.079877700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:01:00 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "add_pred_and_probas_bert(model=bert_model,\n",
    "                         tokenizer=bert_tokenizer,\n",
    "                         data=merged_false2,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_bert',\n",
    "                             'one_proba': '1_bert',\n",
    "                             'pred': 'pred_bert'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:07:26.035644400Z",
     "start_time": "2025-03-05T21:06:25.295205100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start.\n",
      "Prediction finished.\n",
      "Total Prediction took 0:00:56 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "add_pred_and_probas_bert(model=roberta_model,\n",
    "                         tokenizer=roberta_tokenizer,\n",
    "                         data=merged_false2,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_rob',\n",
    "                             'one_proba': '1_rob',\n",
    "                             'pred': 'pred_rob'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:08:21.935992200Z",
     "start_time": "2025-03-05T21:07:26.035644400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "    label_manual                                              tweet  0_ens  \\\n0              1              Post the shit or kill yourself faggot   0.06   \n2              1  i hate jews so much i wish the holocaust actua...   0.16   \n3              1  Poor kid would have been better off with his h...   0.48   \n10             1  Close your fucking legs, hoe. Use birth contro...   0.60   \n11             1  @user @user Please take away their license to ...   0.70   \n..           ...                                                ...    ...   \n95             1           wow men are fucking trash and disgusting   0.19   \n96             1  I hope your an anal only slut. No one should h...   0.17   \n97             1  do you have autism or something? why do you ta...   0.04   \n98             1  Stupid Asian Bitch You're an idiot and you sho...   0.20   \n99             1  RT @user: List of bitches who want my dick... ...   0.58   \n\n    1_ens  pred_ens          0_nb      1_nb  pred_nb  0_svm  1_svm  pred_svm  \\\n0    0.94         1  2.778007e-13  1.000000        1      0      0         1   \n2    0.84         1  9.101217e-02  0.908988        1      0      0         1   \n3    0.52         1  1.087948e-02  0.989121        1      0      0         1   \n10   0.40         1  7.472763e-08  1.000000        1      0      0         0   \n11   0.30         0  9.999939e-01  0.000006        0      0      0         1   \n..    ...       ...           ...       ...      ...    ...    ...       ...   \n95   0.81         1  6.262303e-09  1.000000        1      0      0         1   \n96   0.83         1  4.681266e-07  1.000000        1      0      0         1   \n97   0.96         1  8.632649e-08  1.000000        1      0      0         1   \n98   0.80         1  6.193825e-06  0.999994        1      0      0         1   \n99   0.42         1  9.999785e-01  0.000022        0      0      0         1   \n\n       0_gru     1_gru  pred_gru    0_bert    1_bert  pred_bert     0_rob  \\\n0   0.011137  0.988863         1  0.180920  0.819080          1  0.192266   \n2   0.195016  0.804984         1  0.512623  0.487377          1  0.023317   \n3   0.036294  0.963706         1  0.157057  0.842943          1  0.221822   \n10  0.006292  0.993708         1  0.713035  0.286965          0  0.158761   \n11  0.997577  0.002423         0  0.865542  0.134458          0  0.961045   \n..       ...       ...       ...       ...       ...        ...       ...   \n95  0.903850  0.096150         0  0.523429  0.476571          1  0.428509   \n96  0.012478  0.987522         1  0.265263  0.734737          1  0.052255   \n97  0.019523  0.980477         1  0.475986  0.524014          1  0.047550   \n98  0.011486  0.988514         1  0.222132  0.777868          1  0.057266   \n99  0.796263  0.203737         0  0.921312  0.078688          0  0.017409   \n\n       1_rob  pred_rob  \n0   0.807734         1  \n2   0.976683         1  \n3   0.778178         1  \n10  0.841239         1  \n11  0.038955         0  \n..       ...       ...  \n95  0.571491         1  \n96  0.947745         1  \n97  0.952450         1  \n98  0.942734         1  \n99  0.982591         1  \n\n[400 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_manual</th>\n      <th>tweet</th>\n      <th>0_ens</th>\n      <th>1_ens</th>\n      <th>pred_ens</th>\n      <th>0_nb</th>\n      <th>1_nb</th>\n      <th>pred_nb</th>\n      <th>0_svm</th>\n      <th>1_svm</th>\n      <th>pred_svm</th>\n      <th>0_gru</th>\n      <th>1_gru</th>\n      <th>pred_gru</th>\n      <th>0_bert</th>\n      <th>1_bert</th>\n      <th>pred_bert</th>\n      <th>0_rob</th>\n      <th>1_rob</th>\n      <th>pred_rob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Post the shit or kill yourself faggot</td>\n      <td>0.06</td>\n      <td>0.94</td>\n      <td>1</td>\n      <td>2.778007e-13</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.011137</td>\n      <td>0.988863</td>\n      <td>1</td>\n      <td>0.180920</td>\n      <td>0.819080</td>\n      <td>1</td>\n      <td>0.192266</td>\n      <td>0.807734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>i hate jews so much i wish the holocaust actua...</td>\n      <td>0.16</td>\n      <td>0.84</td>\n      <td>1</td>\n      <td>9.101217e-02</td>\n      <td>0.908988</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.195016</td>\n      <td>0.804984</td>\n      <td>1</td>\n      <td>0.512623</td>\n      <td>0.487377</td>\n      <td>1</td>\n      <td>0.023317</td>\n      <td>0.976683</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Poor kid would have been better off with his h...</td>\n      <td>0.48</td>\n      <td>0.52</td>\n      <td>1</td>\n      <td>1.087948e-02</td>\n      <td>0.989121</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.036294</td>\n      <td>0.963706</td>\n      <td>1</td>\n      <td>0.157057</td>\n      <td>0.842943</td>\n      <td>1</td>\n      <td>0.221822</td>\n      <td>0.778178</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>Close your fucking legs, hoe. Use birth contro...</td>\n      <td>0.60</td>\n      <td>0.40</td>\n      <td>1</td>\n      <td>7.472763e-08</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.006292</td>\n      <td>0.993708</td>\n      <td>1</td>\n      <td>0.713035</td>\n      <td>0.286965</td>\n      <td>0</td>\n      <td>0.158761</td>\n      <td>0.841239</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>@user @user Please take away their license to ...</td>\n      <td>0.70</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>9.999939e-01</td>\n      <td>0.000006</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.997577</td>\n      <td>0.002423</td>\n      <td>0</td>\n      <td>0.865542</td>\n      <td>0.134458</td>\n      <td>0</td>\n      <td>0.961045</td>\n      <td>0.038955</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1</td>\n      <td>wow men are fucking trash and disgusting</td>\n      <td>0.19</td>\n      <td>0.81</td>\n      <td>1</td>\n      <td>6.262303e-09</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.903850</td>\n      <td>0.096150</td>\n      <td>0</td>\n      <td>0.523429</td>\n      <td>0.476571</td>\n      <td>1</td>\n      <td>0.428509</td>\n      <td>0.571491</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>I hope your an anal only slut. No one should h...</td>\n      <td>0.17</td>\n      <td>0.83</td>\n      <td>1</td>\n      <td>4.681266e-07</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.012478</td>\n      <td>0.987522</td>\n      <td>1</td>\n      <td>0.265263</td>\n      <td>0.734737</td>\n      <td>1</td>\n      <td>0.052255</td>\n      <td>0.947745</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1</td>\n      <td>do you have autism or something? why do you ta...</td>\n      <td>0.04</td>\n      <td>0.96</td>\n      <td>1</td>\n      <td>8.632649e-08</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.019523</td>\n      <td>0.980477</td>\n      <td>1</td>\n      <td>0.475986</td>\n      <td>0.524014</td>\n      <td>1</td>\n      <td>0.047550</td>\n      <td>0.952450</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>Stupid Asian Bitch You're an idiot and you sho...</td>\n      <td>0.20</td>\n      <td>0.80</td>\n      <td>1</td>\n      <td>6.193825e-06</td>\n      <td>0.999994</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.011486</td>\n      <td>0.988514</td>\n      <td>1</td>\n      <td>0.222132</td>\n      <td>0.777868</td>\n      <td>1</td>\n      <td>0.057266</td>\n      <td>0.942734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1</td>\n      <td>RT @user: List of bitches who want my dick... ...</td>\n      <td>0.58</td>\n      <td>0.42</td>\n      <td>1</td>\n      <td>9.999785e-01</td>\n      <td>0.000022</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.796263</td>\n      <td>0.203737</td>\n      <td>0</td>\n      <td>0.921312</td>\n      <td>0.078688</td>\n      <td>0</td>\n      <td>0.017409</td>\n      <td>0.982591</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_false2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:08:21.947887400Z",
     "start_time": "2025-03-05T21:08:21.933958100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_false_merged2 = merged_false2[\n",
    "    (merged_false2.pred_ens != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_nb != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_svm != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_gru != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_bert != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_rob != merged_false2.label_manual)]\n",
    "\n",
    "len(all_false_merged2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:08:22.147601200Z",
     "start_time": "2025-03-05T21:08:22.094216800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
