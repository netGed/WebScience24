{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.src.saving import load_model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer\n",
    "from nltk import word_tokenize\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.src.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funktionen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datenvorbereitung etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dataset(tokenizer, max_len, labels_data, tweets_data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for tweet in tweets_data:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels_data)\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, dataset, sampler):\n",
    "    if sampler == \"random\":\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            sampler=RandomSampler(dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    if sampler == \"sequential\":\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            sampler=SequentialSampler(dataset),\n",
    "            batch_size=batch_size\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_max_len(tweets, tokenizer):\n",
    "    max_len = 0\n",
    "\n",
    "    for sent in tweets:\n",
    "        input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "        max_len = max(max_len, len(input_ids))\n",
    "    return max_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vectorize_w2v(tweets, loaded_vectorizer, vector_size=300):\n",
    "    x_tokenized = tweets.map(word_tokenize)\n",
    "\n",
    "    def w2v_vector(x_tokenized, vector_size):\n",
    "        vec = np.zeros(vector_size).reshape((1, vector_size))\n",
    "        count = 0\n",
    "        for word in x_tokenized:\n",
    "            try:\n",
    "                vec += loaded_vectorizer.wv[word].reshape((1, vector_size))\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        return vec\n",
    "\n",
    "    tweets_w2v = np.zeros((len(x_tokenized), 300))\n",
    "    for i in range(len(x_tokenized)):\n",
    "        tweets_w2v[i, :] = w2v_vector(x_tokenized.iloc[i], 300)\n",
    "\n",
    "    return tweets_w2v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_and_vectorize_for_lstm(tokenizer, glove_embeddings, tweets, vector_size=200, max_seq_len=50):\n",
    "    X_sequences = tokenizer.texts_to_sequences(tweets)\n",
    "    X_padded = pad_sequences(X_sequences, padding='post', maxlen=max_seq_len)\n",
    "\n",
    "    def get_glove_vectors(sequence, glove_embeddings, vector_size, max_seq_len):\n",
    "        vectors = [glove_embeddings.get(tokenizer.index_word.get(idx, ''), np.zeros(vector_size)) for idx in sequence]\n",
    "\n",
    "        # Padding sicherstellen\n",
    "        if len(vectors) < max_seq_len:\n",
    "            vectors.extend([np.zeros(vector_size)] * (max_seq_len - len(vectors)))\n",
    "        else:\n",
    "            vectors = vectors[:max_seq_len]\n",
    "\n",
    "        return np.array(vectors, dtype=np.float32)\n",
    "\n",
    "    X_vectors = np.array([get_glove_vectors(seq, glove_embeddings, vector_size, max_seq_len) for seq in X_padded],\n",
    "                         dtype=np.float32)\n",
    "\n",
    "    return X_vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluationsfunktionen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Metriken"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_predictions_bert(test_dataloader, model):\n",
    "    predictions = []\n",
    "    print(\"Prediction start.\")\n",
    "    total_t0 = time.time()\n",
    "    batches_completed = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            predictions.extend(list(pred_flat))\n",
    "\n",
    "        batches_completed += 1\n",
    "\n",
    "    print(\"Total Prediction took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model_name, y_prediction, y_true, sample_size, df, dataset_name, threshold):\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_prediction)\n",
    "    precision = precision_score(y_true, y_prediction)\n",
    "    recall = recall_score(y_true, y_prediction)\n",
    "    f1 = f1_score(y_true, y_prediction)\n",
    "    mcc = matthews_corrcoef(y_true, y_prediction)\n",
    "\n",
    "    df.loc[len(df.index)] = [model_name, dataset_name, sample_size, threshold, accuracy, precision, recall, f1, mcc]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model_bert(tokenizer, model, model_name, labels, tweets, batch_size, data_size, df, dataset_name, threshold,\n",
    "                    max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = get_max_len(tweets, tokenizer)\n",
    "    dataset = create_dataset(tokenizer=tokenizer, max_len=max_len, labels_data=labels,\n",
    "                             tweets_data=tweets)\n",
    "    dataloader = get_dataloader(batch_size=batch_size, sampler=\"sequential\", dataset=dataset)\n",
    "    predictions = get_predictions_bert(test_dataloader=dataloader, model=model)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model_ensemble(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorizer.transform(tweets)\n",
    "    predictions = (model.predict_proba(X_vectorized)[:, 1] >= threshold)\n",
    "    # predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model_bayes(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorize_w2v(tweets, vectorizer)\n",
    "    predictions = (model.predict_proba(X_vectorized)[:, 1] >= threshold)\n",
    "    # predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model_svm(vectorizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold):\n",
    "    X_vectorized = vectorizer.transform(tweets)\n",
    "    predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model_gru(tokenizer, model, model_name, labels, tweets, data_size, df, dataset_name, threshold, max_len):\n",
    "    X_data = [str(x) for x in tweets]\n",
    "    tweets_seq = tokenizer.texts_to_sequences(X_data)\n",
    "    tweets_padded = pad_sequences(tweets_seq, padding='post', maxlen=max_len)\n",
    "    predictions = (model.predict(tweets_padded) > threshold).astype(int)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model_lstm(tokenizer, vectorizer, model, labels, tweets, threshold, model_name, data_size, df, dataset_name):\n",
    "    X_data_vectorized = tokenize_and_vectorize_for_lstm(\n",
    "        glove_embeddings=vectorizer,\n",
    "        tweets=tweets,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    predictions = (model.predict(X_data_vectorized) > threshold).astype(int)\n",
    "\n",
    "    add_to_eval_df(\n",
    "        model_name=model_name,\n",
    "        y_prediction=predictions,\n",
    "        y_true=labels,\n",
    "        sample_size=data_size,\n",
    "        df=df,\n",
    "        dataset_name=dataset_name,\n",
    "        threshold=threshold\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Wahrscheinlichkeiten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_predictions_with_probabilities_bert(test_dataloader, model, threshold):\n",
    "    predictions = []\n",
    "    predictions_proba = []\n",
    "    print(\"Prediction start.\")\n",
    "    total_t0 = time.time()\n",
    "    batches_completed = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            pred_with_thresh = [1 if value[1] > threshold else 0 for value in output.logits.softmax(dim=-1).tolist()]\n",
    "            pred_with_thresh = np.array(pred_with_thresh)\n",
    "\n",
    "            predictions.extend(list(pred_with_thresh))\n",
    "            predictions_proba.extend(output.logits.softmax(dim=-1).tolist())\n",
    "\n",
    "        batches_completed += 1\n",
    "\n",
    "    print(\"Prediction finished.\")\n",
    "    print(\"Total Prediction took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "    return predictions, predictions_proba"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_to_detail_eval_df(dataframe, predictions, probabilities=None):\n",
    "    if probabilities is not None:\n",
    "        dataframe[\"zero_proba\"] = pd.Series((v[0] for v in probabilities), index=dataframe.index)\n",
    "        dataframe[\"one_proba\"] = pd.Series((v[1] for v in probabilities), index=dataframe.index)\n",
    "    else:\n",
    "        dataframe[\"zero_proba\"] = 0\n",
    "        dataframe[\"one_proba\"] = 0\n",
    "    dataframe[\"pred\"] = predictions\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_bert(model, tokenizer, data, label_name, tweet_name, batch_size, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "    y_data = data[label_name].values\n",
    "    max_len = get_max_len(x_data, tokenizer)\n",
    "    test_dataset = create_dataset(tokenizer=tokenizer, max_len=max_len, labels_data=y_data,\n",
    "                                  tweets_data=x_data)\n",
    "    test_dataloader = get_dataloader(batch_size=batch_size, sampler=\"sequential\", dataset=test_dataset)\n",
    "\n",
    "    predictions, predictions_proba = get_predictions_with_probabilities_bert(test_dataloader=test_dataloader,\n",
    "                                                                             model=model, threshold=threshold)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=predictions_proba)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_ensemble(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_vectorized = vectorizer.transform(x_data)\n",
    "    probabilities = model.predict_proba(X_vectorized)\n",
    "    predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_nb(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name]\n",
    "\n",
    "    X_vectorized = vectorize_w2v(x_data, vectorizer)\n",
    "    probabilities = model.predict_proba(X_vectorized)\n",
    "    predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_svm(model, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_vectorized = vectorizer.transform(x_data)\n",
    "    predictions = model.predict(X_vectorized)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_gru(model, tokenizer, data, tweet_name, threshold, max_len):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_data = [str(x) for x in x_data]\n",
    "    tweets_seq = tokenizer.texts_to_sequences(X_data)\n",
    "    tweets_padded = pad_sequences(tweets_seq, padding='post', maxlen=max_len)\n",
    "\n",
    "    probabilities = model.predict(tweets_padded)\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    new_array = []\n",
    "    for proba in probabilities:\n",
    "        complement = 1 - proba[0]\n",
    "        new_array.append([complement, proba[0]])\n",
    "    probabilities = pd.Series(new_array)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_pred_and_probas_lstm(model, tokenizer, vectorizer, data, tweet_name, threshold):\n",
    "    x_data = data[tweet_name].values\n",
    "\n",
    "    X_data_vectorized = tokenize_and_vectorize_for_lstm(\n",
    "        glove_embeddings=vectorizer,\n",
    "        tweets=x_data,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    probabilities = model.predict(X_data_vectorized)\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    new_array = []\n",
    "    for proba in probabilities:\n",
    "        complement = 1 - proba[0]\n",
    "        new_array.append([complement, proba[0]])\n",
    "    probabilities = pd.Series(new_array)\n",
    "\n",
    "    add_to_detail_eval_df(dataframe=data,\n",
    "                          predictions=predictions,\n",
    "                          probabilities=probabilities)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Modelle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODELS_PATH = \"../../webapp/backend/app/models\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nb_vectorizer = joblib.load(MODELS_PATH + \"/nb/vectorizer_nb_tfidf.joblib\")\n",
    "nb_model = joblib.load(MODELS_PATH + \"/nb/model_nb_tfidf_comp.joblib\")\n",
    "nb_modelname = \"ComplementNB\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ensemble_vectorizer = joblib.load(MODELS_PATH + \"/ensemble/tfidf_vectorizer_for_brf.joblib\")\n",
    "ensemble_model = joblib.load(MODELS_PATH + \"/ensemble/tfidf_balancedrandomforest.joblib\")\n",
    "ensemble_modelname = \"BalancedRandomForest\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_vectorizer = joblib.load(MODELS_PATH + \"/svc/tfidf_vectorizer_svm.joblib\")\n",
    "svm_model = joblib.load(MODELS_PATH + \"/svc/model_svc.joblib\")\n",
    "svm_modelname = \"LinearSVC\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4 RNN-GRU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len_gru = 40\n",
    "gru_model = load_model(MODELS_PATH + \"/gru/gru-model_mixed-dataset.keras\")\n",
    "with open(MODELS_PATH + \"/gru/tokenizer_mixed-dataset.pkl\", 'rb') as f:\n",
    "    gru_tokenizer = pickle.load(f)\n",
    "gru_modelname = \"RNN-GRU\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.5 RNN-LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm_model = load_model(\"models/lstm/model_lstm_17.keras\")\n",
    "with open(\"models/lstm/tokenizer_lstm.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tokenizer_data = f.read()\n",
    "    lstm_tokenizer = tokenizer_from_json(tokenizer_data)\n",
    "lstm_glove_embeddings = {}\n",
    "with open(\"models/lstm/glove.6B.200d.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        lstm_glove_embeddings[word] = vector\n",
    "lstm_modelname = \"RNN-LSTM\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.6 BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH_BERT_TUNED = MODELS_PATH + \"/bert/bert_mixed_imran\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(PATH_BERT_TUNED, local_files_only=True)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(PATH_BERT_TUNED, local_files_only=True)\n",
    "bert_modelname = \"bert_tuned_uncased\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.7 RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH_ROBERTA_TUNED = MODELS_PATH + \"/roberta/roberta_hate_mixed_cleaned\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(PATH_ROBERTA_TUNED, local_files_only=True)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(PATH_ROBERTA_TUNED, local_files_only=True)\n",
    "roberta_modelname = \"roberta_hate_mixed_cleaned\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Mixed-Train (cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mixed_train_cleaned = pd.read_csv(\"../../data/mixed_dataset/train_cleaned.csv\", index_col=0)\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned[df_mixed_train_cleaned.tweet_cleaned.notna()]\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned.sample(n=100)\n",
    "\n",
    "df_mixed_train_cleaned = df_mixed_train_cleaned[[\"label\", \"tweet_cleaned\"]]\n",
    "df_mixed_train_cleaned.head(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Mixed-Train (uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mixed_train_uncleaned = pd.read_csv(\"../../data/mixed_dataset/train_cleaned.csv\", index_col=0)\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned[df_mixed_train_uncleaned.tweet.notna()]\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned.sample(n=100)\n",
    "\n",
    "df_mixed_train_uncleaned = df_mixed_train_uncleaned[[\"label\", \"tweet\"]]\n",
    "print(df_mixed_train_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_train_uncleaned))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Mixed-Test (cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mixed_test_cleaned = pd.read_csv(\"../../data/mixed_dataset/test_cleaned.csv\", index_col=0)\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned[df_mixed_test_cleaned.tweet_cleaned.notna()]\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned.sample(n=100)\n",
    "\n",
    "df_mixed_test_cleaned = df_mixed_test_cleaned[[\"label\", \"tweet_cleaned\"]]\n",
    "print(df_mixed_test_cleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_cleaned))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Mixed-Test (cleaned-RNN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mixed_test_cleaned_rnn = pd.read_csv(\"../../data/mixed_dataset/test_cleaned_rnn.csv\", index_col=0)\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn[df_mixed_test_cleaned_rnn.tweet_cleaned.notna()]\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn.sample(n=100)\n",
    "\n",
    "df_mixed_test_cleaned_rnn = df_mixed_test_cleaned_rnn[[\"label\", \"tweet_cleaned\"]]\n",
    "print(df_mixed_test_cleaned_rnn.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_cleaned_rnn))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.5 Mixed-Test (uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mixed_test_uncleaned = pd.read_csv(\"../../data/mixed_dataset/test_cleaned.csv\", index_col=0)\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned[df_mixed_test_uncleaned.tweet.notna()]\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned.sample(n=100)\n",
    "\n",
    "df_mixed_test_uncleaned = df_mixed_test_uncleaned[[\"label\", \"tweet\", ]]\n",
    "print(df_mixed_test_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_test_uncleaned))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.6 Mixed-Test (manual-labeled, uncleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mixed_manual_uncleaned = pd.read_csv(\"../../data/manual_labeled/manual_labeled_group.csv\", index_col=0)\n",
    "df_mixed_manual_uncleaned = df_mixed_manual_uncleaned[df_mixed_manual_uncleaned.tweet.notna()]\n",
    "\n",
    "df_mixed_manual_uncleaned = df_mixed_manual_uncleaned[[\"label_manual\", \"tweet\", ]]\n",
    "print(df_mixed_manual_uncleaned.head(1))\n",
    "print(\"Daten: \\t\", len(df_mixed_manual_uncleaned))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Allgemeine Evaluation - Metriken"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(label_col, tweet_col, data, dataset_name, threshold):\n",
    "    evaluation_df = pd.DataFrame(\n",
    "        columns=[\"model\", \"dataset_name\", \"sample_size\", \"threshold\", \"accuracy\", \"precision\", \"recall\", \"f1_score\",\n",
    "                 \"mcc\"])\n",
    "    eval_model_ensemble(vectorizer=ensemble_vectorizer,\n",
    "                        model=ensemble_model,\n",
    "                        model_name=ensemble_modelname,\n",
    "                        labels=data[label_col],\n",
    "                        tweets=data[tweet_col],\n",
    "                        data_size=len(data),\n",
    "                        df=evaluation_df,\n",
    "                        dataset_name=dataset_name,\n",
    "                        threshold=threshold)\n",
    "\n",
    "    eval_model_bayes(vectorizer=nb_vectorizer,\n",
    "                     model=nb_model,\n",
    "                     model_name=nb_modelname,\n",
    "                     labels=data[label_col],\n",
    "                     tweets=data[tweet_col],\n",
    "                     data_size=len(data),\n",
    "                     df=evaluation_df,\n",
    "                     dataset_name=dataset_name,\n",
    "                     threshold=threshold)\n",
    "\n",
    "    eval_model_svm(vectorizer=svm_vectorizer,\n",
    "                   model=svm_model,\n",
    "                   model_name=svm_modelname,\n",
    "                   labels=data[label_col],\n",
    "                   tweets=data[tweet_col],\n",
    "                   data_size=len(data),\n",
    "                   df=evaluation_df,\n",
    "                   dataset_name=dataset_name,\n",
    "                   threshold=\"None\")\n",
    "\n",
    "    eval_model_lstm(tokenizer=lstm_tokenizer,\n",
    "                    vectorizer=lstm_glove_embeddings,\n",
    "                    model=lstm_model,\n",
    "                    model_name=lstm_modelname,\n",
    "                    labels=data[label_col],\n",
    "                    tweets=data[tweet_col],\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    eval_model_gru(tokenizer=gru_tokenizer,\n",
    "                   model=gru_model,\n",
    "                   model_name=gru_modelname,\n",
    "                   labels=data[label_col],\n",
    "                   tweets=data[tweet_col],\n",
    "                   data_size=len(data),\n",
    "                   df=evaluation_df,\n",
    "                   dataset_name=dataset_name,\n",
    "                   threshold=threshold,\n",
    "                   max_len=40)\n",
    "\n",
    "    eval_model_bert(tokenizer=bert_tokenizer,\n",
    "                    model=bert_model,\n",
    "                    model_name=bert_modelname,\n",
    "                    labels=data[label_col].values,\n",
    "                    tweets=data[tweet_col].values,\n",
    "                    batch_size=16,\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    eval_model_bert(tokenizer=roberta_tokenizer,\n",
    "                    model=roberta_model,\n",
    "                    model_name=roberta_modelname,\n",
    "                    labels=data[label_col].values,\n",
    "                    tweets=data[tweet_col].values,\n",
    "                    batch_size=16,\n",
    "                    data_size=len(data),\n",
    "                    df=evaluation_df,\n",
    "                    dataset_name=dataset_name,\n",
    "                    threshold=threshold)\n",
    "\n",
    "    return evaluation_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1 Alle Datensätze - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.1 Mixed-Train (cleaned) - df_mixed_train_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned = evaluate(label_col=\"label\",\n",
    "                                          tweet_col=\"tweet_cleaned\",\n",
    "                                          data=df_mixed_train_cleaned,\n",
    "                                          dataset_name=\"df_mixed_train_cleaned\",\n",
    "                                          threshold=0.5,\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.2 Mixed-Train (uncleaned) - df_mixed_train_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_uncleaned = evaluate(label_col=\"label\",\n",
    "                                            tweet_col=\"tweet\",\n",
    "                                            data=df_mixed_train_uncleaned,\n",
    "                                            dataset_name=\"df_mixed_train_uncleaned\",\n",
    "                                            threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_uncleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.3 Mixed-Test (cleaned) - df_mixed_test_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned = evaluate(label_col=\"label\",\n",
    "                                         tweet_col=\"tweet_cleaned\",\n",
    "                                         data=df_mixed_test_cleaned,\n",
    "                                         dataset_name=\"df_mixed_test_cleaned\",\n",
    "                                         threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.4 Mixed-Test (cleaned-RNN) - df_mixed_test_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn = evaluate(label_col=\"label\",\n",
    "                                             tweet_col=\"tweet_cleaned\",\n",
    "                                             data=df_mixed_test_cleaned_rnn,\n",
    "                                             dataset_name=\"df_mixed_test_cleaned_rnn\",\n",
    "                                             threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.5 Mixed-Test (uncleaned) - df_mixed_test_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned = evaluate(label_col=\"label\",\n",
    "                                           tweet_col=\"tweet\",\n",
    "                                           data=df_mixed_test_uncleaned,\n",
    "                                           dataset_name=\"df_mixed_test_uncleaned\",\n",
    "                                           threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1.6 Mixed-Test (manual-labeled, uncleaned) - df_mixed_manual_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned = evaluate(label_col=\"label_manual\",\n",
    "                                             tweet_col=\"tweet\",\n",
    "                                             data=df_mixed_manual_uncleaned,\n",
    "                                             dataset_name=\"df_mixed_manual_uncleaned\",\n",
    "                                             threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Alle Datensätze - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.1 Mixed-Train (cleaned) - df_mixed_train_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned2 = evaluate(label_col=\"label\",\n",
    "                                           tweet_col=\"tweet_cleaned\",\n",
    "                                           data=df_mixed_train_cleaned,\n",
    "                                           dataset_name=\"df_mixed_train_cleaned\",\n",
    "                                           threshold=0.35,\n",
    "                                           )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_cleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.2 Mixed-Train (uncleaned) - df_mixed_train_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_uncleaned2 = evaluate(label_col=\"label\",\n",
    "                                             tweet_col=\"tweet\",\n",
    "                                             data=df_mixed_train_uncleaned,\n",
    "                                             dataset_name=\"df_mixed_train_uncleaned\",\n",
    "                                             threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_train_uncleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.3 Mixed-Test (cleaned) - df_mixed_test_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned2 = evaluate(label_col=\"label\",\n",
    "                                          tweet_col=\"tweet_cleaned\",\n",
    "                                          data=df_mixed_test_cleaned,\n",
    "                                          dataset_name=\"df_mixed_test_cleaned\",\n",
    "                                          threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.4 Mixed-Test (cleaned-RNN) - df_mixed_test_cleaned_rnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn2 = evaluate(label_col=\"label\",\n",
    "                                              tweet_col=\"tweet_cleaned\",\n",
    "                                              data=df_mixed_test_cleaned_rnn,\n",
    "                                              dataset_name=\"df_mixed_test_cleaned_rnn\",\n",
    "                                              threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_cleaned_rnn2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.5 Mixed-Test (uncleaned) - df_mixed_test_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned2 = evaluate(label_col=\"label\",\n",
    "                                            tweet_col=\"tweet\",\n",
    "                                            data=df_mixed_test_uncleaned,\n",
    "                                            dataset_name=\"df_mixed_test_uncleaned\",\n",
    "                                            threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_test_uncleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.6 Mixed-Test (manual-labeled, uncleaned) - df_mixed_manual_uncleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned2 = evaluate(label_col=\"label_manual\",\n",
    "                                              tweet_col=\"tweet\",\n",
    "                                              data=df_mixed_manual_uncleaned,\n",
    "                                              dataset_name=\"df_mixed_manual_uncleaned\",\n",
    "                                              threshold=0.35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_mixed_manual_uncleaned2.sort_values(by=[\"f1_score\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Detaillierte Evaluation - Tweetbetrachtung\n",
    "\n",
    "Fragen:\n",
    "- gibt es Tweets, die von keinem Modell korrekt klassifiziert werden können? bzw. nur von wenigen? was haben diese Tweets gemeinsam?\n",
    "- gibt es Tweets, die von allen Modellen korrekt klassifiziert werden können? bzw. von vielen? was haben diese Tweets gemeinsam?\n",
    "-\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1 manuell gelabelte Tweets - Schwellwert 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_false = df_mixed_manual_uncleaned.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_ensemble(model=ensemble_model,\n",
    "                             vectorizer=ensemble_vectorizer,\n",
    "                             data=merged_false,\n",
    "                             tweet_name=\"tweet\",\n",
    "                             threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_ens',\n",
    "                             'one_proba': '1_ens',\n",
    "                             'pred': 'pred_ens'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aufruf wie Ensemble => richtig!\n",
    "add_pred_and_probas_ensemble(model=nb_model,\n",
    "                             vectorizer=nb_vectorizer,\n",
    "                             data=merged_false,\n",
    "                             tweet_name=\"tweet\",\n",
    "                             threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_nb',\n",
    "                             'one_proba': '1_nb',\n",
    "                             'pred': 'pred_nb'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_svm(model=svm_model,\n",
    "                        vectorizer=svm_vectorizer,\n",
    "                        data=merged_false,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_svm',\n",
    "                             'one_proba': '1_svm',\n",
    "                             'pred': 'pred_svm'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_lstm(model=lstm_model,\n",
    "                         tokenizer=lstm_tokenizer,\n",
    "                         vectorizer=lstm_glove_embeddings,\n",
    "                         data=merged_false,\n",
    "                         tweet_name=\"tweet\",\n",
    "                         threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_lstm',\n",
    "                             'one_proba': '1_lstm',\n",
    "                             'pred': 'pred_lstm'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_gru(model=gru_model,\n",
    "                        tokenizer=gru_tokenizer,\n",
    "                        data=merged_false,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.5,\n",
    "                        max_len=40)\n",
    "merged_false.rename(columns={'zero_proba': '0_gru',\n",
    "                             'one_proba': '1_gru',\n",
    "                             'pred': 'pred_gru'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_bert(model=bert_model,\n",
    "                         tokenizer=bert_tokenizer,\n",
    "                         data=merged_false,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_bert',\n",
    "                             'one_proba': '1_bert',\n",
    "                             'pred': 'pred_bert'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_bert(model=roberta_model,\n",
    "                         tokenizer=roberta_tokenizer,\n",
    "                         data=merged_false,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.5)\n",
    "merged_false.rename(columns={'zero_proba': '0_rob',\n",
    "                             'one_proba': '1_rob',\n",
    "                             'pred': 'pred_rob'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_false"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_false_merged = merged_false[\n",
    "    (merged_false.pred_ens != merged_false.label_manual) &\n",
    "    (merged_false.pred_nb != merged_false.label_manual) &\n",
    "    (merged_false.pred_svm != merged_false.label_manual) &\n",
    "    (merged_false.pred_gru != merged_false.label_manual) &\n",
    "    (merged_false.pred_bert != merged_false.label_manual) &\n",
    "    (merged_false.pred_rob != merged_false.label_manual)]\n",
    "\n",
    "len(all_false_merged)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 manuell gelabelte Tweets - Schwellwert 0.35"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_false2 = df_mixed_manual_uncleaned.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_ensemble(model=ensemble_model,\n",
    "                             vectorizer=ensemble_vectorizer,\n",
    "                             data=merged_false2,\n",
    "                             tweet_name=\"tweet\",\n",
    "                             threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_ens',\n",
    "                              'one_proba': '1_ens',\n",
    "                              'pred': 'pred_ens'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aufruf wie Ensemble => richtig!\n",
    "add_pred_and_probas_nb(model=nb_model,\n",
    "                       vectorizer=nb_vectorizer,\n",
    "                       data=merged_false2,\n",
    "                       tweet_name=\"tweet\",\n",
    "                       threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_nb',\n",
    "                              'one_proba': '1_nb',\n",
    "                              'pred': 'pred_nb'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_svm(model=svm_model,\n",
    "                        vectorizer=svm_vectorizer,\n",
    "                        data=merged_false2,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_svm',\n",
    "                              'one_proba': '1_svm',\n",
    "                              'pred': 'pred_svm'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_lstm(model=lstm_model,\n",
    "                         tokenizer=lstm_tokenizer,\n",
    "                         vectorizer=lstm_glove_embeddings,\n",
    "                         data=merged_false2,\n",
    "                         tweet_name=\"tweet\",\n",
    "                         threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_lstm',\n",
    "                             'one_proba': '1_lstm',\n",
    "                             'pred': 'pred_lstm'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_gru(model=gru_model,\n",
    "                        tokenizer=gru_tokenizer,\n",
    "                        data=merged_false2,\n",
    "                        tweet_name=\"tweet\",\n",
    "                        threshold=0.35,\n",
    "                        max_len=40)\n",
    "merged_false2.rename(columns={'zero_proba': '0_gru',\n",
    "                              'one_proba': '1_gru',\n",
    "                              'pred': 'pred_gru'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_bert(model=bert_model,\n",
    "                         tokenizer=bert_tokenizer,\n",
    "                         data=merged_false2,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_bert',\n",
    "                              'one_proba': '1_bert',\n",
    "                              'pred': 'pred_bert'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pred_and_probas_bert(model=roberta_model,\n",
    "                         tokenizer=roberta_tokenizer,\n",
    "                         data=merged_false2,\n",
    "                         label_name=\"label_manual\",\n",
    "                         tweet_name=\"tweet\",\n",
    "                         batch_size=16,\n",
    "                         threshold=0.35)\n",
    "merged_false2.rename(columns={'zero_proba': '0_rob',\n",
    "                              'one_proba': '1_rob',\n",
    "                              'pred': 'pred_rob'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_false2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_false_merged2 = merged_false2[\n",
    "    (merged_false2.pred_ens != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_nb != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_svm != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_gru != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_bert != merged_false2.label_manual) &\n",
    "    (merged_false2.pred_rob != merged_false2.label_manual)]\n",
    "\n",
    "len(all_false_merged2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
