{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\nasiba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\nasiba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\nasiba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\nasiba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\nasiba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import os\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer, PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from ftfy import fix_encoding\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>father selfish drag kid run</td>\n",
       "      <td>1</td>\n",
       "      <td>['#run']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "\n",
       "                                                                                                    tweet  \\\n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "\n",
       "                 tweet_cleaned  user_handle  hashtags emojis  \n",
       "0  father selfish drag kid run            1  ['#run']    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "csv_path  = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_cleaned.csv'))\n",
    "dict_path = os.path.abspath(os.path.join(current_dir, '../nasiba/data/frequency_dictionary_en_82_765.txt'))\n",
    "df_cleaned = pd.read_csv(csv_path, encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "df_cleaned=df_cleaned[df_cleaned['tweet_cleaned'].notna()]\n",
    "df_cleaned.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "Die Kernintuition hinter dem Bag of Words (BoW)-Modell ist, dass unser Algorithmus, wenn er ähnliche Wörter mit ähnlicher Häufigkeit erkennt, die Dokumente als derselben Klasse zugehörig klassifiziert. Dabei spielen die Reihenfolge der Wörter und der Kontext keine Rolle; wichtig sind das Vorhandensein und die Häufigkeit der Wörter.\n",
    "\n",
    "In BoW wird jedes Wort als Koordinate in einem n-dimensionalen Raum dargestellt. Wenn wir den binären Parameter auf „True“ setzen, wird jedes Wort, das mehr als einmal vorkommt, trotzdem so behandelt, als ob es nur einmal vorkommt. Folglich sind die Koordinaten binär und nur mit 0en und 1en gefüllt.\n",
    "\n",
    "### Beispieldaten\n",
    "| Index | Text | Ausgabe |\n",
    "|-------|--------------------------|--------|\n",
    "| D1 | Personen folgen Mr.Beast | 1 |\n",
    "| D2 | Mr.Beast folgt Mr.Beast | 1 |\n",
    "| D3 | Personen schreiben Kommentar | 0 |\n",
    "| D4 | Mr.Beast schreibt Kommentar | 0 |\n",
    "\n",
    "### BoW mit `binary=False`\n",
    "\n",
    "| Personen | Folgen | Mr.Beast | Schreiben | Kommentieren | Index |\n",
    "|--------|--------|----------|-------|---------|-------|\n",
    "| 1 | 1 | 1 | 0 | 0 | D1 |\n",
    "| 0 | 1 | 2 | 0 | 0 | D2 |\n",
    "| 1 | 0 | 0 | 1 | 1 | D3 |\n",
    "| 0 | 0 | 1 | 1 | 1 | D4 |\n",
    "\n",
    "### BoW mit `binary=True`\n",
    "\n",
    "| Personen | Folgen | Mr.Beast | Schreiben | Kommentieren | Index |\n",
    "|--------|--------|----------|-------|---------|-------|\n",
    "| 1 | 1 | 1 | 0 | 0 | D1 |\n",
    "| 0 | 1 | 1 | 0 | 0 | D2 |\n",
    "| 1 | 0 | 0 | 1 | 1 | D3 |\n",
    "| 0 | 0 | 1 | 1 | 1 | D4 |\n",
    "\n",
    "### Filtern seltener Wörter\n",
    "\n",
    "Um seltene Wörter zu entfernen, können Sie den Parameter „max_features“ verwenden, der das Vokabular auf die häufigsten Wörter beschränkt. Wenn Sie beispielsweise „max_features=1/2“ festlegen, werden alle Wörter ignoriert, deren Häufigkeit unter diesem Schwellenwert liegt.\n",
    "\n",
    "### Vorteile von Bag of Words\n",
    "\n",
    "- **Einfachheit und Intuitiv**: Leicht zu implementieren und zu verstehen.\n",
    "- **Milderung des Out-of-Vocabulary (OOV)-Problems**: Da das Modell ein festes Vokabular verwendet, wird das OOV-Problem vermieden, das bei der One-Hot-Kodierung auftritt.\n",
    "\n",
    "### Nachteile von Bag of Words\n",
    "\n",
    "- **Spärlichkeit**: Bei einem großen Vokabular enthält die Darstellung viele Nullen, was möglicherweise zu Überanpassung führt.\n",
    "- **Informationsverlust**: Ignoriert Wortreihenfolge und Kontext, was zu einem Verlust der semantischen Bedeutung führt.\n",
    "- Beispiel: „Dies ist ein sehr guter Film“ und „Dies ist kein sehr guter Film“ können ähnlich dargestellt werden, was zu Problemen mit der Kosinusähnlichkeit führen kann.\n",
    "\n",
    "### Kosinusähnlichkeit\n",
    "\n",
    "Die Kosinusähnlichkeit misst den Kosinus des Winkels zwischen zwei Vektoren und liefert eine Metrik für ihre Ähnlichkeit. Die Formel lautet:\n",
    "\n",
    "$$\n",
    "\\text{Kosinusähnlichkeit} = \\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "$$\n",
    "\n",
    "Mithilfe der Kosinusähnlichkeit können „Dies ist ein sehr guter Film“ und „Dies ist kein sehr guter Film“ aufgrund des geringen Winkels zwischen ihren Vektordarstellungen im BoW-Modell ähnlich erscheinen.\n",
    "\n",
    "Mit BoW können Sie Textdaten schnell und effizient in numerische Merkmale für maschinelle Lernalgorithmen umwandeln. Beachten Sie jedoch die Einschränkungen und ziehen Sie fortgeschrittenere Techniken wie TF-IDF, Wort-Einbettungen oder Sprachmodelle in Betracht, um differenziertere Textinformationen zu erfassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aamp' 'aap' 'ab' ... 'zootopia' 'zoro' 'zzz']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamp</th>\n",
       "      <th>aap</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abasel</th>\n",
       "      <th>abba</th>\n",
       "      <th>abc</th>\n",
       "      <th>abe</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>zionazi</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zipline</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zootopia</th>\n",
       "      <th>zoro</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27649 rows × 6325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aamp  aap  ab  abandon  abasel  abba  abc  abe  ability  able  ...  \\\n",
       "0         0    0   0        0       0     0    0    0        0     0  ...   \n",
       "1         0    0   0        0       0     0    0    0        0     0  ...   \n",
       "2         0    0   0        0       0     0    0    0        0     0  ...   \n",
       "3         0    0   0        0       0     0    0    0        0     0  ...   \n",
       "4         0    0   0        0       0     0    0    0        0     0  ...   \n",
       "...     ...  ...  ..      ...     ...   ...  ...  ...      ...   ...  ...   \n",
       "27644     0    0   0        0       0     0    0    0        0     0  ...   \n",
       "27645     0    0   0        0       0     0    0    0        0     0  ...   \n",
       "27646     0    0   0        0       0     0    0    0        0     0  ...   \n",
       "27647     0    0   0        0       0     0    0    0        0     0  ...   \n",
       "27648     0    0   0        0       0     0    0    0        0     0  ...   \n",
       "\n",
       "       zionazi  zionism  zipline  zipper  zombie  zone  zoo  zootopia  zoro  \\\n",
       "0            0        0        0       0       0     0    0         0     0   \n",
       "1            0        0        0       0       0     0    0         0     0   \n",
       "2            0        0        0       0       0     0    0         0     0   \n",
       "3            0        0        0       0       0     0    0         0     0   \n",
       "4            0        0        0       0       0     0    0         0     0   \n",
       "...        ...      ...      ...     ...     ...   ...  ...       ...   ...   \n",
       "27644        0        0        0       0       0     0    0         0     0   \n",
       "27645        0        0        0       0       0     0    0         0     0   \n",
       "27646        0        0        0       0       0     0    0         0     0   \n",
       "27647        0        0        0       0       0     0    0         0     0   \n",
       "27648        0        0        0       0       0     0    0         0     0   \n",
       "\n",
       "       zzz  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "...    ...  \n",
       "27644    0  \n",
       "27645    0  \n",
       "27646    0  \n",
       "27647    0  \n",
       "27648    0  \n",
       "\n",
       "[27649 rows x 6325 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df_cleaned['tweet_cleaned'])\n",
    "\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab)\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vocab)\n",
    "bow_df \n",
    "#final_df = pd.concat([df_cleaned[['Index', 'Output']], bow_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF behebt die Einschränkung der Gleichgewichtung von Begriffen in Bag of Words, indem Begriffen, die im Korpus selten, in einem bestimmten Dokument jedoch häufig vorkommen, höhere Gewichte zugewiesen werden. Dieser Ansatz ist entscheidend, um die Bedeutung von Begriffen in Dokumenten für Aufgaben wie Informationsabruf und Text Mining zu erfassen.\n",
    "\n",
    "### Begriffshäufigkeit (TF)\n",
    "\n",
    "Die Begriffshäufigkeit (TF) misst, wie häufig ein Begriff in einem Dokument im Verhältnis zur Gesamtzahl der Begriffe in diesem Dokument vorkommt. Sie wird wie folgt berechnet:\n",
    "\n",
    "$$\n",
    "\\text{TF}(t, d) = \\frac{\\text{Anzahl der Vorkommen des Begriffs } t \\text{ im Dokument } d}{\\text{Gesamtzahl der Begriffe im Dokument } d}\n",
    "$$\n",
    "\n",
    "#### Beispiel:\n",
    "\n",
    "Betrachten Sie ein Dokument: „Die Katze saß auf der Matte.“\n",
    "\n",
    "- Häufigkeit der Begriffe für jeden Begriff:\n",
    "- TF(\"the\") = 2/6 = 1/3\n",
    "- TF(\"cat\") = 1/6\n",
    "- TF(\"sat\") = 1/6\n",
    "- TF(\"on\") = 1/6\n",
    "- TF(\"mat\") = 1/6\n",
    "\n",
    "### Inverse Dokumenthäufigkeit (IDF)\n",
    "\n",
    "Die inverse Dokumenthäufigkeit (IDF) misst, wie wichtig ein Begriff in allen Dokumenten eines Korpus ist. Sie wird wie folgt berechnet:\n",
    "\n",
    "$$\n",
    "\\text{IDF}(t) = \\log\\left(\\frac{\\text{Gesamtzahl der Dokumente}}{\\text{Anzahl der Dokumente, die den Begriff } t enthalten}\\right)\n",
    "$$\n",
    "\n",
    "Sie quantifiziert die Seltenheit eines Begriffs in allen Dokumenten und gewichtet Begriffe, die in allen Dokumenten weniger häufig vorkommen, höher.\n",
    "\n",
    "#### Beispiel:\n",
    "\n",
    "Betrachten Sie ein Corpus mit 100 Dokumenten und der Begriff „Katze“ erscheint in 10 davon:\n",
    "\n",
    "- IDF(„Katze“) = log(100/10) = log(10) ≈ 2,3026\n",
    "\n",
    "### TF-IDF-Score\n",
    "\n",
    "Der TF-IDF-Score für einen Begriff in einem Dokument ist das Produkt seiner Begriffshäufigkeit und seiner inversen Dokumenthäufigkeit:\n",
    "\n",
    "$$\n",
    "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
    "$$\n",
    "\n",
    "### Beispielberechnung:\n",
    "\n",
    "Berechnen wir TF-IDF für den gegebenen Beispieldatensatz:\n",
    "\n",
    "#### Schritt 1: TF berechnen\n",
    "\n",
    "Der Einfachheit halber nehmen wir binäres Zählen an:\n",
    "\n",
    "| Index | Text | Begriffe | TF |\n",
    "|-------|--------------------------|---------------------|-------------|\n",
    "| D1 | Leute folgen Mr.Beast | Leute, folgen, mr.beast | 1/3 für jeden Begriff |\n",
    "| D2 | Mr.Beast folgt Mr.Beast | mr.beast, folgen | 1/2 für mr.beast, 1/2 für folgen |\n",
    "| D3 | Leute schreiben Kommentar | Leute, schreiben, kommentieren | 1/3 für jeden Begriff |\n",
    "| D4 | Mr.Beast schreibt Kommentar | mr.beast, schreiben, kommentieren | 1/3 für mr.beast, 1/3 für schreiben, 1/3 für Kommentar |\n",
    "\n",
    "#### Schritt 2: IDF berechnen\n",
    "\n",
    "Angenommen, es gibt insgesamt 4 Dokumente im Korpus:\n",
    "\n",
    "| Begriff | IDF-Formel | IDF (unter Annahme von Logarithmus zur Basis 2) |\n",
    "|-----------|-------------------------------------|---------------------------|\n",
    "| Leute | log(4/2) | log(2) = 1 |\n",
    "| folgen | log(4/3) | log(4/3)=0,415 |\n",
    "| Mr.Beast | log(4/3) | log(4/3)=0,415 |\n",
    "\n",
    "### Vorteile und Nachteile\n",
    "\n",
    "**Vorteile**:\n",
    "- **Informationsabruf**: Wird in Suchmaschinen wie Google verwendet, um Dokumente nach Relevanz zu bewerten.\n",
    "- **Begriffswichtigkeit**: Hebt Begriffe hervor, die in einem Dokument im Vergleich zu anderen deutlich oder wichtig sind.\n",
    "\n",
    "**Nachteile**:\n",
    "- **Sparcity**: Sparse-Vektoren können bei der Handhabung großer Vokabulare zu Problemen führen.\n",
    "- **Out-of-Bag-Wörter**: Begriffe, die im Trainingskorpus nicht vorhanden sind, können zu null IDF und ineffektiver Darstellung führen.\n",
    "- **Semantische Beziehung**: Erfasst keine semantischen Beziehungen zwischen Wörtern (z. B. können „schön“ und „umwerfend“ trotz unterschiedlicher Bedeutungen ähnliche TF-IDF haben).\n",
    "\n",
    "In praktischen Implementierungen wie in sklearn wird häufig ein Glättungsterm „(1+TFIDF)“ hinzugefügt, um eine Division durch Null zu vermeiden und selbst für Begriffe, die in allen Dokumenten vorkommen, von Null verschiedene IDF-Werte sicherzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamp</th>\n",
       "      <th>aap</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abasel</th>\n",
       "      <th>abba</th>\n",
       "      <th>abc</th>\n",
       "      <th>abe</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>zionazi</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zipline</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zootopia</th>\n",
       "      <th>zoro</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27649 rows × 6325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aamp  aap   ab  abandon  abasel  abba  abc  abe  ability  able  ...  \\\n",
       "0       0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "1       0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "2       0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "3       0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "4       0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "...     ...  ...  ...      ...     ...   ...  ...  ...      ...   ...  ...   \n",
       "27644   0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "27645   0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "27646   0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "27647   0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "27648   0.0  0.0  0.0      0.0     0.0   0.0  0.0  0.0      0.0   0.0  ...   \n",
       "\n",
       "       zionazi  zionism  zipline  zipper  zombie  zone  zoo  zootopia  zoro  \\\n",
       "0          0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "1          0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "2          0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "3          0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "4          0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "...        ...      ...      ...     ...     ...   ...  ...       ...   ...   \n",
       "27644      0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "27645      0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "27646      0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "27647      0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "27648      0.0      0.0      0.0     0.0     0.0   0.0  0.0       0.0   0.0   \n",
       "\n",
       "       zzz  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "27644  0.0  \n",
       "27645  0.0  \n",
       "27646  0.0  \n",
       "27647  0.0  \n",
       "27648  0.0  \n",
       "\n",
       "[27649 rows x 6325 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tweets = df_cleaned['tweet_cleaned']\n",
    "labels = df_cleaned['label']\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(tweets)\n",
    "X_tfidf\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_names\n",
    "\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "df_tfidf\n",
    "#df_final = pd.concat([df_cleaned[['Index', 'Output']], df_tfidf], axis=1)\n",
    "\n",
    "# print(\"Final DataFrame with TF-IDF:\")\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Word Embeddings Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. FastText"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
