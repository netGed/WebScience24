{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports & Downloads"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (3800709767.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[349], line 10\u001B[1;36m\u001B[0m\n\u001B[1;33m    from sklearn.model_selection import GridSearchCV,\u001B[0m\n\u001B[1;37m                                                      ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NearMiss, CondensedNearestNeighbour, NeighbourhoodCleaningRule\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV,\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:54.122396400Z",
     "start_time": "2024-11-13T21:29:54.037726700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Einladen der Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Originaldaten ohne umfassende Vorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet\nid                                                          \n1       0   @user when a father is dysfunctional and is s...\n2       0  @user @user thanks for #lyft credit i can't us...\n3       0                                bihday your majesty\n4       0  #model   i love u take with u all the time in ...\n5       0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_basic_cleaned.csv'))\n",
    "df = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 2013\n",
      "Negative: 27517\n",
      "Verhältnis: 13.669647292598112\n"
     ]
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "positive = len(df[df['label'] == 1])\n",
    "negative = len(df[df['label'] == 0])\n",
    "print(\"Positive:\", positive)\n",
    "print(\"Negative:\", negative)\n",
    "print(\"Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorverarbeitete Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet  \\\nid                                                             \n1       0   @user when a father is dysfunctional and is s...   \n2       0  @user @user thanks for #lyft credit i can't us...   \n3       0                                bihday your majesty   \n4       0  #model   i love u take with u all the time in ...   \n5       0             factsguide: society now    #motivation   \n\n                                        tweet_cleaned  user_handle  \\\nid                                                                   \n1                         father selfish drag kid run            1   \n2               thank lyft credit use cause offer van            2   \n3                                      bihday majesty            0   \n4   model take time mobile phone kiss sunglass mou...            0   \n5                       factsguide society motivation            0   \n\n                                    hashtags  \\\nid                                             \n1                                   ['#run']   \n2   ['#lyft', '#disapointed', '#getthanked']   \n3                                         []   \n4                                 ['#model']   \n5                            ['#motivation']   \n\n                                               emojis  \nid                                                     \n1                                                 NaN  \n2                                                 NaN  \n3                                                 NaN  \n4   :mobile_phone:,:kissing_face_with_smiling_eyes...  \n5                                                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_cleaned</th>\n      <th>user_handle</th>\n      <th>hashtags</th>\n      <th>emojis</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n      <td>father selfish drag kid run</td>\n      <td>1</td>\n      <td>['#run']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n      <td>thank lyft credit use cause offer van</td>\n      <td>2</td>\n      <td>['#lyft', '#disapointed', '#getthanked']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n      <td>bihday majesty</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n      <td>model take time mobile phone kiss sunglass mou...</td>\n      <td>0</td>\n      <td>['#model']</td>\n      <td>:mobile_phone:,:kissing_face_with_smiling_eyes...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n      <td>factsguide society motivation</td>\n      <td>0</td>\n      <td>['#motivation']</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df_cleaned.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 1811\n",
      "Negative: 25839\n",
      "Verhältnis: 14.26780784097184\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['label'].value_counts()\n",
    "positive = len(df_cleaned[df_cleaned['label'] == 1])\n",
    "negative = len(df_cleaned[df_cleaned['label'] == 0])\n",
    "print(\"Positive:\", positive)\n",
    "print(\"Negative:\", negative)\n",
    "print(\"Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verhältnis hat sich durch die Bereinigung sogar noch weiter verschlechter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "def print_pos_neg(y_train, y_test):\n",
    "    positive = np.count_nonzero(y_train == 1)\n",
    "    negative = np.count_nonzero(y_train == 0)\n",
    "    print(\"Train\")\n",
    "    print(\"- Positive:\", positive)\n",
    "    print(\"- Negative:\", negative)\n",
    "    print(\"- Verhältnis:\", negative / positive)\n",
    "\n",
    "    positive = np.count_nonzero(y_test == 1)\n",
    "    negative = np.count_nonzero(y_test == 0)\n",
    "    print(\"Test\")\n",
    "    print(\"- Positive:\", positive)\n",
    "    print(\"- Negative:\", negative)\n",
    "    print(\"- Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:15:19.253936500Z",
     "start_time": "2024-11-13T21:15:17.904532100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "X_base = df[\"tweet\"]\n",
    "y_base = df[\"label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:22:39.200557500Z",
     "start_time": "2024-11-13T21:22:39.158145300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 1401\n",
      "- Negative: 19270\n",
      "- Verhältnis: 13.754461099214847\n",
      "Test\n",
      "- Positive: 612\n",
      "- Negative: 8247\n",
      "- Verhältnis: 13.47549019607843\n"
     ]
    }
   ],
   "source": [
    "# Ohne stratify\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.3, random_state=42)\n",
    "print_pos_neg(y_train_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:22:39.842673100Z",
     "start_time": "2024-11-13T21:22:39.793345700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 1409\n",
      "- Negative: 19262\n",
      "- Verhältnis: 13.67068843151171\n",
      "Test\n",
      "- Positive: 604\n",
      "- Negative: 8255\n",
      "- Verhältnis: 13.667218543046358\n"
     ]
    }
   ],
   "source": [
    "# mit stratify\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.3, stratify=y_base,\n",
    "                                                                        random_state=42)\n",
    "print_pos_neg(y_train_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:22:40.453335200Z",
     "start_time": "2024-11-13T21:22:40.394829200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "X_clean = df_cleaned[\"tweet_cleaned\"]\n",
    "y_clean = df_cleaned[\"label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:22:41.153630600Z",
     "start_time": "2024-11-13T21:22:41.054846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 66\n",
      "- Negative: 4071\n",
      "- Verhältnis: 61.68181818181818\n",
      "Test\n",
      "- Positive: 26\n",
      "- Negative: 1748\n",
      "- Verhältnis: 67.23076923076923\n"
     ]
    }
   ],
   "source": [
    "# Ohne stratify\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.3,\n",
    "                                                                            random_state=42)\n",
    "print_pos_neg(y_train_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:22:41.432847800Z",
     "start_time": "2024-11-13T21:22:41.385973800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 64\n",
      "- Negative: 4073\n",
      "- Verhältnis: 63.640625\n",
      "Test\n",
      "- Positive: 28\n",
      "- Negative: 1746\n",
      "- Verhältnis: 62.357142857142854\n"
     ]
    }
   ],
   "source": [
    "# mit stratify\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.3,\n",
    "                                                                            stratify=y_clean, random_state=42)\n",
    "print_pos_neg(y_train_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:22:44.160651Z",
     "start_time": "2024-11-13T21:22:44.098135200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vektorisierung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#Unsupervised_text_classification_Word2Vec\n",
    "\n",
    "# def vectorize(sentence, w2v_model):\n",
    "#     words = sentence.split()\n",
    "#     words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "#     if len(words_vecs) == 0:\n",
    "#         return np.zeros(100)\n",
    "#     words_vecs = np.array(words_vecs)\n",
    "#     return words_vecs.mean(axis=0)\n",
    "\n",
    "\n",
    "# def vectorize_df(df):\n",
    "#     X = df[\"tweet\"]\n",
    "#     y = df[\"label\"]\n",
    "#\n",
    "#     sentences_base = [sentence.split() for sentence in X]\n",
    "#     w2v_model_base = Word2Vec(sentences_base, window=5, min_count=5, workers=-1)\n",
    "#\n",
    "#     x_data = np.array([vectorize(sentence, w2v_model_base) for sentence in X])\n",
    "#     return x_data, y\n",
    "\n",
    "\n",
    "# def vectorize_df_cleaned(df):\n",
    "#     X = df[\"tweet_cleaned\"]\n",
    "#     y = df[\"label\"]\n",
    "#\n",
    "#     sentences_base = [sentence.split() for sentence in X]\n",
    "#     w2v_model_base = Word2Vec(sentences_base, window=5, min_count=5, workers=-1, )\n",
    "#\n",
    "#     x_data = np.array([vectorize(sentence, w2v_model_base) for sentence in X])\n",
    "#     return x_data, y\n",
    "\n",
    "\n",
    "# X_base, y_base = vectorize_df(df)\n",
    "# X_clean, y_clean = vectorize_df(df_cleaned)\n",
    "\n",
    "\n",
    "# nicht richtig genutzt, führt zu falschen train/test Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train_base = vectorizer.fit_transform(X_train_base)\n",
    "X_test_base = vectorizer.transform(X_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:25:00.059423800Z",
     "start_time": "2024-11-13T21:24:59.334237500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_base shape (20671, 5000)\n",
      "y_train_base shape (20671,)\n",
      "X_test_base shape (8859, 5000)\n",
      "y_test_base shape (8859,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_base shape\", X_train_base.shape)\n",
    "print(\"y_train_base shape\", y_train_base.shape)\n",
    "\n",
    "print(\"X_test_base shape\", X_test_base.shape)\n",
    "print(\"y_test_base shape\", y_test_base.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:25:03.619574500Z",
     "start_time": "2024-11-13T21:25:03.528838600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "# df_cleaned.dropna(inplace=True)  #irgendwoher kommt eine na row in tweet_cleaned, dadurch funktioniert der Vectorizer nicht\n",
    "vectorizer_clean = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train_clean = vectorizer_clean.fit_transform(X_train_clean)\n",
    "X_test_clean = vectorizer_clean.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:07.703638400Z",
     "start_time": "2024-11-13T21:26:07.580375300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape (4137, 4093)\n",
      "y_train_clean shape (4137,)\n",
      "X_test_clean shape (1774, 4093)\n",
      "y_test_clean shape (1774,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_clean shape\", X_train_clean.shape)\n",
    "print(\"y_train_clean shape\", y_train_clean.shape)\n",
    "\n",
    "print(\"X_test_clean shape\", X_test_clean.shape)\n",
    "print(\"y_test_clean shape\", y_test_clean.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:17.108077800Z",
     "start_time": "2024-11-13T21:26:16.323497600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Resampling Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "def print_data(y_before, y_after, sampling_technique):\n",
    "    counter_before = Counter(y_before)\n",
    "    counter_after = Counter(y_after)\n",
    "    print(\"Before sampling with:\", sampling_technique, counter_before)\n",
    "    print(\"After sampling with:\", sampling_technique, counter_after)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:17.590007Z",
     "start_time": "2024-11-13T21:26:16.351764800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.1 SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "os_smote = SMOTE()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:17.672981800Z",
     "start_time": "2024-11-13T21:26:16.395519800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 19262, 1: 1409})\n",
      "After sampling with: SMOTE Counter({1: 19262, 0: 19262})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_s, y_train_base_s = os_smote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:17.844684300Z",
     "start_time": "2024-11-13T21:26:16.405625900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 4073, 1: 64})\n",
      "After sampling with: SMOTE Counter({0: 4073, 1: 4073})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_s, y_train_clean_s = os_smote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:17.945839900Z",
     "start_time": "2024-11-13T21:26:16.585701600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.2 Borderline-SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "os_bsmote = BorderlineSMOTE()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:17.945839900Z",
     "start_time": "2024-11-13T21:26:16.643128300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 19262, 1: 1409})\n",
      "After sampling with: BorderlineSMOTE Counter({1: 19262, 0: 19262})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_bs, y_train_base_bs = os_bsmote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:18.691328200Z",
     "start_time": "2024-11-13T21:26:16.652854500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 4073, 1: 64})\n",
      "After sampling with: BorderlineSMOTE Counter({0: 4073, 1: 4073})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_bs, y_train_clean_bs = os_bsmote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:18.731811800Z",
     "start_time": "2024-11-13T21:26:17.672981800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.3 ADASYN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "os_ada = ADASYN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:18.731811800Z",
     "start_time": "2024-11-13T21:26:17.773911200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 19262, 1: 1409})\n",
      "After sampling with: ADASYN Counter({0: 19262, 1: 18876})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_a, y_train_base_a = os_ada.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:18.894152300Z",
     "start_time": "2024-11-13T21:26:17.794087400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 4073, 1: 64})\n",
      "After sampling with: ADASYN Counter({0: 4073, 1: 4071})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_a, y_train_clean_a = os_ada.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:18.993011500Z",
     "start_time": "2024-11-13T21:26:18.871912900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.1 NearMiss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "us_near_miss = NearMiss(version=3, n_neighbors_ver3=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:18.993011500Z",
     "start_time": "2024-11-13T21:26:18.981488700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 19262, 1: 1409})\n",
      "After sampling with: NearMiss Counter({1: 1409, 0: 185})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_base_nm, y_train_base_nm = us_near_miss.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.767892500Z",
     "start_time": "2024-11-13T21:26:18.982997500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 4073, 1: 64})\n",
      "After sampling with: NearMiss Counter({0: 64, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_nm, y_train_clean_nm = us_near_miss.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.767892500Z",
     "start_time": "2024-11-13T21:26:23.677127900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.2 Condensed Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "us_cnn = CondensedNearestNeighbour(n_neighbors=1, n_jobs=-1)  # sehr langsam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.798167200Z",
     "start_time": "2024-11-13T21:26:23.767892500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "# X_train_base_cnn, y_train_base_cnn = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.907249400Z",
     "start_time": "2024-11-13T21:26:23.788076800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "# X_train_clean_cnn, y_train_clean_cnn = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.969693600Z",
     "start_time": "2024-11-13T21:26:23.798167200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.3 Neighborhood Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "us_cnn_cr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5, n_jobs=-1)  # sehr langsam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.990252400Z",
     "start_time": "2024-11-13T21:26:23.818346700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "# X_train_base_ncr, y_train_base_ncr = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.990252400Z",
     "start_time": "2024-11-13T21:26:23.828450200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "# X_train_clean_ncr, y_train_clean_ncr = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.990252400Z",
     "start_time": "2024-11-13T21:26:23.848649900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.4 Tomek Links Undersampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "us_tomek = TomekLinks()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:23.990252400Z",
     "start_time": "2024-11-13T21:26:23.858770500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: TomekLinks Counter({0: 19262, 1: 1409})\n",
      "After sampling with: TomekLinks Counter({0: 19223, 1: 1409})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_t, y_train_base_t = us_tomek.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_t, \"TomekLinks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.019777100Z",
     "start_time": "2024-11-13T21:26:23.877524900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: TomekLinks Counter({0: 4073, 1: 64})\n",
      "After sampling with: TomekLinks Counter({0: 4070, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_t, y_train_clean_t = us_tomek.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_t, \"TomekLinks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.383181500Z",
     "start_time": "2024-11-13T21:26:36.009651100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Ensemble Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(\n",
    "    columns=[\"model\", \"variant\", \"train_acc\", \"train_prec\", \"train_rec\", \"train_f1\", \"test_acc\", \"test_prec\",\n",
    "             \"test_rec\", \"test_f1\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.393317900Z",
     "start_time": "2024-11-13T21:26:36.383181500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model, model_name, variant, x_data_train, y_data_train, x_data_test, y_data_test):\n",
    "    train_acc = model.score(x_data_train, y_data_train)\n",
    "    train_precision = precision_score(y_data_train, model.predict(x_data_train))\n",
    "    train_recall = recall_score(y_data_train, model.predict(x_data_train))\n",
    "    train_f1 = f1_score(y_data_train, model.predict(x_data_train))\n",
    "\n",
    "    test_acc = model.score(x_data_test, y_data_test)\n",
    "    test_precision = precision_score(y_data_test, model.predict(x_data_test))\n",
    "    test_recall = recall_score(y_data_test, model.predict(x_data_test))\n",
    "    test_f1 = f1_score(y_data_test, model.predict(x_data_test))\n",
    "\n",
    "    evaluation.loc[len(evaluation.index)] = [model_name, variant, train_acc, train_precision, train_recall, train_f1,\n",
    "                                             test_acc, test_precision, test_recall, test_f1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.509123900Z",
     "start_time": "2024-11-13T21:26:36.393317900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, sampling_method):\n",
    "    pred = model.predict(x_test)\n",
    "    accscore = metrics.accuracy_score(pred, y_test)\n",
    "\n",
    "    print(f'{sampling_method} model accuracy for classification is =', str('{:04.2f}'.format(accscore * 100)) + '%')\n",
    "    print('------------------------------------------------')\n",
    "    print('Confusion Matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n",
    "    print('------------------------------------------------')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.635125700Z",
     "start_time": "2024-11-13T21:26:36.518124500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "def fit_model(model, modelName):\n",
    "    print(\"Starting model fitting.\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"1/12 Fitting: \", modelName, \"BASE started...\")\n",
    "    model.fit(X_train_base, y_train_base)\n",
    "    add_to_eval_df(model, modelName, \"base\", X_train_base, y_train_base, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"2/12 Fitting: \", modelName, \"CLEAN started...\")\n",
    "    model.fit(X_train_clean, y_train_clean)\n",
    "    add_to_eval_df(model, modelName, \"clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"3/12 Fitting: \", modelName, \"SMOTE-base started...\")\n",
    "    model.fit(X_train_base_s, y_train_base_s)\n",
    "    add_to_eval_df(model, modelName, \"SMOTE base\", X_train_base_s, y_train_base_s, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"4/12 Fitting: \", modelName, \"SMOTE-clean started...\")\n",
    "    model.fit(X_train_clean_s, y_train_clean_s)\n",
    "    add_to_eval_df(model, modelName, \"SMOTE clean\", X_train_clean_s, y_train_clean_s, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"5/12 Fitting: \", modelName, \"BorderlineSMOTE-base started...\")\n",
    "    model.fit(X_train_base_bs, y_train_base_bs)\n",
    "    add_to_eval_df(model, modelName, \"BorderlineSMOTE base\", X_train_base_bs, y_train_base_bs, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"6/12 Fitting: \", modelName, \"BorderlineSMOTE-clean started...\")\n",
    "    model.fit(X_train_clean_bs, y_train_clean_bs)\n",
    "    add_to_eval_df(model, modelName, \"BorderlineSMOTE clean\", X_train_clean_bs, y_train_clean_bs, X_test_clean,\n",
    "                   y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"7/12 Fitting: \", modelName, \"ADASYN-base started...\")\n",
    "    model.fit(X_train_base_a, y_train_base_a)\n",
    "    add_to_eval_df(model, modelName, \"ADASYN base\", X_train_base_a, y_train_base_a, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"8/12 Fitting: \", modelName, \"ADASYN-clean started...\")\n",
    "    model.fit(X_train_clean_a, y_train_clean_a)\n",
    "    add_to_eval_df(model, modelName, \"ADASYN clean\", X_train_clean_a, y_train_clean_a, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"9/12 Fitting: \", modelName, \"NearMiss-base started...\")\n",
    "    model.fit(X_train_base_nm, y_train_base_nm)\n",
    "    add_to_eval_df(model, modelName, \"NearMiss base\", X_train_base_nm, y_train_base_nm, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"10/12 Fitting: \", modelName, \"NearMiss-clean started...\")\n",
    "    model.fit(X_train_clean_nm, y_train_clean_nm)\n",
    "    add_to_eval_df(model, modelName, \"NearMiss clean\", X_train_clean_nm, y_train_clean_nm, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"11/12 Fitting: \", modelName, \"TomekLink-base started...\")\n",
    "    model.fit(X_train_clean_t, y_train_clean_t)\n",
    "    add_to_eval_df(model, modelName, \"TomekLink base\", X_train_clean_t, y_train_clean_t, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"12/12 Fitting: \", modelName, \"TomekLink-clean started...\")\n",
    "    model.fit(X_train_clean_t, y_train_clean_t)\n",
    "    add_to_eval_df(model, modelName, \"TomekLink clean\", X_train_clean_t, y_train_clean_t, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    print(\"Model fitting finished.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.761125Z",
     "start_time": "2024-11-13T21:26:36.635125700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:26:36.845144100Z",
     "start_time": "2024-11-13T21:26:36.734125300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  RandomForest BASE started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  3 Seconds\n",
      "2/12 Fitting:  RandomForest CLEAN started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "3/12 Fitting:  RandomForest SMOTE-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  8 Seconds\n",
      "4/12 Fitting:  RandomForest SMOTE-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "5/12 Fitting:  RandomForest BorderlineSMOTE-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  5 Seconds\n",
      "6/12 Fitting:  RandomForest BorderlineSMOTE-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  RandomForest ADASYN-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  6 Seconds\n",
      "8/12 Fitting:  RandomForest ADASYN-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "9/12 Fitting:  RandomForest NearMiss-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "10/12 Fitting:  RandomForest NearMiss-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  RandomForest TomekLink-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "12/12 Fitting:  RandomForest TomekLink-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(rf, \"RandomForest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:06.089829700Z",
     "start_time": "2024-11-13T21:26:36.845144100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "brf = BalancedRandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:06.121079100Z",
     "start_time": "2024-11-13T21:27:06.089829700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BASE\n",
    "brf.fit(X_train_base, y_train_base)\n",
    "add_to_eval_df(brf, \"BalancedRandomForest\", \"BALANCED base\", X_train_base, y_train_base, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:08.041985200Z",
     "start_time": "2024-11-13T21:27:06.105453900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CLEANED\n",
    "brf.fit(X_train_clean, y_train_clean)\n",
    "add_to_eval_df(brf, \"BalancedRandomForest\", \"BALANCED clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:08.897614600Z",
     "start_time": "2024-11-13T21:27:08.041985200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n3           RandomForest            SMOTE clean   1.000000    1.000000   \n5           RandomForest  BorderlineSMOTE clean   1.000000    1.000000   \n11          RandomForest        TomekLink clean   1.000000    1.000000   \n0           RandomForest                   base   0.999855    1.000000   \n7           RandomForest           ADASYN clean   1.000000    1.000000   \n4           RandomForest   BorderlineSMOTE base   0.999922    1.000000   \n10          RandomForest         TomekLink base   1.000000    1.000000   \n6           RandomForest            ADASYN base   0.999921    0.999947   \n2           RandomForest             SMOTE base   0.999922    1.000000   \n1           RandomForest                  clean   1.000000    1.000000   \n12  BalancedRandomForest          BALANCED base   0.856949    0.322721   \n13  BalancedRandomForest         BALANCED clean   0.939328    0.203175   \n9           RandomForest         NearMiss clean   1.000000    1.000000   \n8           RandomForest          NearMiss base   0.998118    1.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n3    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n5    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n11   1.000000  1.000000  0.986471   1.000000  0.142857  0.250000  \n0    0.997871  0.998934  0.956203   0.880282  0.413907  0.563063  \n7    1.000000  1.000000  0.987599   0.875000  0.250000  0.388889  \n4    0.999844  0.999922  0.950785   0.868421  0.327815  0.475962  \n10   1.000000  1.000000  0.985908   0.800000  0.142857  0.242424  \n6    0.999894  0.999921  0.952703   0.782875  0.423841  0.549946  \n2    0.999844  0.999922  0.952026   0.759420  0.433775  0.552160  \n1    1.000000  1.000000  0.985344   0.750000  0.107143  0.187500  \n12   1.000000  0.487965  0.816119   0.248651  0.839404  0.383655  \n13   1.000000  0.337731  0.934047   0.132231  0.571429  0.214765  \n9    1.000000  1.000000  0.932356   0.089286  0.357143  0.142857  \n8    0.997871  0.998934  0.222711   0.078502  0.968543  0.145233  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.986471</td>\n      <td>1.000000</td>\n      <td>0.142857</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.956203</td>\n      <td>0.880282</td>\n      <td>0.413907</td>\n      <td>0.563063</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.875000</td>\n      <td>0.250000</td>\n      <td>0.388889</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.950785</td>\n      <td>0.868421</td>\n      <td>0.327815</td>\n      <td>0.475962</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink base</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.985908</td>\n      <td>0.800000</td>\n      <td>0.142857</td>\n      <td>0.242424</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999921</td>\n      <td>0.999947</td>\n      <td>0.999894</td>\n      <td>0.999921</td>\n      <td>0.952703</td>\n      <td>0.782875</td>\n      <td>0.423841</td>\n      <td>0.549946</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.952026</td>\n      <td>0.759420</td>\n      <td>0.433775</td>\n      <td>0.552160</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.985344</td>\n      <td>0.750000</td>\n      <td>0.107143</td>\n      <td>0.187500</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.856949</td>\n      <td>0.322721</td>\n      <td>1.000000</td>\n      <td>0.487965</td>\n      <td>0.816119</td>\n      <td>0.248651</td>\n      <td>0.839404</td>\n      <td>0.383655</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.939328</td>\n      <td>0.203175</td>\n      <td>1.000000</td>\n      <td>0.337731</td>\n      <td>0.934047</td>\n      <td>0.132231</td>\n      <td>0.571429</td>\n      <td>0.214765</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.932356</td>\n      <td>0.089286</td>\n      <td>0.357143</td>\n      <td>0.142857</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998118</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.222711</td>\n      <td>0.078502</td>\n      <td>0.968543</td>\n      <td>0.145233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[(evaluation.model == \"RandomForest\") | (evaluation.model == \"BalancedRandomForest\")].sort_values(\n",
    "    by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:08.944490300Z",
     "start_time": "2024-11-13T21:27:08.897614600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1a XGBClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:08.982273300Z",
     "start_time": "2024-11-13T21:27:08.928864700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  XGBClassifier BASE started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "2/12 Fitting:  XGBClassifier CLEAN started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "3/12 Fitting:  XGBClassifier SMOTE-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  12 Seconds\n",
      "4/12 Fitting:  XGBClassifier SMOTE-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "5/12 Fitting:  XGBClassifier BorderlineSMOTE-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  7 Seconds\n",
      "6/12 Fitting:  XGBClassifier BorderlineSMOTE-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  XGBClassifier ADASYN-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  10 Seconds\n",
      "8/12 Fitting:  XGBClassifier ADASYN-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  2 Seconds\n",
      "9/12 Fitting:  XGBClassifier NearMiss-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  XGBClassifier NearMiss-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  XGBClassifier TomekLink-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "12/12 Fitting:  XGBClassifier TomekLink-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(xgb, \"XGBClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:47.911119400Z",
     "start_time": "2024-11-13T21:27:08.944490300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "data": {
      "text/plain": "            model                variant  train_acc  train_prec  train_rec  \\\n21  XGBClassifier           ADASYN clean   0.998404    1.000000   0.996807   \n14  XGBClassifier                   base   0.965120    0.972527   0.502484   \n19  XGBClassifier  BorderlineSMOTE clean   0.997545    1.000000   0.995090   \n17  XGBClassifier            SMOTE clean   0.998527    1.000000   0.997054   \n18  XGBClassifier   BorderlineSMOTE base   0.978221    0.993359   0.962880   \n15  XGBClassifier                  clean   0.992265    1.000000   0.500000   \n20  XGBClassifier            ADASYN base   0.969374    0.991507   0.946228   \n16  XGBClassifier             SMOTE base   0.969422    0.990347   0.948084   \n24  XGBClassifier         TomekLink base   0.992259    1.000000   0.500000   \n25  XGBClassifier        TomekLink clean   0.992259    1.000000   0.500000   \n22  XGBClassifier          NearMiss base   0.966123    0.969508   0.992903   \n23  XGBClassifier         NearMiss clean   0.789062    0.877551   0.671875   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n21  0.998401  0.988726   0.900000  0.321429  0.473684  \n14  0.662611  0.951010   0.824427  0.357616  0.498845  \n19  0.997539  0.988162   0.818182  0.321429  0.461538  \n17  0.998525  0.987599   0.800000  0.285714  0.421053  \n18  0.977882  0.946947   0.681081  0.417219  0.517454  \n15  0.666667  0.985344   0.666667  0.142857  0.235294  \n20  0.968338  0.944012   0.644385  0.399007  0.492843  \n16  0.968755  0.944802   0.642680  0.428808  0.514399  \n24  0.666667  0.984780   0.600000  0.107143  0.181818  \n25  0.666667  0.984780   0.600000  0.107143  0.181818  \n22  0.981066  0.137600   0.070976  0.963576  0.132213  \n23  0.761062  0.757046   0.030303  0.464286  0.056893  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.998404</td>\n      <td>1.000000</td>\n      <td>0.996807</td>\n      <td>0.998401</td>\n      <td>0.988726</td>\n      <td>0.900000</td>\n      <td>0.321429</td>\n      <td>0.473684</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.965120</td>\n      <td>0.972527</td>\n      <td>0.502484</td>\n      <td>0.662611</td>\n      <td>0.951010</td>\n      <td>0.824427</td>\n      <td>0.357616</td>\n      <td>0.498845</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997545</td>\n      <td>1.000000</td>\n      <td>0.995090</td>\n      <td>0.997539</td>\n      <td>0.988162</td>\n      <td>0.818182</td>\n      <td>0.321429</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.998527</td>\n      <td>1.000000</td>\n      <td>0.997054</td>\n      <td>0.998525</td>\n      <td>0.987599</td>\n      <td>0.800000</td>\n      <td>0.285714</td>\n      <td>0.421053</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.978221</td>\n      <td>0.993359</td>\n      <td>0.962880</td>\n      <td>0.977882</td>\n      <td>0.946947</td>\n      <td>0.681081</td>\n      <td>0.417219</td>\n      <td>0.517454</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.992265</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.985344</td>\n      <td>0.666667</td>\n      <td>0.142857</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.969374</td>\n      <td>0.991507</td>\n      <td>0.946228</td>\n      <td>0.968338</td>\n      <td>0.944012</td>\n      <td>0.644385</td>\n      <td>0.399007</td>\n      <td>0.492843</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969422</td>\n      <td>0.990347</td>\n      <td>0.948084</td>\n      <td>0.968755</td>\n      <td>0.944802</td>\n      <td>0.642680</td>\n      <td>0.428808</td>\n      <td>0.514399</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.966123</td>\n      <td>0.969508</td>\n      <td>0.992903</td>\n      <td>0.981066</td>\n      <td>0.137600</td>\n      <td>0.070976</td>\n      <td>0.963576</td>\n      <td>0.132213</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.789062</td>\n      <td>0.877551</td>\n      <td>0.671875</td>\n      <td>0.761062</td>\n      <td>0.757046</td>\n      <td>0.030303</td>\n      <td>0.464286</td>\n      <td>0.056893</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"XGBClassifier\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:47.971596500Z",
     "start_time": "2024-11-13T21:27:47.911119400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1b XGBClassifier tuning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "# todo erneut machen\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test1, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:47.991771800Z",
     "start_time": "2024-11-13T21:27:47.971596500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "# gsearch1.fit(X_train_clean, y_train_clean)\n",
    "# gsearch1.best_score_, gsearch1.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.041073300Z",
     "start_time": "2024-11-13T21:27:47.991771800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    "    'min_child_weight': range(1, 6, 2),\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test2, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.072322800Z",
     "start_time": "2024-11-13T21:27:48.009811800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "# gsearch2.fit(X_train_clean, y_train_clean)\n",
    "# gsearch2.best_score_, gsearch2.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.072322800Z",
     "start_time": "2024-11-13T21:27:48.025447800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'gamma': [i / 10.0 for i in range(0, 5)],\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test3, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.072322800Z",
     "start_time": "2024-11-13T21:27:48.041073300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "# gsearch3.fit(X_train_clean, y_train_clean)\n",
    "# gsearch3.best_score_, gsearch3.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.056698100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    "    'subsample': [i / 10.0 for i in range(6, 10)],\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test4, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.072322800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "# gsearch4.fit(X_train_clean, y_train_clean)\n",
    "# gsearch4.best_score_, gsearch4.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.087947400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    "    'colsample_bytree': [i / 10.0 for i in range(6, 10)],\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.110094900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "# gsearch5.fit(X_train_clean, y_train_clean)\n",
    "# gsearch5.best_score_, gsearch5.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.125743400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test6, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.141365400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "# gsearch6.fit(X_train_clean, y_train_clean)\n",
    "# gsearch6.best_score_, gsearch6.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.172615500Z",
     "start_time": "2024-11-13T21:27:48.156988700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [],
   "source": [
    "xgb_tune = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:27:48.188239500Z",
     "start_time": "2024-11-13T21:27:48.172615500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fit_model(xgb_tune, \"XGBClassifier-tuned\")\n",
    "# evaluation[evaluation.model == \"XGBClassifier-tuned\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1 CatBoostClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(iterations=2,\n",
    "                         depth=2,\n",
    "                         learning_rate=1,\n",
    "                         loss_function='Logloss',\n",
    "                         verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:28:43.055485Z",
     "start_time": "2024-11-13T21:28:42.996900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  CatBoostClassifier BASE started...\n",
      "0:\tlearn: 0.2487701\ttotal: 16.5ms\tremaining: 16.5ms\n",
      "1:\tlearn: 0.2343139\ttotal: 33.1ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  CatBoostClassifier CLEAN started...\n",
      "0:\tlearn: 0.0796309\ttotal: 6.26ms\tremaining: 6.26ms\n",
      "1:\tlearn: 0.0749569\ttotal: 12.1ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  CatBoostClassifier SMOTE-base started...\n",
      "0:\tlearn: 0.6007060\ttotal: 25.2ms\tremaining: 25.2ms\n",
      "1:\tlearn: 0.5466845\ttotal: 46.5ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "4/12 Fitting:  CatBoostClassifier SMOTE-clean started...\n",
      "0:\tlearn: 0.6029243\ttotal: 8.2ms\tremaining: 8.2ms\n",
      "1:\tlearn: 0.5223909\ttotal: 16.3ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  CatBoostClassifier BorderlineSMOTE-base started...\n",
      "0:\tlearn: 0.5941689\ttotal: 22.5ms\tremaining: 22.5ms\n",
      "1:\tlearn: 0.5369019\ttotal: 44.4ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "6/12 Fitting:  CatBoostClassifier BorderlineSMOTE-clean started...\n",
      "0:\tlearn: 0.5694987\ttotal: 7.43ms\tremaining: 7.43ms\n",
      "1:\tlearn: 0.4868169\ttotal: 14.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  CatBoostClassifier ADASYN-base started...\n",
      "0:\tlearn: 0.5942736\ttotal: 22.6ms\tremaining: 22.6ms\n",
      "1:\tlearn: 0.5510505\ttotal: 43.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "8/12 Fitting:  CatBoostClassifier ADASYN-clean started...\n",
      "0:\tlearn: 0.6099676\ttotal: 8.36ms\tremaining: 8.36ms\n",
      "1:\tlearn: 0.5262791\ttotal: 15.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  CatBoostClassifier NearMiss-base started...\n",
      "0:\tlearn: 0.3586037\ttotal: 3.72ms\tremaining: 3.72ms\n",
      "1:\tlearn: 0.3403802\ttotal: 7.51ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  CatBoostClassifier NearMiss-clean started...\n",
      "0:\tlearn: 0.6732156\ttotal: 1.6ms\tremaining: 1.6ms\n",
      "1:\tlearn: 0.6434392\ttotal: 3ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  CatBoostClassifier TomekLink-base started...\n",
      "0:\tlearn: 0.0797480\ttotal: 5.85ms\tremaining: 5.85ms\n",
      "1:\tlearn: 0.0743677\ttotal: 11.7ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  CatBoostClassifier TomekLink-clean started...\n",
      "0:\tlearn: 0.0797480\ttotal: 6.05ms\tremaining: 6.05ms\n",
      "1:\tlearn: 0.0743677\ttotal: 12.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(cat, \"CatBoostClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:28:47.421912400Z",
     "start_time": "2024-11-13T21:28:43.017052500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "data": {
      "text/plain": "                 model                variant  train_acc  train_prec  \\\n38  CatBoostClassifier                   base   0.936191    0.736842   \n41  CatBoostClassifier            SMOTE clean   0.717162    0.987865   \n43  CatBoostClassifier  BorderlineSMOTE clean   0.757918    0.979461   \n40  CatBoostClassifier             SMOTE base   0.715606    0.686216   \n44  CatBoostClassifier            ADASYN base   0.712098    0.680340   \n42  CatBoostClassifier   BorderlineSMOTE base   0.714464    0.665518   \n45  CatBoostClassifier           ADASYN clean   0.735020    0.926818   \n46  CatBoostClassifier          NearMiss base   0.891468    0.891635   \n47  CatBoostClassifier         NearMiss clean   0.570312    0.846154   \n39  CatBoostClassifier                  clean   0.985738    1.000000   \n48  CatBoostClassifier         TomekLink base   0.985728    0.857143   \n49  CatBoostClassifier        TomekLink clean   0.985728    0.857143   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n38   0.099361  0.175109  0.936787   0.744444  0.110927  0.193084  \n41   0.439725  0.608563  0.981398   0.272727  0.107143  0.153846  \n43   0.526884  0.685185  0.974634   0.206897  0.214286  0.210526  \n40   0.794518  0.736407  0.639914   0.114030  0.632450  0.193222  \n44   0.789044  0.730671  0.639914   0.114030  0.632450  0.193222  \n42   0.862320  0.751244  0.576363   0.107063  0.710265  0.186077  \n45   0.510194  0.658112  0.947012   0.076923  0.214286  0.113208  \n46   0.998581  0.942082  0.072017   0.068148  0.995033  0.127560  \n47   0.171875  0.285714  0.967869   0.032258  0.035714  0.033898  \n39   0.078125  0.144928  0.983653   0.000000  0.000000  0.000000  \n48   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n49   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.936191</td>\n      <td>0.736842</td>\n      <td>0.099361</td>\n      <td>0.175109</td>\n      <td>0.936787</td>\n      <td>0.744444</td>\n      <td>0.110927</td>\n      <td>0.193084</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.717162</td>\n      <td>0.987865</td>\n      <td>0.439725</td>\n      <td>0.608563</td>\n      <td>0.981398</td>\n      <td>0.272727</td>\n      <td>0.107143</td>\n      <td>0.153846</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.757918</td>\n      <td>0.979461</td>\n      <td>0.526884</td>\n      <td>0.685185</td>\n      <td>0.974634</td>\n      <td>0.206897</td>\n      <td>0.214286</td>\n      <td>0.210526</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.715606</td>\n      <td>0.686216</td>\n      <td>0.794518</td>\n      <td>0.736407</td>\n      <td>0.639914</td>\n      <td>0.114030</td>\n      <td>0.632450</td>\n      <td>0.193222</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.712098</td>\n      <td>0.680340</td>\n      <td>0.789044</td>\n      <td>0.730671</td>\n      <td>0.639914</td>\n      <td>0.114030</td>\n      <td>0.632450</td>\n      <td>0.193222</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.714464</td>\n      <td>0.665518</td>\n      <td>0.862320</td>\n      <td>0.751244</td>\n      <td>0.576363</td>\n      <td>0.107063</td>\n      <td>0.710265</td>\n      <td>0.186077</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.735020</td>\n      <td>0.926818</td>\n      <td>0.510194</td>\n      <td>0.658112</td>\n      <td>0.947012</td>\n      <td>0.076923</td>\n      <td>0.214286</td>\n      <td>0.113208</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.891468</td>\n      <td>0.891635</td>\n      <td>0.998581</td>\n      <td>0.942082</td>\n      <td>0.072017</td>\n      <td>0.068148</td>\n      <td>0.995033</td>\n      <td>0.127560</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.570312</td>\n      <td>0.846154</td>\n      <td>0.171875</td>\n      <td>0.285714</td>\n      <td>0.967869</td>\n      <td>0.032258</td>\n      <td>0.035714</td>\n      <td>0.033898</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.985738</td>\n      <td>1.000000</td>\n      <td>0.078125</td>\n      <td>0.144928</td>\n      <td>0.983653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"CatBoostClassifier\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:28:47.468787200Z",
     "start_time": "2024-11-13T21:28:47.421912400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1 LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "light = LGBMClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:28:47.468787200Z",
     "start_time": "2024-11-13T21:28:47.453161100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LGBMClassifier BASE started...\n",
      "[LightGBM] [Info] Number of positive: 1409, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45936\n",
      "[LightGBM] [Info] Number of data points in the train set: 20671, number of used features: 1379\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.068163 -> initscore=-2.615254\n",
      "[LightGBM] [Info] Start training from score -2.615254\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  9 Seconds\n",
      "2/12 Fitting:  LGBMClassifier CLEAN started...\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7842\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015470 -> initscore=-4.153252\n",
      "[LightGBM] [Info] Start training from score -4.153252\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  LGBMClassifier SMOTE-base started...\n",
      "[LightGBM] [Info] Number of positive: 19262, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108411\n",
      "[LightGBM] [Info] Number of data points in the train set: 38524, number of used features: 2600\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  3 Seconds\n",
      "4/12 Fitting:  LGBMClassifier SMOTE-clean started...\n",
      "[LightGBM] [Info] Number of positive: 4073, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29398\n",
      "[LightGBM] [Info] Number of data points in the train set: 8146, number of used features: 610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "5/12 Fitting:  LGBMClassifier BorderlineSMOTE-base started...\n",
      "[LightGBM] [Info] Number of positive: 19262, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 100804\n",
      "[LightGBM] [Info] Number of data points in the train set: 38524, number of used features: 1988\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  3 Seconds\n",
      "6/12 Fitting:  LGBMClassifier BorderlineSMOTE-clean started...\n",
      "[LightGBM] [Info] Number of positive: 4073, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28253\n",
      "[LightGBM] [Info] Number of data points in the train set: 8146, number of used features: 573\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  LGBMClassifier ADASYN-base started...\n",
      "[LightGBM] [Info] Number of positive: 18876, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108746\n",
      "[LightGBM] [Info] Number of data points in the train set: 38138, number of used features: 2635\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494939 -> initscore=-0.020243\n",
      "[LightGBM] [Info] Start training from score -0.020243\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  8 Seconds\n",
      "8/12 Fitting:  LGBMClassifier ADASYN-clean started...\n",
      "[LightGBM] [Info] Number of positive: 4071, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29556\n",
      "[LightGBM] [Info] Number of data points in the train set: 8144, number of used features: 610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499877 -> initscore=-0.000491\n",
      "[LightGBM] [Info] Start training from score -0.000491\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  5 Seconds\n",
      "9/12 Fitting:  LGBMClassifier NearMiss-base started...\n",
      "[LightGBM] [Info] Number of positive: 1409, number of negative: 185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2935\n",
      "[LightGBM] [Info] Number of data points in the train set: 1594, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.883940 -> initscore=2.030280\n",
      "[LightGBM] [Info] Start training from score 2.030280\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LGBMClassifier NearMiss-clean started...\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 64\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 128, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LGBMClassifier TomekLink-base started...\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 4070\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7829\n",
      "[LightGBM] [Info] Number of data points in the train set: 4134, number of used features: 356\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015481 -> initscore=-4.152515\n",
      "[LightGBM] [Info] Start training from score -4.152515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  LGBMClassifier TomekLink-clean started...\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 4070\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7829\n",
      "[LightGBM] [Info] Number of data points in the train set: 4134, number of used features: 356\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015481 -> initscore=-4.152515\n",
      "[LightGBM] [Info] Start training from score -4.152515\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(light, \"LGBMClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:17.818790700Z",
     "start_time": "2024-11-13T21:28:47.468787200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "data": {
      "text/plain": "             model                variant  train_acc  train_prec  train_rec  \\\n55  LGBMClassifier  BorderlineSMOTE clean   1.000000    1.000000   1.000000   \n50  LGBMClassifier                   base   0.964298    0.944371   0.506033   \n53  LGBMClassifier            SMOTE clean   1.000000    1.000000   1.000000   \n57  LGBMClassifier           ADASYN clean   1.000000    1.000000   1.000000   \n54  LGBMClassifier   BorderlineSMOTE base   0.976846    0.984645   0.968799   \n52  LGBMClassifier             SMOTE base   0.969733    0.978730   0.960336   \n56  LGBMClassifier            ADASYN base   0.969138    0.978688   0.958519   \n51  LGBMClassifier                  clean   0.999758    1.000000   0.984375   \n60  LGBMClassifier         TomekLink base   0.999758    0.984615   1.000000   \n61  LGBMClassifier        TomekLink clean   0.999758    0.984615   1.000000   \n58  LGBMClassifier          NearMiss base   0.971142    0.975576   0.992193   \n59  LGBMClassifier         NearMiss clean   0.500000    0.000000   0.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n55  1.000000  0.987599   0.800000  0.285714  0.421053  \n50  0.658965  0.948301   0.753472  0.359272  0.486547  \n53  1.000000  0.987035   0.727273  0.285714  0.410256  \n57  1.000000  0.987035   0.727273  0.285714  0.410256  \n54  0.976658  0.945592   0.632035  0.483444  0.547842  \n52  0.969446  0.941641   0.581006  0.516556  0.546889  \n56  0.968498  0.940738   0.574388  0.504967  0.537445  \n51  0.992126  0.981398   0.222222  0.071429  0.108108  \n60  0.992248  0.981398   0.222222  0.071429  0.108108  \n61  0.992248  0.981398   0.222222  0.071429  0.108108  \n58  0.983814  0.138052   0.070801  0.960265  0.131878  \n59  0.000000  0.984216   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.800000</td>\n      <td>0.285714</td>\n      <td>0.421053</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.964298</td>\n      <td>0.944371</td>\n      <td>0.506033</td>\n      <td>0.658965</td>\n      <td>0.948301</td>\n      <td>0.753472</td>\n      <td>0.359272</td>\n      <td>0.486547</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.976846</td>\n      <td>0.984645</td>\n      <td>0.968799</td>\n      <td>0.976658</td>\n      <td>0.945592</td>\n      <td>0.632035</td>\n      <td>0.483444</td>\n      <td>0.547842</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969733</td>\n      <td>0.978730</td>\n      <td>0.960336</td>\n      <td>0.969446</td>\n      <td>0.941641</td>\n      <td>0.581006</td>\n      <td>0.516556</td>\n      <td>0.546889</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.969138</td>\n      <td>0.978688</td>\n      <td>0.958519</td>\n      <td>0.968498</td>\n      <td>0.940738</td>\n      <td>0.574388</td>\n      <td>0.504967</td>\n      <td>0.537445</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.971142</td>\n      <td>0.975576</td>\n      <td>0.992193</td>\n      <td>0.983814</td>\n      <td>0.138052</td>\n      <td>0.070801</td>\n      <td>0.960265</td>\n      <td>0.131878</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LGBMClassifier\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:17.849792800Z",
     "start_time": "2024-11-13T21:29:17.820792400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Stacking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', LinearSVC(random_state=42))\n",
    "]\n",
    "stack = StackingClassifier(estimators=base_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:17.907792400Z",
     "start_time": "2024-11-13T21:29:17.851794800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [],
   "source": [
    "# stack.fit(X_train_base, y_train_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:17.987792600Z",
     "start_time": "2024-11-13T21:29:17.864792100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model comparision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model                variant  train_acc  train_prec  \\\n11         RandomForest        TomekLink clean   1.000000    1.000000   \n3          RandomForest            SMOTE clean   1.000000    1.000000   \n5          RandomForest  BorderlineSMOTE clean   1.000000    1.000000   \n21        XGBClassifier           ADASYN clean   0.998404    1.000000   \n0          RandomForest                   base   0.999855    1.000000   \n..                  ...                    ...        ...         ...   \n49   CatBoostClassifier        TomekLink clean   0.985728    0.857143   \n36  XGBClassifier-tuned         TomekLink base   0.984519    0.000000   \n39   CatBoostClassifier                  clean   0.985738    1.000000   \n37  XGBClassifier-tuned        TomekLink clean   0.984519    0.000000   \n48   CatBoostClassifier         TomekLink base   0.985728    0.857143   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n11   1.000000  1.000000  0.986471   1.000000  0.142857  0.250000  \n3    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n5    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n21   0.996807  0.998401  0.988726   0.900000  0.321429  0.473684  \n0    0.997871  0.998934  0.956203   0.880282  0.413907  0.563063  \n..        ...       ...       ...        ...       ...       ...  \n49   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n36   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n39   0.078125  0.144928  0.983653   0.000000  0.000000  0.000000  \n37   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n48   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n\n[62 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.986471</td>\n      <td>1.000000</td>\n      <td>0.142857</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.998404</td>\n      <td>1.000000</td>\n      <td>0.996807</td>\n      <td>0.998401</td>\n      <td>0.988726</td>\n      <td>0.900000</td>\n      <td>0.321429</td>\n      <td>0.473684</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.956203</td>\n      <td>0.880282</td>\n      <td>0.413907</td>\n      <td>0.563063</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink base</td>\n      <td>0.984519</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.985738</td>\n      <td>1.000000</td>\n      <td>0.078125</td>\n      <td>0.144928</td>\n      <td>0.983653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink clean</td>\n      <td>0.984519</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.019791400Z",
     "start_time": "2024-11-13T21:29:17.881791300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model          variant  train_acc  train_prec  train_rec  \\\n46   CatBoostClassifier    NearMiss base   0.891468    0.891635   0.998581   \n34  XGBClassifier-tuned    NearMiss base   0.911543    0.912760   0.995032   \n8          RandomForest    NearMiss base   0.998118    1.000000   0.997871   \n22        XGBClassifier    NearMiss base   0.966123    0.969508   0.992903   \n58       LGBMClassifier    NearMiss base   0.971142    0.975576   0.992193   \n..                  ...              ...        ...         ...        ...   \n49   CatBoostClassifier  TomekLink clean   0.985728    0.857143   0.093750   \n48   CatBoostClassifier   TomekLink base   0.985728    0.857143   0.093750   \n36  XGBClassifier-tuned   TomekLink base   0.984519    0.000000   0.000000   \n37  XGBClassifier-tuned  TomekLink clean   0.984519    0.000000   0.000000   \n59       LGBMClassifier   NearMiss clean   0.500000    0.000000   0.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n46  0.942082  0.072017   0.068148  0.995033  0.127560  \n34  0.952122  0.083644   0.067763  0.975166  0.126721  \n8   0.998934  0.222711   0.078502  0.968543  0.145233  \n22  0.981066  0.137600   0.070976  0.963576  0.132213  \n58  0.983814  0.138052   0.070801  0.960265  0.131878  \n..       ...       ...        ...       ...       ...  \n49  0.169014  0.983089   0.000000  0.000000  0.000000  \n48  0.169014  0.983089   0.000000  0.000000  0.000000  \n36  0.000000  0.984216   0.000000  0.000000  0.000000  \n37  0.000000  0.984216   0.000000  0.000000  0.000000  \n59  0.000000  0.984216   0.000000  0.000000  0.000000  \n\n[62 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>46</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.891468</td>\n      <td>0.891635</td>\n      <td>0.998581</td>\n      <td>0.942082</td>\n      <td>0.072017</td>\n      <td>0.068148</td>\n      <td>0.995033</td>\n      <td>0.127560</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>XGBClassifier-tuned</td>\n      <td>NearMiss base</td>\n      <td>0.911543</td>\n      <td>0.912760</td>\n      <td>0.995032</td>\n      <td>0.952122</td>\n      <td>0.083644</td>\n      <td>0.067763</td>\n      <td>0.975166</td>\n      <td>0.126721</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998118</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.222711</td>\n      <td>0.078502</td>\n      <td>0.968543</td>\n      <td>0.145233</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.966123</td>\n      <td>0.969508</td>\n      <td>0.992903</td>\n      <td>0.981066</td>\n      <td>0.137600</td>\n      <td>0.070976</td>\n      <td>0.963576</td>\n      <td>0.132213</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.971142</td>\n      <td>0.975576</td>\n      <td>0.992193</td>\n      <td>0.983814</td>\n      <td>0.138052</td>\n      <td>0.070801</td>\n      <td>0.960265</td>\n      <td>0.131878</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink base</td>\n      <td>0.984519</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink clean</td>\n      <td>0.984519</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.067793100Z",
     "start_time": "2024-11-13T21:29:17.912793200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model               variant  train_acc  train_prec  \\\n0          RandomForest                  base   0.999855    1.000000   \n2          RandomForest            SMOTE base   0.999922    1.000000   \n6          RandomForest           ADASYN base   0.999921    0.999947   \n54       LGBMClassifier  BorderlineSMOTE base   0.976846    0.984645   \n52       LGBMClassifier            SMOTE base   0.969733    0.978730   \n..                  ...                   ...        ...         ...   \n37  XGBClassifier-tuned       TomekLink clean   0.984519    0.000000   \n36  XGBClassifier-tuned        TomekLink base   0.984519    0.000000   \n35  XGBClassifier-tuned        NearMiss clean   0.500000    0.000000   \n59       LGBMClassifier        NearMiss clean   0.500000    0.000000   \n27  XGBClassifier-tuned                 clean   0.984530    0.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n0    0.997871  0.998934  0.956203   0.880282  0.413907  0.563063  \n2    0.999844  0.999922  0.952026   0.759420  0.433775  0.552160  \n6    0.999894  0.999921  0.952703   0.782875  0.423841  0.549946  \n54   0.968799  0.976658  0.945592   0.632035  0.483444  0.547842  \n52   0.960336  0.969446  0.941641   0.581006  0.516556  0.546889  \n..        ...       ...       ...        ...       ...       ...  \n37   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n36   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n35   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n59   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n27   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n\n[62 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.956203</td>\n      <td>0.880282</td>\n      <td>0.413907</td>\n      <td>0.563063</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.952026</td>\n      <td>0.759420</td>\n      <td>0.433775</td>\n      <td>0.552160</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999921</td>\n      <td>0.999947</td>\n      <td>0.999894</td>\n      <td>0.999921</td>\n      <td>0.952703</td>\n      <td>0.782875</td>\n      <td>0.423841</td>\n      <td>0.549946</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.976846</td>\n      <td>0.984645</td>\n      <td>0.968799</td>\n      <td>0.976658</td>\n      <td>0.945592</td>\n      <td>0.632035</td>\n      <td>0.483444</td>\n      <td>0.547842</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969733</td>\n      <td>0.978730</td>\n      <td>0.960336</td>\n      <td>0.969446</td>\n      <td>0.941641</td>\n      <td>0.581006</td>\n      <td>0.516556</td>\n      <td>0.546889</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink clean</td>\n      <td>0.984519</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink base</td>\n      <td>0.984519</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>XGBClassifier-tuned</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>XGBClassifier-tuned</td>\n      <td>clean</td>\n      <td>0.984530</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_f1\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.113791700Z",
     "start_time": "2024-11-13T21:29:17.944798100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Einfache SVM / Bayes-Classifier zum Vergleich"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1 LinearSVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [],
   "source": [
    "svc = LinearSVC()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.113791700Z",
     "start_time": "2024-11-13T21:29:17.987792600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LinearSVC BASE started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  LinearSVC CLEAN started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  LinearSVC SMOTE-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "4/12 Fitting:  LinearSVC SMOTE-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  LinearSVC BorderlineSMOTE-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "6/12 Fitting:  LinearSVC BorderlineSMOTE-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  LinearSVC ADASYN-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "8/12 Fitting:  LinearSVC ADASYN-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  LinearSVC NearMiss-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LinearSVC NearMiss-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LinearSVC TomekLink-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  LinearSVC TomekLink-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(svc, \"LinearSVC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.880791600Z",
     "start_time": "2024-11-13T21:29:18.003793300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [
    {
     "data": {
      "text/plain": "        model                variant  train_acc  train_prec  train_rec  \\\n62  LinearSVC                   base   0.980891    0.967712   0.744500   \n63  LinearSVC                  clean   0.998550    1.000000   0.906250   \n65  LinearSVC            SMOTE clean   1.000000    1.000000   1.000000   \n69  LinearSVC           ADASYN clean   1.000000    1.000000   1.000000   \n72  LinearSVC         TomekLink base   0.998549    1.000000   0.906250   \n73  LinearSVC        TomekLink clean   0.998549    1.000000   0.906250   \n67  LinearSVC  BorderlineSMOTE clean   1.000000    1.000000   1.000000   \n66  LinearSVC   BorderlineSMOTE base   0.989643    0.991096   0.988163   \n64  LinearSVC             SMOTE base   0.987956    0.978467   0.997871   \n68  LinearSVC            ADASYN base   0.988201    0.977655   0.998993   \n70  LinearSVC          NearMiss base   0.975533    0.977019   0.995742   \n71  LinearSVC         NearMiss clean   1.000000    1.000000   1.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n62  0.841556  0.957896   0.800000  0.509934  0.622851  \n63  0.950820  0.986471   0.750000  0.214286  0.333333  \n65  1.000000  0.987599   0.750000  0.321429  0.450000  \n69  1.000000  0.987599   0.750000  0.321429  0.450000  \n72  0.950820  0.986471   0.750000  0.214286  0.333333  \n73  0.950820  0.986471   0.750000  0.214286  0.333333  \n67  1.000000  0.987035   0.727273  0.285714  0.410256  \n66  0.989627  0.947963   0.623489  0.597682  0.610313  \n64  0.988074  0.934530   0.514563  0.701987  0.593838  \n68  0.988209  0.933175   0.507126  0.706954  0.590595  \n70  0.986292  0.165594   0.074473  0.983444  0.138462  \n71  1.000000  0.810034   0.054755  0.678571  0.101333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>62</th>\n      <td>LinearSVC</td>\n      <td>base</td>\n      <td>0.980891</td>\n      <td>0.967712</td>\n      <td>0.744500</td>\n      <td>0.841556</td>\n      <td>0.957896</td>\n      <td>0.800000</td>\n      <td>0.509934</td>\n      <td>0.622851</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>LinearSVC</td>\n      <td>clean</td>\n      <td>0.998550</td>\n      <td>1.000000</td>\n      <td>0.906250</td>\n      <td>0.950820</td>\n      <td>0.986471</td>\n      <td>0.750000</td>\n      <td>0.214286</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>LinearSVC</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>LinearSVC</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>LinearSVC</td>\n      <td>TomekLink base</td>\n      <td>0.998549</td>\n      <td>1.000000</td>\n      <td>0.906250</td>\n      <td>0.950820</td>\n      <td>0.986471</td>\n      <td>0.750000</td>\n      <td>0.214286</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>LinearSVC</td>\n      <td>TomekLink clean</td>\n      <td>0.998549</td>\n      <td>1.000000</td>\n      <td>0.906250</td>\n      <td>0.950820</td>\n      <td>0.986471</td>\n      <td>0.750000</td>\n      <td>0.214286</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>LinearSVC</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>LinearSVC</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.989643</td>\n      <td>0.991096</td>\n      <td>0.988163</td>\n      <td>0.989627</td>\n      <td>0.947963</td>\n      <td>0.623489</td>\n      <td>0.597682</td>\n      <td>0.610313</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>LinearSVC</td>\n      <td>SMOTE base</td>\n      <td>0.987956</td>\n      <td>0.978467</td>\n      <td>0.997871</td>\n      <td>0.988074</td>\n      <td>0.934530</td>\n      <td>0.514563</td>\n      <td>0.701987</td>\n      <td>0.593838</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>LinearSVC</td>\n      <td>ADASYN base</td>\n      <td>0.988201</td>\n      <td>0.977655</td>\n      <td>0.998993</td>\n      <td>0.988209</td>\n      <td>0.933175</td>\n      <td>0.507126</td>\n      <td>0.706954</td>\n      <td>0.590595</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>LinearSVC</td>\n      <td>NearMiss base</td>\n      <td>0.975533</td>\n      <td>0.977019</td>\n      <td>0.995742</td>\n      <td>0.986292</td>\n      <td>0.165594</td>\n      <td>0.074473</td>\n      <td>0.983444</td>\n      <td>0.138462</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>LinearSVC</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.810034</td>\n      <td>0.054755</td>\n      <td>0.678571</td>\n      <td>0.101333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LinearSVC\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.947793Z",
     "start_time": "2024-11-13T21:29:18.870792200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "svc = LinearSVC(\n",
    "    class_weight=\"balanced\")  # ohne balanced wird die SVC in einigen Fällen nur auf 0 trainiert, d.h. precision = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:18.948794Z",
     "start_time": "2024-11-13T21:29:18.900793100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LinearSVC-balanced BASE started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  LinearSVC-balanced CLEAN started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  LinearSVC-balanced SMOTE-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "4/12 Fitting:  LinearSVC-balanced SMOTE-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  LinearSVC-balanced BorderlineSMOTE-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "6/12 Fitting:  LinearSVC-balanced BorderlineSMOTE-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  LinearSVC-balanced ADASYN-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "8/12 Fitting:  LinearSVC-balanced ADASYN-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  LinearSVC-balanced NearMiss-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LinearSVC-balanced NearMiss-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LinearSVC-balanced TomekLink-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  LinearSVC-balanced TomekLink-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(svc, \"LinearSVC-balanced\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:19.913792100Z",
     "start_time": "2024-11-13T21:29:18.916805900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "data": {
      "text/plain": "                 model                variant  train_acc  train_prec  \\\n78  LinearSVC-balanced   BorderlineSMOTE base   0.989643    0.991096   \n76  LinearSVC-balanced             SMOTE base   0.987956    0.978467   \n74  LinearSVC-balanced                   base   0.969619    0.692270   \n80  LinearSVC-balanced            ADASYN base   0.987965    0.977100   \n75  LinearSVC-balanced                  clean   0.999758    0.984615   \n77  LinearSVC-balanced            SMOTE clean   1.000000    1.000000   \n81  LinearSVC-balanced           ADASYN clean   1.000000    1.000000   \n84  LinearSVC-balanced         TomekLink base   0.999758    0.984615   \n85  LinearSVC-balanced        TomekLink clean   0.999758    0.984615   \n79  LinearSVC-balanced  BorderlineSMOTE clean   1.000000    1.000000   \n82  LinearSVC-balanced          NearMiss base   0.967378    0.997799   \n83  LinearSVC-balanced         NearMiss clean   1.000000    1.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n78   0.988163  0.989627  0.947963   0.623489  0.597682  0.610313  \n76   0.997871  0.988074  0.934530   0.514563  0.701987  0.593838  \n74   0.997871  0.817442  0.930128   0.491803  0.745033  0.592495  \n80   0.999099  0.987977  0.932498   0.503538  0.706954  0.588154  \n75   1.000000  0.992248  0.987599   0.750000  0.321429  0.450000  \n77   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n81   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n84   1.000000  0.992248  0.987599   0.750000  0.321429  0.450000  \n85   1.000000  0.992248  0.987599   0.750000  0.321429  0.450000  \n79   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n82   0.965224  0.981241  0.386274   0.093250  0.917219  0.169290  \n83   1.000000  1.000000  0.810034   0.054755  0.678571  0.101333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>78</th>\n      <td>LinearSVC-balanced</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.989643</td>\n      <td>0.991096</td>\n      <td>0.988163</td>\n      <td>0.989627</td>\n      <td>0.947963</td>\n      <td>0.623489</td>\n      <td>0.597682</td>\n      <td>0.610313</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>LinearSVC-balanced</td>\n      <td>SMOTE base</td>\n      <td>0.987956</td>\n      <td>0.978467</td>\n      <td>0.997871</td>\n      <td>0.988074</td>\n      <td>0.934530</td>\n      <td>0.514563</td>\n      <td>0.701987</td>\n      <td>0.593838</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>LinearSVC-balanced</td>\n      <td>base</td>\n      <td>0.969619</td>\n      <td>0.692270</td>\n      <td>0.997871</td>\n      <td>0.817442</td>\n      <td>0.930128</td>\n      <td>0.491803</td>\n      <td>0.745033</td>\n      <td>0.592495</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>LinearSVC-balanced</td>\n      <td>ADASYN base</td>\n      <td>0.987965</td>\n      <td>0.977100</td>\n      <td>0.999099</td>\n      <td>0.987977</td>\n      <td>0.932498</td>\n      <td>0.503538</td>\n      <td>0.706954</td>\n      <td>0.588154</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>LinearSVC-balanced</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>LinearSVC-balanced</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>LinearSVC-balanced</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>LinearSVC-balanced</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>LinearSVC-balanced</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>LinearSVC-balanced</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>LinearSVC-balanced</td>\n      <td>NearMiss base</td>\n      <td>0.967378</td>\n      <td>0.997799</td>\n      <td>0.965224</td>\n      <td>0.981241</td>\n      <td>0.386274</td>\n      <td>0.093250</td>\n      <td>0.917219</td>\n      <td>0.169290</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>LinearSVC-balanced</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.810034</td>\n      <td>0.054755</td>\n      <td>0.678571</td>\n      <td>0.101333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LinearSVC-balanced\"].sort_values(by=[\"test_f1\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:36:54.801463200Z",
     "start_time": "2024-11-13T21:36:54.669930100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2 Bayes-Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:19.971792400Z",
     "start_time": "2024-11-13T21:29:19.936793200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [],
   "source": [
    "bayes = GaussianNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:19.996791600Z",
     "start_time": "2024-11-13T21:29:19.953793700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  GaussianNB BASE started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  GaussianNB CLEAN started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  GaussianNB SMOTE-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "4/12 Fitting:  GaussianNB SMOTE-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  GaussianNB BorderlineSMOTE-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "6/12 Fitting:  GaussianNB BorderlineSMOTE-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  GaussianNB ADASYN-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "8/12 Fitting:  GaussianNB ADASYN-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  GaussianNB NearMiss-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  GaussianNB NearMiss-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  GaussianNB TomekLink-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  GaussianNB TomekLink-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(svc, \"GaussianNB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:20.999801100Z",
     "start_time": "2024-11-13T21:29:19.977792900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "data": {
      "text/plain": "         model                variant  train_acc  train_prec  train_rec  \\\n90  GaussianNB   BorderlineSMOTE base   0.989643    0.991096   0.988163   \n88  GaussianNB             SMOTE base   0.987956    0.978467   0.997871   \n86  GaussianNB                   base   0.969619    0.692270   0.997871   \n92  GaussianNB            ADASYN base   0.987965    0.977100   0.999099   \n87  GaussianNB                  clean   0.999758    0.984615   1.000000   \n89  GaussianNB            SMOTE clean   1.000000    1.000000   1.000000   \n93  GaussianNB           ADASYN clean   1.000000    1.000000   1.000000   \n96  GaussianNB         TomekLink base   0.999758    0.984615   1.000000   \n97  GaussianNB        TomekLink clean   0.999758    0.984615   1.000000   \n91  GaussianNB  BorderlineSMOTE clean   1.000000    1.000000   1.000000   \n94  GaussianNB          NearMiss base   0.967378    0.997799   0.965224   \n95  GaussianNB         NearMiss clean   1.000000    1.000000   1.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n90  0.989627  0.947963   0.623489  0.597682  0.610313  \n88  0.988074  0.934530   0.514563  0.701987  0.593838  \n86  0.817442  0.930128   0.491803  0.745033  0.592495  \n92  0.987977  0.932498   0.503538  0.706954  0.588154  \n87  0.992248  0.987599   0.750000  0.321429  0.450000  \n89  1.000000  0.987599   0.750000  0.321429  0.450000  \n93  1.000000  0.987599   0.750000  0.321429  0.450000  \n96  0.992248  0.987599   0.750000  0.321429  0.450000  \n97  0.992248  0.987599   0.750000  0.321429  0.450000  \n91  1.000000  0.987035   0.727273  0.285714  0.410256  \n94  0.981241  0.386274   0.093250  0.917219  0.169290  \n95  1.000000  0.810034   0.054755  0.678571  0.101333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>90</th>\n      <td>GaussianNB</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.989643</td>\n      <td>0.991096</td>\n      <td>0.988163</td>\n      <td>0.989627</td>\n      <td>0.947963</td>\n      <td>0.623489</td>\n      <td>0.597682</td>\n      <td>0.610313</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>GaussianNB</td>\n      <td>SMOTE base</td>\n      <td>0.987956</td>\n      <td>0.978467</td>\n      <td>0.997871</td>\n      <td>0.988074</td>\n      <td>0.934530</td>\n      <td>0.514563</td>\n      <td>0.701987</td>\n      <td>0.593838</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>GaussianNB</td>\n      <td>base</td>\n      <td>0.969619</td>\n      <td>0.692270</td>\n      <td>0.997871</td>\n      <td>0.817442</td>\n      <td>0.930128</td>\n      <td>0.491803</td>\n      <td>0.745033</td>\n      <td>0.592495</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>GaussianNB</td>\n      <td>ADASYN base</td>\n      <td>0.987965</td>\n      <td>0.977100</td>\n      <td>0.999099</td>\n      <td>0.987977</td>\n      <td>0.932498</td>\n      <td>0.503538</td>\n      <td>0.706954</td>\n      <td>0.588154</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>GaussianNB</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>GaussianNB</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>GaussianNB</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>GaussianNB</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>GaussianNB</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>GaussianNB</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>GaussianNB</td>\n      <td>NearMiss base</td>\n      <td>0.967378</td>\n      <td>0.997799</td>\n      <td>0.965224</td>\n      <td>0.981241</td>\n      <td>0.386274</td>\n      <td>0.093250</td>\n      <td>0.917219</td>\n      <td>0.169290</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>GaussianNB</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.810034</td>\n      <td>0.054755</td>\n      <td>0.678571</td>\n      <td>0.101333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"GaussianNB\"].sort_values(by=[\"test_f1\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:36:48.151303600Z",
     "start_time": "2024-11-13T21:36:48.095302600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:29:21.055793800Z",
     "start_time": "2024-11-13T21:29:21.017794Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
