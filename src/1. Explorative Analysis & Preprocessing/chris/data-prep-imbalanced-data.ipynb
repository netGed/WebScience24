{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports & Downloads"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NearMiss, CondensedNearestNeighbour, NeighbourhoodCleaningRule\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:19.555310Z",
     "start_time": "2024-11-10T18:42:19.075382100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Einladen der Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Originaldaten ohne umfassende Vorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet\nid                                                          \n1       0   @user when a father is dysfunctional and is s...\n2       0  @user @user thanks for #lyft credit i can't us...\n3       0                                bihday your majesty\n4       0  #model   i love u take with u all the time in ...\n5       0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_basic_cleaned.csv'))\n",
    "df = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:20.010120500Z",
     "start_time": "2024-11-10T18:42:19.110697900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 2013\n",
      "Negative: 27517\n",
      "Verhältnis: 13.669647292598112\n"
     ]
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "positive = len(df[df['label'] == 1])\n",
    "negative = len(df[df['label'] == 0])\n",
    "print(\"Positive:\", positive)\n",
    "print(\"Negative:\", negative)\n",
    "print(\"Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:20.025287200Z",
     "start_time": "2024-11-10T18:42:19.185255200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorverarbeitete Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet  \\\nid                                                             \n1       0   @user when a father is dysfunctional and is s...   \n2       0  @user @user thanks for #lyft credit i can't us...   \n3       0                                bihday your majesty   \n4       0  #model   i love u take with u all the time in ...   \n5       0             factsguide: society now    #motivation   \n\n                                        tweet_cleaned  user_handle  \\\nid                                                                   \n1                         father selfish drag kid run            1   \n2               thank lyft credit use cause offer van            2   \n3                                      bihday majesty            0   \n4   model take time mobile phone kiss sunglass mou...            0   \n5                       factsguide society motivation            0   \n\n                                    hashtags  \\\nid                                             \n1                                   ['#run']   \n2   ['#lyft', '#disapointed', '#getthanked']   \n3                                         []   \n4                                 ['#model']   \n5                            ['#motivation']   \n\n                                               emojis  \nid                                                     \n1                                                 NaN  \n2                                                 NaN  \n3                                                 NaN  \n4   :mobile_phone:,:kissing_face_with_smiling_eyes...  \n5                                                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_cleaned</th>\n      <th>user_handle</th>\n      <th>hashtags</th>\n      <th>emojis</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n      <td>father selfish drag kid run</td>\n      <td>1</td>\n      <td>['#run']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n      <td>thank lyft credit use cause offer van</td>\n      <td>2</td>\n      <td>['#lyft', '#disapointed', '#getthanked']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n      <td>bihday majesty</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n      <td>model take time mobile phone kiss sunglass mou...</td>\n      <td>0</td>\n      <td>['#model']</td>\n      <td>:mobile_phone:,:kissing_face_with_smiling_eyes...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n      <td>factsguide society motivation</td>\n      <td>0</td>\n      <td>['#motivation']</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df_cleaned.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:20.135376100Z",
     "start_time": "2024-11-10T18:42:19.200367800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 1811\n",
      "Negative: 25839\n",
      "Verhältnis: 14.26780784097184\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['label'].value_counts()\n",
    "positive = len(df_cleaned[df_cleaned['label'] == 1])\n",
    "negative = len(df_cleaned[df_cleaned['label'] == 0])\n",
    "print(\"Positive:\", positive)\n",
    "print(\"Negative:\", negative)\n",
    "print(\"Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:20.165574500Z",
     "start_time": "2024-11-10T18:42:19.315545200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verhältnis hat sich durch die Bereinigung sogar noch weiter verschlechter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vektorisierung der Daten\n",
    "https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#Unsupervised_text_classification_Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def vectorize(sentence, w2v_model):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:20.202423Z",
     "start_time": "2024-11-10T18:42:19.341099800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def vectorize_df(df):\n",
    "    X = df[\"tweet\"]\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    sentences_base = [sentence.split() for sentence in X]\n",
    "    w2v_model_base = Word2Vec(sentences_base, window=5, min_count=5, workers=-1)\n",
    "\n",
    "    x_data = np.array([vectorize(sentence, w2v_model_base) for sentence in X])\n",
    "    return x_data, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:20.215534200Z",
     "start_time": "2024-11-10T18:42:19.355448800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X_base, y_base = vectorize_df(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:21.990686400Z",
     "start_time": "2024-11-10T18:42:19.375708300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.30374171e-03, -6.65663800e-04,  3.21442029e-03, ...,\n        -2.68328539e-03,  1.41547900e-03, -2.84765265e-03],\n       [ 3.36569443e-04, -9.82483965e-04,  9.05304274e-04, ...,\n        -4.07109677e-04,  5.64215006e-04,  1.94166932e-04],\n       [ 1.23032148e-03, -2.46845209e-03,  2.51201470e-03, ...,\n         2.88697542e-03,  4.11413144e-03,  4.88469563e-03],\n       ...,\n       [-9.87032778e-04,  5.68386691e-04, -1.85755307e-05, ...,\n         3.09016541e-05, -3.14187346e-04, -8.47426010e-04],\n       [ 1.40571001e-03,  4.23042104e-03,  2.36720010e-03, ...,\n        -4.67062840e-04,  2.66610738e-03, -7.61655625e-04],\n       [ 8.88627619e-05, -6.70738227e-04,  2.82955565e-03, ...,\n        -3.34652583e-03,  8.70123040e-04,  3.40033951e-03]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:21.992229500Z",
     "start_time": "2024-11-10T18:42:21.990686400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "id\n1        0\n2        0\n3        0\n4        0\n5        0\n        ..\n31957    0\n31958    0\n31959    0\n31960    0\n31962    0\nName: label, Length: 29530, dtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:21.994308700Z",
     "start_time": "2024-11-10T18:42:21.990686400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_clean, y_clean = vectorize_df(df_cleaned)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.040005300Z",
     "start_time": "2024-11-10T18:42:21.992229500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.000164  , -0.00097227,  0.00330843, ..., -0.00523365,\n         0.00096938, -0.00285136],\n       [-0.00232347, -0.0016694 ,  0.00038817, ..., -0.00020569,\n         0.00022666,  0.0038221 ],\n       [-0.00620588, -0.00316428,  0.00138663, ...,  0.00165645,\n         0.00093876, -0.00017074],\n       ...,\n       [ 0.0017181 ,  0.00186271,  0.00110266, ..., -0.0023023 ,\n        -0.00016485,  0.00787419],\n       [-0.00182129,  0.00049515,  0.0007572 , ..., -0.00087936,\n        -0.00065907, -0.00146304],\n       [-0.00335515, -0.00040929, -0.00032946, ..., -0.00268573,\n         0.00366877, -0.0030683 ]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.050204300Z",
     "start_time": "2024-11-10T18:42:25.040005300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "id\n1        0\n2        0\n3        0\n4        0\n5        0\n        ..\n31956    0\n31957    0\n31958    0\n31959    0\n31960    0\nName: label, Length: 27650, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.050204300Z",
     "start_time": "2024-11-10T18:42:25.042013600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.050204300Z",
     "start_time": "2024-11-10T18:42:25.042043800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.145360500Z",
     "start_time": "2024-11-10T18:42:25.055240600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Resampling Methods\n",
    "https://www.analyticsvidhya.com/blog/2022/05/handling-imbalanced-data-with-imbalance-learn-in-python/#h-techniques-for-handling-imbalanced-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def print_data(y_before, y_after, sampling_technique):\n",
    "    counter_before = Counter(y_before)\n",
    "    counter_after = Counter(y_after)\n",
    "    print(\"Before sampling with:\", sampling_technique, counter_before)\n",
    "    print(\"After sampling with:\", sampling_technique, counter_after)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.145360500Z",
     "start_time": "2024-11-10T18:42:25.081932500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.1 SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "os_smote = SMOTE()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.145360500Z",
     "start_time": "2024-11-10T18:42:25.087991700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 20638, 1: 1509})\n",
      "After sampling with: SMOTE Counter({0: 20638, 1: 20638})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_s, y_train_base_s = os_smote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.410401300Z",
     "start_time": "2024-11-10T18:42:25.100562200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 19373, 1: 1364})\n",
      "After sampling with: SMOTE Counter({0: 19373, 1: 19373})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_s, y_train_clean_s = os_smote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.565504500Z",
     "start_time": "2024-11-10T18:42:25.390303700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.2 Borderline-SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "os_bsmote = BorderlineSMOTE()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.565504500Z",
     "start_time": "2024-11-10T18:42:25.540302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 20638, 1: 1509})\n",
      "After sampling with: BorderlineSMOTE Counter({0: 20638, 1: 20638})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_bs, y_train_base_bs = os_bsmote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:25.905302700Z",
     "start_time": "2024-11-10T18:42:25.555409200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 19373, 1: 1364})\n",
      "After sampling with: BorderlineSMOTE Counter({0: 19373, 1: 19373})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_bs, y_train_clean_bs = os_bsmote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:26.155168700Z",
     "start_time": "2024-11-10T18:42:25.855176900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.3 ADASYN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "os_ada = ADASYN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:26.155168700Z",
     "start_time": "2024-11-10T18:42:26.130477200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 20638, 1: 1509})\n",
      "After sampling with: ADASYN Counter({1: 20681, 0: 20638})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_a, y_train_base_a = os_ada.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:26.438748500Z",
     "start_time": "2024-11-10T18:42:26.145067900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 19373, 1: 1364})\n",
      "After sampling with: ADASYN Counter({0: 19373, 1: 18998})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_a, y_train_clean_a = os_ada.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:26.725346900Z",
     "start_time": "2024-11-10T18:42:26.440789200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.1 NearMiss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "us_near_miss = NearMiss(version=3, n_neighbors_ver3=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:26.800358900Z",
     "start_time": "2024-11-10T18:42:26.725346900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 20638, 1: 1509})\n",
      "After sampling with: NearMiss Counter({0: 1509, 1: 1509})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_nm, y_train_base_nm = us_near_miss.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:26.959845400Z",
     "start_time": "2024-11-10T18:42:26.740436100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 19373, 1: 1364})\n",
      "After sampling with: NearMiss Counter({0: 1364, 1: 1364})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_nm, y_train_clean_nm = us_near_miss.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.168578900Z",
     "start_time": "2024-11-10T18:42:26.965968600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.2 Condensed Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "us_cnn = CondensedNearestNeighbour(n_neighbors=1, n_jobs=-1)  # sehr langsam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.186761900Z",
     "start_time": "2024-11-10T18:42:27.168578900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# X_train_base_cnn, y_train_base_cnn = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.265199800Z",
     "start_time": "2024-11-10T18:42:27.188818700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# X_train_clean_cnn, y_train_clean_cnn = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.290325700Z",
     "start_time": "2024-11-10T18:42:27.198928900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.3 Neighborhood Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "us_cnn_cr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5, n_jobs=-1)  # sehr langsam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.290325700Z",
     "start_time": "2024-11-10T18:42:27.219171500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# X_train_base_ncr, y_train_base_ncr = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.290325700Z",
     "start_time": "2024-11-10T18:42:27.229302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# X_train_clean_ncr, y_train_clean_ncr = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.290325700Z",
     "start_time": "2024-11-10T18:42:27.249565500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.4 Tomek Links Undersampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "us_tomek = TomekLinks()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:27.290325700Z",
     "start_time": "2024-11-10T18:42:27.267734700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: TomekLinks Counter({0: 20638, 1: 1509})\n",
      "After sampling with: TomekLinks Counter({0: 20581, 1: 1509})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_t, y_train_base_t = us_tomek.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_t, \"TomekLinks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.205261100Z",
     "start_time": "2024-11-10T18:42:27.285316600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: TomekLinks Counter({0: 19373, 1: 1364})\n",
      "After sampling with: TomekLinks Counter({0: 19326, 1: 1364})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_t, y_train_clean_t = us_tomek.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_t, \"TomekLinks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.397420500Z",
     "start_time": "2024-11-10T18:42:29.214906200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Ensemble Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(\n",
    "    columns=[\"model\", \"variant\", \"train_acc\", \"train_prec\", \"train_rec\", \"train_f1\", \"test_acc\", \"test_prec\",\n",
    "             \"test_rec\", \"test_f1\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.407574500Z",
     "start_time": "2024-11-10T18:42:29.387278900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model, model_name, variant, x_data_train, y_data_train, x_data_test, y_data_test):\n",
    "    train_acc = model.score(x_data_train, y_data_train)\n",
    "    train_precision = precision_score(y_data_train, model.predict(x_data_train), average=\"weighted\")\n",
    "    train_recall = recall_score(y_data_train, model.predict(x_data_train), average=\"weighted\")\n",
    "    train_f1 = f1_score(y_data_train, model.predict(x_data_train), average=\"weighted\")\n",
    "\n",
    "    test_acc = model.score(x_data_test, y_data_test)\n",
    "    test_precision = precision_score(y_data_test, model.predict(x_data_test), average=\"weighted\")\n",
    "    test_recall = recall_score(y_data_test, model.predict(x_data_test), average=\"weighted\")\n",
    "    test_f1 = f1_score(y_data_test, model.predict(x_data_test), average=\"weighted\")\n",
    "\n",
    "    evaluation.loc[len(evaluation.index)] = [model_name, variant, train_acc, train_precision, train_recall, train_f1,\n",
    "                                             test_acc, test_precision, test_recall, test_f1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.475338800Z",
     "start_time": "2024-11-10T18:42:29.407574500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, sampling_method):\n",
    "    pred = model.predict(x_test)\n",
    "    accscore = metrics.accuracy_score(pred, y_test)\n",
    "\n",
    "    print(f'{sampling_method} model accuracy for classification is =', str('{:04.2f}'.format(accscore * 100)) + '%')\n",
    "    print('------------------------------------------------')\n",
    "    print('Confusion Matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n",
    "    print('------------------------------------------------')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.498630900Z",
     "start_time": "2024-11-10T18:42:29.427838300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def fit_model(model, modelName):\n",
    "    print(\"Starting model fitting.\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"1/12 Fitting: \", modelName, \"BASE started...\")\n",
    "    model.fit(X_train_base, y_train_base)\n",
    "    add_to_eval_df(model, modelName, \"base\", X_train_base, y_train_base, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"2/12 Fitting: \", modelName, \"CLEAN started...\")\n",
    "    model.fit(X_train_clean, y_train_clean)\n",
    "    add_to_eval_df(model, modelName, \"clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"3/12 Fitting: \", modelName, \"SMOTE-base started...\")\n",
    "    model.fit(X_train_base_s, y_train_base_s)\n",
    "    add_to_eval_df(model, modelName, \"SMOTE base\", X_train_base_s, y_train_base_s, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"4/12 Fitting: \", modelName, \"SMOTE-clean started...\")\n",
    "    model.fit(X_train_clean_s, y_train_clean_s)\n",
    "    add_to_eval_df(model, modelName, \"SMOTE clean\", X_train_clean_s, y_train_clean_s, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"5/12 Fitting: \", modelName, \"BorderlineSMOTE-base started...\")\n",
    "    model.fit(X_train_base_bs, y_train_base_bs)\n",
    "    add_to_eval_df(model, modelName, \"BorderlineSMOTE base\", X_train_base_bs, y_train_base_bs, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"6/12 Fitting: \", modelName, \"BorderlineSMOTE-clean started...\")\n",
    "    model.fit(X_train_clean_bs, y_train_clean_bs)\n",
    "    add_to_eval_df(model, modelName, \"BorderlineSMOTE clean\", X_train_clean_bs, y_train_clean_bs, X_test_clean,\n",
    "                   y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"7/12 Fitting: \", modelName, \"ADASYN-base started...\")\n",
    "    model.fit(X_train_base_a, y_train_base_a)\n",
    "    add_to_eval_df(model, modelName, \"ADASYN base\", X_train_base_a, y_train_base_a, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"8/12 Fitting: \", modelName, \"ADASYN-clean started...\")\n",
    "    model.fit(X_train_clean_a, y_train_clean_a)\n",
    "    add_to_eval_df(model, modelName, \"ADASYN clean\", X_train_clean_a, y_train_clean_a, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"9/12 Fitting: \", modelName, \"NearMiss-base started...\")\n",
    "    model.fit(X_train_base_nm, y_train_base_nm)\n",
    "    add_to_eval_df(model, modelName, \"NearMiss base\", X_train_base_nm, y_train_base_nm, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"10/12 Fitting: \", modelName, \"NearMiss-clean started...\")\n",
    "    model.fit(X_train_clean_nm, y_train_clean_nm)\n",
    "    add_to_eval_df(model, modelName, \"NearMiss clean\", X_train_clean_nm, y_train_clean_nm, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"11/12 Fitting: \", modelName, \"TomekLink-base started...\")\n",
    "    model.fit(X_train_clean_t, y_train_clean_t)\n",
    "    add_to_eval_df(model, modelName, \"TomekLink clean\", X_train_clean_t, y_train_clean_t, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"12/12 Fitting: \", modelName, \"TomekLink-clean started...\")\n",
    "    model.fit(X_train_clean_t, y_train_clean_t)\n",
    "    add_to_eval_df(model, modelName, \"TomekLink clean\", X_train_clean_t, y_train_clean_t, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    print(\"Model fitting finished.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.498630900Z",
     "start_time": "2024-11-10T18:42:29.437974200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:42:29.498630900Z",
     "start_time": "2024-11-10T18:42:29.486474100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  RandomForest BASE started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  7 Seconds\n",
      "2/12 Fitting:  RandomForest CLEAN started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  7 Seconds\n",
      "3/12 Fitting:  RandomForest SMOTE-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  13 Seconds\n",
      "4/12 Fitting:  RandomForest SMOTE-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  13 Seconds\n",
      "5/12 Fitting:  RandomForest BorderlineSMOTE-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  13 Seconds\n",
      "6/12 Fitting:  RandomForest BorderlineSMOTE-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  12 Seconds\n",
      "7/12 Fitting:  RandomForest ADASYN-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  17 Seconds\n",
      "8/12 Fitting:  RandomForest ADASYN-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  14 Seconds\n",
      "9/12 Fitting:  RandomForest NearMiss-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "10/12 Fitting:  RandomForest NearMiss-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "11/12 Fitting:  RandomForest TomekLink-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  5 Seconds\n",
      "12/12 Fitting:  RandomForest TomekLink-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  5 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(rf, \"RandomForest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:17.467513800Z",
     "start_time": "2024-11-10T18:42:29.498630900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "brf = BalancedRandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:17.483511600Z",
     "start_time": "2024-11-10T18:44:17.471514700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BASE\n",
    "brf.fit(X_train_base, y_train_base)\n",
    "add_to_eval_df(brf, \"BalancedRandomForest\", \"BALANCED base\", X_train_base, y_train_base, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:19.100005Z",
     "start_time": "2024-11-10T18:44:17.487598900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CLEANED\n",
    "brf.fit(X_train_clean, y_train_clean)\n",
    "add_to_eval_df(brf, \"BalancedRandomForest\", \"BALANCED clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:20.688797500Z",
     "start_time": "2024-11-10T18:44:19.108016800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n1           RandomForest                  clean   0.999711    0.999711   \n10          RandomForest        TomekLink clean   0.999710    0.999710   \n11          RandomForest        TomekLink clean   0.999710    0.999710   \n0           RandomForest                   base   0.999729    0.999729   \n5           RandomForest  BorderlineSMOTE clean   0.999871    0.999871   \n4           RandomForest   BorderlineSMOTE base   0.999176    0.999178   \n3           RandomForest            SMOTE clean   0.999794    0.999794   \n7           RandomForest           ADASYN clean   0.999739    0.999739   \n2           RandomForest             SMOTE base   0.999443    0.999443   \n6           RandomForest            ADASYN base   0.999443    0.999444   \n12  BalancedRandomForest          BALANCED base   0.799296    0.949070   \n13  BalancedRandomForest         BALANCED clean   0.771712    0.948730   \n8           RandomForest          NearMiss base   0.999337    0.999338   \n9           RandomForest         NearMiss clean   0.999633    0.999634   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n1    0.999711  0.999710  0.935918   0.924098  0.935918  0.906055  \n10   0.999710  0.999710  0.935773   0.921662  0.935773  0.905707  \n11   0.999710  0.999710  0.935773   0.918701  0.935773  0.905979  \n0    0.999729  0.999729  0.933496   0.937926  0.933496  0.903062  \n5    0.999871  0.999871  0.922176   0.896158  0.922176  0.906817  \n4    0.999176  0.999176  0.918326   0.895816  0.918326  0.904959  \n3    0.999794  0.999794  0.917981   0.896207  0.917981  0.905666  \n7    0.999739  0.999739  0.913786   0.893155  0.913786  0.902476  \n2    0.999443  0.999443  0.911147   0.893146  0.911147  0.901177  \n6    0.999443  0.999443  0.909251   0.895514  0.909251  0.901808  \n12   0.799296  0.846950  0.711635   0.905412  0.711635  0.782027  \n13   0.771761  0.828229  0.667872   0.907749  0.667872  0.752252  \n8    0.999337  0.999337  0.425437   0.885160  0.425437  0.539718  \n9    0.999633  0.999633  0.423261   0.882394  0.423261  0.541775  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>0.999710</td>\n      <td>0.935918</td>\n      <td>0.924098</td>\n      <td>0.935918</td>\n      <td>0.906055</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.935773</td>\n      <td>0.921662</td>\n      <td>0.935773</td>\n      <td>0.905707</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.935773</td>\n      <td>0.918701</td>\n      <td>0.935773</td>\n      <td>0.905979</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.933496</td>\n      <td>0.937926</td>\n      <td>0.933496</td>\n      <td>0.903062</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.999871</td>\n      <td>0.999871</td>\n      <td>0.999871</td>\n      <td>0.999871</td>\n      <td>0.922176</td>\n      <td>0.896158</td>\n      <td>0.922176</td>\n      <td>0.906817</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999176</td>\n      <td>0.999178</td>\n      <td>0.999176</td>\n      <td>0.999176</td>\n      <td>0.918326</td>\n      <td>0.895816</td>\n      <td>0.918326</td>\n      <td>0.904959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>0.999794</td>\n      <td>0.999794</td>\n      <td>0.999794</td>\n      <td>0.999794</td>\n      <td>0.917981</td>\n      <td>0.896207</td>\n      <td>0.917981</td>\n      <td>0.905666</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>0.999739</td>\n      <td>0.999739</td>\n      <td>0.999739</td>\n      <td>0.999739</td>\n      <td>0.913786</td>\n      <td>0.893155</td>\n      <td>0.913786</td>\n      <td>0.902476</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.911147</td>\n      <td>0.893146</td>\n      <td>0.911147</td>\n      <td>0.901177</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999443</td>\n      <td>0.999444</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.909251</td>\n      <td>0.895514</td>\n      <td>0.909251</td>\n      <td>0.901808</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.799296</td>\n      <td>0.949070</td>\n      <td>0.799296</td>\n      <td>0.846950</td>\n      <td>0.711635</td>\n      <td>0.905412</td>\n      <td>0.711635</td>\n      <td>0.782027</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.771712</td>\n      <td>0.948730</td>\n      <td>0.771761</td>\n      <td>0.828229</td>\n      <td>0.667872</td>\n      <td>0.907749</td>\n      <td>0.667872</td>\n      <td>0.752252</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.999337</td>\n      <td>0.999338</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.425437</td>\n      <td>0.885160</td>\n      <td>0.425437</td>\n      <td>0.539718</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.423261</td>\n      <td>0.882394</td>\n      <td>0.423261</td>\n      <td>0.541775</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[(evaluation.model == \"RandomForest\") | (evaluation.model == \"BalancedRandomForest\")].sort_values(\n",
    "    by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:20.728790100Z",
     "start_time": "2024-11-10T18:44:20.692787800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1a XGBClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:20.764790100Z",
     "start_time": "2024-11-10T18:44:20.720791800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  XGBClassifier BASE started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "2/12 Fitting:  XGBClassifier CLEAN started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "3/12 Fitting:  XGBClassifier SMOTE-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "4/12 Fitting:  XGBClassifier SMOTE-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "5/12 Fitting:  XGBClassifier BorderlineSMOTE-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "6/12 Fitting:  XGBClassifier BorderlineSMOTE-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  3 Seconds\n",
      "7/12 Fitting:  XGBClassifier ADASYN-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  2 Seconds\n",
      "8/12 Fitting:  XGBClassifier ADASYN-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  2 Seconds\n",
      "9/12 Fitting:  XGBClassifier NearMiss-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "10/12 Fitting:  XGBClassifier NearMiss-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "11/12 Fitting:  XGBClassifier TomekLink-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "12/12 Fitting:  XGBClassifier TomekLink-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(xgb, \"XGBClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:47.751774Z",
     "start_time": "2024-11-10T18:44:20.736785200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "            model                variant  train_acc  train_prec  train_rec  \\\n24  XGBClassifier        TomekLink clean   0.999420    0.999420   0.999420   \n25  XGBClassifier        TomekLink clean   0.999420    0.999420   0.999420   \n15  XGBClassifier                  clean   0.999566    0.999566   0.999566   \n14  XGBClassifier                   base   0.999142    0.999142   0.999142   \n19  XGBClassifier  BorderlineSMOTE clean   0.997651    0.997651   0.997651   \n18  XGBClassifier   BorderlineSMOTE base   0.994549    0.994550   0.994549   \n21  XGBClassifier           ADASYN clean   0.996534    0.996551   0.996534   \n16  XGBClassifier             SMOTE base   0.994743    0.994770   0.994743   \n17  XGBClassifier            SMOTE clean   0.996980    0.996992   0.996980   \n20  XGBClassifier            ADASYN base   0.995789    0.995808   0.995789   \n23  XGBClassifier         NearMiss clean   0.999633    0.999634   0.999633   \n22  XGBClassifier          NearMiss base   0.999337    0.999338   0.999337   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n24  0.999419  0.936352   0.916800  0.936352  0.909647  \n25  0.999419  0.936352   0.916800  0.936352  0.909647  \n15  0.999565  0.935773   0.912286  0.935773  0.909072  \n14  0.999140  0.935663   0.931619  0.935663  0.909167  \n19  0.997651  0.905396   0.904404  0.905396  0.904897  \n18  0.994549  0.896113   0.901739  0.896113  0.898845  \n21  0.996534  0.890352   0.899949  0.890352  0.894982  \n16  0.994743  0.887986   0.901167  0.887986  0.894202  \n17  0.996980  0.887892   0.900993  0.887892  0.894133  \n20  0.995789  0.887850   0.900422  0.887850  0.893800  \n23  0.999633  0.505569   0.888524  0.505569  0.620631  \n22  0.999337  0.489503   0.887529  0.489503  0.602656  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999419</td>\n      <td>0.936352</td>\n      <td>0.916800</td>\n      <td>0.936352</td>\n      <td>0.909647</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999419</td>\n      <td>0.936352</td>\n      <td>0.916800</td>\n      <td>0.936352</td>\n      <td>0.909647</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.999566</td>\n      <td>0.999566</td>\n      <td>0.999566</td>\n      <td>0.999565</td>\n      <td>0.935773</td>\n      <td>0.912286</td>\n      <td>0.935773</td>\n      <td>0.909072</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.999142</td>\n      <td>0.999142</td>\n      <td>0.999142</td>\n      <td>0.999140</td>\n      <td>0.935663</td>\n      <td>0.931619</td>\n      <td>0.935663</td>\n      <td>0.909167</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997651</td>\n      <td>0.997651</td>\n      <td>0.997651</td>\n      <td>0.997651</td>\n      <td>0.905396</td>\n      <td>0.904404</td>\n      <td>0.905396</td>\n      <td>0.904897</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.994549</td>\n      <td>0.994550</td>\n      <td>0.994549</td>\n      <td>0.994549</td>\n      <td>0.896113</td>\n      <td>0.901739</td>\n      <td>0.896113</td>\n      <td>0.898845</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.996534</td>\n      <td>0.996551</td>\n      <td>0.996534</td>\n      <td>0.996534</td>\n      <td>0.890352</td>\n      <td>0.899949</td>\n      <td>0.890352</td>\n      <td>0.894982</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.994743</td>\n      <td>0.994770</td>\n      <td>0.994743</td>\n      <td>0.994743</td>\n      <td>0.887986</td>\n      <td>0.901167</td>\n      <td>0.887986</td>\n      <td>0.894202</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.996980</td>\n      <td>0.996992</td>\n      <td>0.996980</td>\n      <td>0.996980</td>\n      <td>0.887892</td>\n      <td>0.900993</td>\n      <td>0.887892</td>\n      <td>0.894133</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.995789</td>\n      <td>0.995808</td>\n      <td>0.995789</td>\n      <td>0.995789</td>\n      <td>0.887850</td>\n      <td>0.900422</td>\n      <td>0.887850</td>\n      <td>0.893800</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.505569</td>\n      <td>0.888524</td>\n      <td>0.505569</td>\n      <td>0.620631</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.999337</td>\n      <td>0.999338</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.489503</td>\n      <td>0.887529</td>\n      <td>0.489503</td>\n      <td>0.602656</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"XGBClassifier\"].sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:47.806771700Z",
     "start_time": "2024-11-10T18:44:47.754773900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1b XGBClassifier tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:09:33.749567200Z",
     "start_time": "2024-11-10T19:09:33.732570200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test1, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:23:02.674259400Z",
     "start_time": "2024-11-10T19:23:02.633261100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7424466598112309, {'max_depth': 9})"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(X_train_clean, y_train_clean)\n",
    "gsearch1.best_score_, gsearch1.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:23:51.589798200Z",
     "start_time": "2024-11-10T19:23:04.130072300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    "    'min_child_weight': range(1, 6, 2),\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test2, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:24:09.382810200Z",
     "start_time": "2024-11-10T19:24:09.360803400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7459381685237177, {'min_child_weight': 5})"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.fit(X_train_clean, y_train_clean)\n",
    "gsearch2.best_score_, gsearch2.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:24:47.100623900Z",
     "start_time": "2024-11-10T19:24:11.104127500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'gamma': [i / 10.0 for i in range(0, 5)],\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test3, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:26:54.393949700Z",
     "start_time": "2024-11-10T19:26:54.347075900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7473632876235745, {'gamma': 0.1})"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.fit(X_train_clean, y_train_clean)\n",
    "gsearch3.best_score_, gsearch3.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:27:43.908619400Z",
     "start_time": "2024-11-10T19:26:54.747540500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    "    'subsample': [i / 10.0 for i in range(6, 10)],\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test4, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:27:54.900741Z",
     "start_time": "2024-11-10T19:27:54.852741400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7473632876235745, {'subsample': 0.8})"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.fit(X_train_clean, y_train_clean)\n",
    "gsearch4.best_score_, gsearch4.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:28:37.354980300Z",
     "start_time": "2024-11-10T19:27:55.020747900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    "    'colsample_bytree': [i / 10.0 for i in range(6, 10)],\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:28:56.203484600Z",
     "start_time": "2024-11-10T19:28:56.174488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7473632876235745, {'colsample_bytree': 0.8})"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.fit(X_train_clean, y_train_clean)\n",
    "gsearch5.best_score_, gsearch5.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:29:36.442513Z",
     "start_time": "2024-11-10T19:28:56.807523800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test6, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:30:10.919021600Z",
     "start_time": "2024-11-10T19:30:10.901801300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7473632876235745, {'reg_alpha': 1e-05})"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch6.fit(X_train_clean, y_train_clean)\n",
    "gsearch6.best_score_, gsearch6.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:30:55.757851200Z",
     "start_time": "2024-11-10T19:30:12.874004200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "xgb_tune = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:33:24.927933700Z",
     "start_time": "2024-11-10T19:33:24.849538500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  XGBClassifier-tuned BASE started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  5 Seconds\n",
      "2/12 Fitting:  XGBClassifier-tuned CLEAN started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  5 Seconds\n",
      "3/12 Fitting:  XGBClassifier-tuned SMOTE-base started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  8 Seconds\n",
      "4/12 Fitting:  XGBClassifier-tuned SMOTE-clean started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  9 Seconds\n",
      "5/12 Fitting:  XGBClassifier-tuned BorderlineSMOTE-base started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  6 Seconds\n",
      "6/12 Fitting:  XGBClassifier-tuned BorderlineSMOTE-clean started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  6 Seconds\n",
      "7/12 Fitting:  XGBClassifier-tuned ADASYN-base started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  6 Seconds\n",
      "8/12 Fitting:  XGBClassifier-tuned ADASYN-clean started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  6 Seconds\n",
      "9/12 Fitting:  XGBClassifier-tuned NearMiss-base started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  1 Seconds\n",
      "10/12 Fitting:  XGBClassifier-tuned NearMiss-clean started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  1 Seconds\n",
      "11/12 Fitting:  XGBClassifier-tuned TomekLink-base started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  3 Seconds\n",
      "12/12 Fitting:  XGBClassifier-tuned TomekLink-clean started...\n",
      "Fitting:  XGBClassifier-tuned finished. Elapsed time:  3 Seconds\n",
      "Model fitting finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  model                variant  train_acc  train_prec  \\\n60  XGBClassifier-tuned        TomekLink clean   0.998115    0.998117   \n61  XGBClassifier-tuned        TomekLink clean   0.998115    0.998117   \n51  XGBClassifier-tuned                  clean   0.997782    0.997785   \n50  XGBClassifier-tuned                   base   0.996839    0.996850   \n55  XGBClassifier-tuned  BorderlineSMOTE clean   0.998787    0.998788   \n54  XGBClassifier-tuned   BorderlineSMOTE base   0.997383    0.997387   \n53  XGBClassifier-tuned            SMOTE clean   0.999406    0.999406   \n57  XGBClassifier-tuned           ADASYN clean   0.999166    0.999166   \n52  XGBClassifier-tuned             SMOTE base   0.998449    0.998450   \n56  XGBClassifier-tuned            ADASYN base   0.998427    0.998427   \n59  XGBClassifier-tuned         NearMiss clean   0.999633    0.999634   \n58  XGBClassifier-tuned          NearMiss base   0.999337    0.999337   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n60   0.998115  0.998103  0.937220   0.931315  0.937220  0.909395  \n61   0.998115  0.998103  0.937220   0.931315  0.937220  0.909395  \n51   0.997782  0.997765  0.936786   0.931787  0.936786  0.908122  \n50   0.996839  0.996804  0.934850   0.930740  0.934850  0.907133  \n55   0.998787  0.998787  0.911326   0.904257  0.911326  0.907633  \n54   0.997383  0.997383  0.907490   0.902133  0.907490  0.904715  \n53   0.999406  0.999406  0.901924   0.898574  0.901924  0.900225  \n57   0.999166  0.999166  0.898308   0.898835  0.898308  0.898571  \n52   0.998449  0.998449  0.896925   0.900538  0.896925  0.898699  \n56   0.998427  0.998427  0.894352   0.897957  0.894352  0.896125  \n59   0.999633  0.999633  0.493563   0.887924  0.493563  0.609686  \n58   0.999337  0.999337  0.481241   0.893071  0.481241  0.593954  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink clean</td>\n      <td>0.998115</td>\n      <td>0.998117</td>\n      <td>0.998115</td>\n      <td>0.998103</td>\n      <td>0.937220</td>\n      <td>0.931315</td>\n      <td>0.937220</td>\n      <td>0.909395</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>XGBClassifier-tuned</td>\n      <td>TomekLink clean</td>\n      <td>0.998115</td>\n      <td>0.998117</td>\n      <td>0.998115</td>\n      <td>0.998103</td>\n      <td>0.937220</td>\n      <td>0.931315</td>\n      <td>0.937220</td>\n      <td>0.909395</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>XGBClassifier-tuned</td>\n      <td>clean</td>\n      <td>0.997782</td>\n      <td>0.997785</td>\n      <td>0.997782</td>\n      <td>0.997765</td>\n      <td>0.936786</td>\n      <td>0.931787</td>\n      <td>0.936786</td>\n      <td>0.908122</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>XGBClassifier-tuned</td>\n      <td>base</td>\n      <td>0.996839</td>\n      <td>0.996850</td>\n      <td>0.996839</td>\n      <td>0.996804</td>\n      <td>0.934850</td>\n      <td>0.930740</td>\n      <td>0.934850</td>\n      <td>0.907133</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>XGBClassifier-tuned</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.998787</td>\n      <td>0.998788</td>\n      <td>0.998787</td>\n      <td>0.998787</td>\n      <td>0.911326</td>\n      <td>0.904257</td>\n      <td>0.911326</td>\n      <td>0.907633</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>XGBClassifier-tuned</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.997383</td>\n      <td>0.997387</td>\n      <td>0.997383</td>\n      <td>0.997383</td>\n      <td>0.907490</td>\n      <td>0.902133</td>\n      <td>0.907490</td>\n      <td>0.904715</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>XGBClassifier-tuned</td>\n      <td>SMOTE clean</td>\n      <td>0.999406</td>\n      <td>0.999406</td>\n      <td>0.999406</td>\n      <td>0.999406</td>\n      <td>0.901924</td>\n      <td>0.898574</td>\n      <td>0.901924</td>\n      <td>0.900225</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>XGBClassifier-tuned</td>\n      <td>ADASYN clean</td>\n      <td>0.999166</td>\n      <td>0.999166</td>\n      <td>0.999166</td>\n      <td>0.999166</td>\n      <td>0.898308</td>\n      <td>0.898835</td>\n      <td>0.898308</td>\n      <td>0.898571</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>XGBClassifier-tuned</td>\n      <td>SMOTE base</td>\n      <td>0.998449</td>\n      <td>0.998450</td>\n      <td>0.998449</td>\n      <td>0.998449</td>\n      <td>0.896925</td>\n      <td>0.900538</td>\n      <td>0.896925</td>\n      <td>0.898699</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>XGBClassifier-tuned</td>\n      <td>ADASYN base</td>\n      <td>0.998427</td>\n      <td>0.998427</td>\n      <td>0.998427</td>\n      <td>0.998427</td>\n      <td>0.894352</td>\n      <td>0.897957</td>\n      <td>0.894352</td>\n      <td>0.896125</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>XGBClassifier-tuned</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.493563</td>\n      <td>0.887924</td>\n      <td>0.493563</td>\n      <td>0.609686</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>XGBClassifier-tuned</td>\n      <td>NearMiss base</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.481241</td>\n      <td>0.893071</td>\n      <td>0.481241</td>\n      <td>0.593954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model(xgb_tune, \"XGBClassifier-tuned\")\n",
    "evaluation[evaluation.model == \"XGBClassifier-tuned\"].sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T19:34:25.021554Z",
     "start_time": "2024-11-10T19:33:25.748784300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1 CatBoostClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(iterations=2,\n",
    "                         depth=2,\n",
    "                         learning_rate=1,\n",
    "                         loss_function='Logloss',\n",
    "                         verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:44:47.806771700Z",
     "start_time": "2024-11-10T18:44:47.786773400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  CatBoostClassifier BASE started...\n",
      "0:\tlearn: 0.2482938\ttotal: 158ms\tremaining: 158ms\n",
      "1:\tlearn: 0.2445480\ttotal: 166ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  CatBoostClassifier finished. Elapsed time:  7 Seconds\n",
      "2/12 Fitting:  CatBoostClassifier CLEAN started...\n",
      "0:\tlearn: 0.2422224\ttotal: 9.27ms\tremaining: 9.27ms\n",
      "1:\tlearn: 0.2381026\ttotal: 18.3ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  CatBoostClassifier finished. Elapsed time:  6 Seconds\n",
      "3/12 Fitting:  CatBoostClassifier SMOTE-base started...\n",
      "0:\tlearn: 0.6573267\ttotal: 11.8ms\tremaining: 11.8ms\n",
      "1:\tlearn: 0.6294410\ttotal: 22.5ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  9 Seconds\n",
      "4/12 Fitting:  CatBoostClassifier SMOTE-clean started...\n",
      "0:\tlearn: 0.6523384\ttotal: 9.7ms\tremaining: 9.7ms\n",
      "1:\tlearn: 0.6275114\ttotal: 18.3ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  8 Seconds\n",
      "5/12 Fitting:  CatBoostClassifier BorderlineSMOTE-base started...\n",
      "0:\tlearn: 0.6531919\ttotal: 9.98ms\tremaining: 9.98ms\n",
      "1:\tlearn: 0.6279220\ttotal: 20.3ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  8 Seconds\n",
      "6/12 Fitting:  CatBoostClassifier BorderlineSMOTE-clean started...\n",
      "0:\tlearn: 0.6451640\ttotal: 15.1ms\tremaining: 15.1ms\n",
      "1:\tlearn: 0.6177823\ttotal: 28.4ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  8 Seconds\n",
      "7/12 Fitting:  CatBoostClassifier ADASYN-base started...\n",
      "0:\tlearn: 0.6561711\ttotal: 9.37ms\tremaining: 9.37ms\n",
      "1:\tlearn: 0.6339215\ttotal: 18.4ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  8 Seconds\n",
      "8/12 Fitting:  CatBoostClassifier ADASYN-clean started...\n",
      "0:\tlearn: 0.6544035\ttotal: 8.58ms\tremaining: 8.58ms\n",
      "1:\tlearn: 0.6283163\ttotal: 16.7ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  8 Seconds\n",
      "9/12 Fitting:  CatBoostClassifier NearMiss-base started...\n",
      "0:\tlearn: 0.6785819\ttotal: 4.2ms\tremaining: 4.2ms\n",
      "1:\tlearn: 0.6663802\ttotal: 8.04ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  2 Seconds\n",
      "10/12 Fitting:  CatBoostClassifier NearMiss-clean started...\n",
      "0:\tlearn: 0.6828736\ttotal: 9.7ms\tremaining: 9.7ms\n",
      "1:\tlearn: 0.6701762\ttotal: 52.9ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  2 Seconds\n",
      "11/12 Fitting:  CatBoostClassifier TomekLink-base started...\n",
      "0:\tlearn: 0.2426231\ttotal: 10.5ms\tremaining: 10.5ms\n",
      "1:\tlearn: 0.2389774\ttotal: 25.7ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  CatBoostClassifier finished. Elapsed time:  5 Seconds\n",
      "12/12 Fitting:  CatBoostClassifier TomekLink-clean started...\n",
      "0:\tlearn: 0.2426231\ttotal: 7.63ms\tremaining: 7.63ms\n",
      "1:\tlearn: 0.2389774\ttotal: 15.1ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  CatBoostClassifier finished. Elapsed time:  4 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(cat, \"CatBoostClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:03.452287200Z",
     "start_time": "2024-11-10T18:44:47.801773500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                 model                variant  train_acc  train_prec  \\\n27  CatBoostClassifier                  clean   0.934224    0.872774   \n36  CatBoostClassifier        TomekLink clean   0.934074    0.872495   \n37  CatBoostClassifier        TomekLink clean   0.934074    0.872495   \n26  CatBoostClassifier                   base   0.931864    0.868371   \n30  CatBoostClassifier   BorderlineSMOTE base   0.661498    0.663853   \n31  CatBoostClassifier  BorderlineSMOTE clean   0.669488    0.670451   \n29  CatBoostClassifier            SMOTE clean   0.659604    0.659836   \n32  CatBoostClassifier            ADASYN base   0.657688    0.657701   \n35  CatBoostClassifier         NearMiss clean   0.587610    0.605143   \n28  CatBoostClassifier             SMOTE base   0.662443    0.663300   \n34  CatBoostClassifier          NearMiss base   0.601723    0.606703   \n33  CatBoostClassifier           ADASYN clean   0.662923    0.669586   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n27   0.934224  0.902454  0.935339   0.874859  0.935339  0.904089  \n36   0.934074  0.902235  0.935339   0.874859  0.935339  0.904089  \n37   0.934074  0.902235  0.935339   0.874859  0.935339  0.904089  \n26   0.931864  0.898998  0.931735   0.868130  0.931735  0.898809  \n30   0.661498  0.660278  0.693485   0.884205  0.693485  0.767804  \n31   0.669488  0.669021  0.684363   0.890649  0.684363  0.763719  \n29   0.659604  0.659480  0.656878   0.891162  0.656878  0.743972  \n32   0.657688  0.657684  0.645537   0.888848  0.645537  0.733368  \n35   0.587610  0.569670  0.639230   0.878632  0.639230  0.730830  \n28   0.662443  0.662000  0.614791   0.890127  0.614791  0.709803  \n34   0.601723  0.597021  0.572125   0.876333  0.572125  0.676406  \n33   0.662923  0.660201  0.568494   0.899303  0.568494  0.674314  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.934224</td>\n      <td>0.872774</td>\n      <td>0.934224</td>\n      <td>0.902454</td>\n      <td>0.935339</td>\n      <td>0.874859</td>\n      <td>0.935339</td>\n      <td>0.904089</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.934074</td>\n      <td>0.872495</td>\n      <td>0.934074</td>\n      <td>0.902235</td>\n      <td>0.935339</td>\n      <td>0.874859</td>\n      <td>0.935339</td>\n      <td>0.904089</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.934074</td>\n      <td>0.872495</td>\n      <td>0.934074</td>\n      <td>0.902235</td>\n      <td>0.935339</td>\n      <td>0.874859</td>\n      <td>0.935339</td>\n      <td>0.904089</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.931864</td>\n      <td>0.868371</td>\n      <td>0.931864</td>\n      <td>0.898998</td>\n      <td>0.931735</td>\n      <td>0.868130</td>\n      <td>0.931735</td>\n      <td>0.898809</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.661498</td>\n      <td>0.663853</td>\n      <td>0.661498</td>\n      <td>0.660278</td>\n      <td>0.693485</td>\n      <td>0.884205</td>\n      <td>0.693485</td>\n      <td>0.767804</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.669488</td>\n      <td>0.670451</td>\n      <td>0.669488</td>\n      <td>0.669021</td>\n      <td>0.684363</td>\n      <td>0.890649</td>\n      <td>0.684363</td>\n      <td>0.763719</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.659604</td>\n      <td>0.659836</td>\n      <td>0.659604</td>\n      <td>0.659480</td>\n      <td>0.656878</td>\n      <td>0.891162</td>\n      <td>0.656878</td>\n      <td>0.743972</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.657688</td>\n      <td>0.657701</td>\n      <td>0.657688</td>\n      <td>0.657684</td>\n      <td>0.645537</td>\n      <td>0.888848</td>\n      <td>0.645537</td>\n      <td>0.733368</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.587610</td>\n      <td>0.605143</td>\n      <td>0.587610</td>\n      <td>0.569670</td>\n      <td>0.639230</td>\n      <td>0.878632</td>\n      <td>0.639230</td>\n      <td>0.730830</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.662443</td>\n      <td>0.663300</td>\n      <td>0.662443</td>\n      <td>0.662000</td>\n      <td>0.614791</td>\n      <td>0.890127</td>\n      <td>0.614791</td>\n      <td>0.709803</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.601723</td>\n      <td>0.606703</td>\n      <td>0.601723</td>\n      <td>0.597021</td>\n      <td>0.572125</td>\n      <td>0.876333</td>\n      <td>0.572125</td>\n      <td>0.676406</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.662923</td>\n      <td>0.669586</td>\n      <td>0.662923</td>\n      <td>0.660201</td>\n      <td>0.568494</td>\n      <td>0.899303</td>\n      <td>0.568494</td>\n      <td>0.674314</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"CatBoostClassifier\"].sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:03.520285400Z",
     "start_time": "2024-11-10T18:46:03.456284900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1 LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "light = LGBMClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:03.524285500Z",
     "start_time": "2024-11-10T18:46:03.488284600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LGBMClassifier BASE started...\n",
      "[LightGBM] [Info] Number of positive: 1509, number of negative: 20638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 22147, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.068136 -> initscore=-2.615687\n",
      "[LightGBM] [Info] Start training from score -2.615687\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "2/12 Fitting:  LGBMClassifier CLEAN started...\n",
      "[LightGBM] [Info] Number of positive: 1364, number of negative: 19373\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 20737, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065776 -> initscore=-2.653459\n",
      "[LightGBM] [Info] Start training from score -2.653459\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  5 Seconds\n",
      "3/12 Fitting:  LGBMClassifier SMOTE-base started...\n",
      "[LightGBM] [Info] Number of positive: 20638, number of negative: 20638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 41276, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  4 Seconds\n",
      "4/12 Fitting:  LGBMClassifier SMOTE-clean started...\n",
      "[LightGBM] [Info] Number of positive: 19373, number of negative: 19373\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 38746, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  2 Seconds\n",
      "5/12 Fitting:  LGBMClassifier BorderlineSMOTE-base started...\n",
      "[LightGBM] [Info] Number of positive: 20638, number of negative: 20638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 41276, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "6/12 Fitting:  LGBMClassifier BorderlineSMOTE-clean started...\n",
      "[LightGBM] [Info] Number of positive: 19373, number of negative: 19373\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 38746, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  LGBMClassifier ADASYN-base started...\n",
      "[LightGBM] [Info] Number of positive: 20681, number of negative: 20638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 41319, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500520 -> initscore=0.002081\n",
      "[LightGBM] [Info] Start training from score 0.002081\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "8/12 Fitting:  LGBMClassifier ADASYN-clean started...\n",
      "[LightGBM] [Info] Number of positive: 18998, number of negative: 19373\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 38371, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495113 -> initscore=-0.019547\n",
      "[LightGBM] [Info] Start training from score -0.019547\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "9/12 Fitting:  LGBMClassifier NearMiss-base started...\n",
      "[LightGBM] [Info] Number of positive: 1509, number of negative: 1509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 3018, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LGBMClassifier NearMiss-clean started...\n",
      "[LightGBM] [Info] Number of positive: 1364, number of negative: 1364\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 2728, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LGBMClassifier TomekLink-base started...\n",
      "[LightGBM] [Info] Number of positive: 1364, number of negative: 19326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 20690, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065926 -> initscore=-2.651030\n",
      "[LightGBM] [Info] Start training from score -2.651030\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "12/12 Fitting:  LGBMClassifier TomekLink-clean started...\n",
      "[LightGBM] [Info] Number of positive: 1364, number of negative: 19326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 20690, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065926 -> initscore=-2.651030\n",
      "[LightGBM] [Info] Start training from score -2.651030\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(light, \"LGBMClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:23.462979400Z",
     "start_time": "2024-11-10T18:46:03.504287100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "             model                variant  train_acc  train_prec  train_rec  \\\n48  LGBMClassifier        TomekLink clean   0.965926    0.967125   0.965926   \n49  LGBMClassifier        TomekLink clean   0.965926    0.967125   0.965926   \n39  LGBMClassifier                  clean   0.966485    0.967646   0.966485   \n38  LGBMClassifier                   base   0.962568    0.964014   0.962568   \n43  LGBMClassifier  BorderlineSMOTE clean   0.948072    0.948609   0.948072   \n42  LGBMClassifier   BorderlineSMOTE base   0.941806    0.942448   0.941806   \n41  LGBMClassifier            SMOTE clean   0.931967    0.932416   0.931967   \n45  LGBMClassifier           ADASYN clean   0.932214    0.932896   0.932214   \n40  LGBMClassifier             SMOTE base   0.928893    0.929438   0.928893   \n44  LGBMClassifier            ADASYN base   0.929669    0.930422   0.929669   \n47  LGBMClassifier         NearMiss clean   0.999633    0.999634   0.999633   \n46  LGBMClassifier          NearMiss base   0.998675    0.998675   0.998675   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n48  0.960293  0.936062   0.922873  0.936062  0.906672  \n49  0.960293  0.936062   0.922873  0.936062  0.906672  \n39  0.961052  0.935773   0.916859  0.935773  0.906250  \n38  0.955849  0.933496   0.922201  0.933496  0.904505  \n43  0.948057  0.857949   0.900116  0.857949  0.876850  \n42  0.941785  0.848977   0.898356  0.848977  0.870578  \n41  0.931950  0.841603   0.902923  0.841603  0.868058  \n45  0.932202  0.835817   0.900703  0.835817  0.863911  \n40  0.928871  0.834078   0.898682  0.834078  0.861683  \n44  0.929637  0.829744   0.897243  0.829744  0.858625  \n47  0.999633  0.484305   0.887628  0.484305  0.601085  \n46  0.998675  0.459569   0.891732  0.459569  0.573111  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.965926</td>\n      <td>0.967125</td>\n      <td>0.965926</td>\n      <td>0.960293</td>\n      <td>0.936062</td>\n      <td>0.922873</td>\n      <td>0.936062</td>\n      <td>0.906672</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.965926</td>\n      <td>0.967125</td>\n      <td>0.965926</td>\n      <td>0.960293</td>\n      <td>0.936062</td>\n      <td>0.922873</td>\n      <td>0.936062</td>\n      <td>0.906672</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.966485</td>\n      <td>0.967646</td>\n      <td>0.966485</td>\n      <td>0.961052</td>\n      <td>0.935773</td>\n      <td>0.916859</td>\n      <td>0.935773</td>\n      <td>0.906250</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.962568</td>\n      <td>0.964014</td>\n      <td>0.962568</td>\n      <td>0.955849</td>\n      <td>0.933496</td>\n      <td>0.922201</td>\n      <td>0.933496</td>\n      <td>0.904505</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.948072</td>\n      <td>0.948609</td>\n      <td>0.948072</td>\n      <td>0.948057</td>\n      <td>0.857949</td>\n      <td>0.900116</td>\n      <td>0.857949</td>\n      <td>0.876850</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.941806</td>\n      <td>0.942448</td>\n      <td>0.941806</td>\n      <td>0.941785</td>\n      <td>0.848977</td>\n      <td>0.898356</td>\n      <td>0.848977</td>\n      <td>0.870578</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.931967</td>\n      <td>0.932416</td>\n      <td>0.931967</td>\n      <td>0.931950</td>\n      <td>0.841603</td>\n      <td>0.902923</td>\n      <td>0.841603</td>\n      <td>0.868058</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.932214</td>\n      <td>0.932896</td>\n      <td>0.932214</td>\n      <td>0.932202</td>\n      <td>0.835817</td>\n      <td>0.900703</td>\n      <td>0.835817</td>\n      <td>0.863911</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.928893</td>\n      <td>0.929438</td>\n      <td>0.928893</td>\n      <td>0.928871</td>\n      <td>0.834078</td>\n      <td>0.898682</td>\n      <td>0.834078</td>\n      <td>0.861683</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.929669</td>\n      <td>0.930422</td>\n      <td>0.929669</td>\n      <td>0.929637</td>\n      <td>0.829744</td>\n      <td>0.897243</td>\n      <td>0.829744</td>\n      <td>0.858625</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.484305</td>\n      <td>0.887628</td>\n      <td>0.484305</td>\n      <td>0.601085</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.998675</td>\n      <td>0.998675</td>\n      <td>0.998675</td>\n      <td>0.998675</td>\n      <td>0.459569</td>\n      <td>0.891732</td>\n      <td>0.459569</td>\n      <td>0.573111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LGBMClassifier\"].sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:23.514976Z",
     "start_time": "2024-11-10T18:46:23.465977300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Stacking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42))\n",
    "]\n",
    "stack = StackingClassifier(estimators=base_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:23.514976Z",
     "start_time": "2024-11-10T18:46:23.497976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# stack.fit(X_train_base, y_train_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:23.532975900Z",
     "start_time": "2024-11-10T18:46:23.512976Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model comparision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n25         XGBClassifier        TomekLink clean   0.999420    0.999420   \n24         XGBClassifier        TomekLink clean   0.999420    0.999420   \n48        LGBMClassifier        TomekLink clean   0.965926    0.967125   \n49        LGBMClassifier        TomekLink clean   0.965926    0.967125   \n1           RandomForest                  clean   0.999711    0.999711   \n39        LGBMClassifier                  clean   0.966485    0.967646   \n10          RandomForest        TomekLink clean   0.999710    0.999710   \n11          RandomForest        TomekLink clean   0.999710    0.999710   \n15         XGBClassifier                  clean   0.999566    0.999566   \n14         XGBClassifier                   base   0.999142    0.999142   \n27    CatBoostClassifier                  clean   0.934224    0.872774   \n37    CatBoostClassifier        TomekLink clean   0.934074    0.872495   \n36    CatBoostClassifier        TomekLink clean   0.934074    0.872495   \n38        LGBMClassifier                   base   0.962568    0.964014   \n0           RandomForest                   base   0.999729    0.999729   \n26    CatBoostClassifier                   base   0.931864    0.868371   \n5           RandomForest  BorderlineSMOTE clean   0.999871    0.999871   \n4           RandomForest   BorderlineSMOTE base   0.999176    0.999178   \n3           RandomForest            SMOTE clean   0.999794    0.999794   \n7           RandomForest           ADASYN clean   0.999739    0.999739   \n2           RandomForest             SMOTE base   0.999443    0.999443   \n6           RandomForest            ADASYN base   0.999443    0.999444   \n19         XGBClassifier  BorderlineSMOTE clean   0.997651    0.997651   \n18         XGBClassifier   BorderlineSMOTE base   0.994549    0.994550   \n21         XGBClassifier           ADASYN clean   0.996534    0.996551   \n16         XGBClassifier             SMOTE base   0.994743    0.994770   \n17         XGBClassifier            SMOTE clean   0.996980    0.996992   \n20         XGBClassifier            ADASYN base   0.995789    0.995808   \n43        LGBMClassifier  BorderlineSMOTE clean   0.948072    0.948609   \n42        LGBMClassifier   BorderlineSMOTE base   0.941806    0.942448   \n41        LGBMClassifier            SMOTE clean   0.931967    0.932416   \n45        LGBMClassifier           ADASYN clean   0.932214    0.932896   \n40        LGBMClassifier             SMOTE base   0.928893    0.929438   \n44        LGBMClassifier            ADASYN base   0.929669    0.930422   \n12  BalancedRandomForest          BALANCED base   0.799296    0.949070   \n30    CatBoostClassifier   BorderlineSMOTE base   0.661498    0.663853   \n31    CatBoostClassifier  BorderlineSMOTE clean   0.669488    0.670451   \n13  BalancedRandomForest         BALANCED clean   0.771712    0.948730   \n29    CatBoostClassifier            SMOTE clean   0.659604    0.659836   \n32    CatBoostClassifier            ADASYN base   0.657688    0.657701   \n35    CatBoostClassifier         NearMiss clean   0.587610    0.605143   \n28    CatBoostClassifier             SMOTE base   0.662443    0.663300   \n34    CatBoostClassifier          NearMiss base   0.601723    0.606703   \n33    CatBoostClassifier           ADASYN clean   0.662923    0.669586   \n23         XGBClassifier         NearMiss clean   0.999633    0.999634   \n22         XGBClassifier          NearMiss base   0.999337    0.999338   \n47        LGBMClassifier         NearMiss clean   0.999633    0.999634   \n46        LGBMClassifier          NearMiss base   0.998675    0.998675   \n8           RandomForest          NearMiss base   0.999337    0.999338   \n9           RandomForest         NearMiss clean   0.999633    0.999634   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n25   0.999420  0.999419  0.936352   0.916800  0.936352  0.909647  \n24   0.999420  0.999419  0.936352   0.916800  0.936352  0.909647  \n48   0.965926  0.960293  0.936062   0.922873  0.936062  0.906672  \n49   0.965926  0.960293  0.936062   0.922873  0.936062  0.906672  \n1    0.999711  0.999710  0.935918   0.924098  0.935918  0.906055  \n39   0.966485  0.961052  0.935773   0.916859  0.935773  0.906250  \n10   0.999710  0.999710  0.935773   0.921662  0.935773  0.905707  \n11   0.999710  0.999710  0.935773   0.918701  0.935773  0.905979  \n15   0.999566  0.999565  0.935773   0.912286  0.935773  0.909072  \n14   0.999142  0.999140  0.935663   0.931619  0.935663  0.909167  \n27   0.934224  0.902454  0.935339   0.874859  0.935339  0.904089  \n37   0.934074  0.902235  0.935339   0.874859  0.935339  0.904089  \n36   0.934074  0.902235  0.935339   0.874859  0.935339  0.904089  \n38   0.962568  0.955849  0.933496   0.922201  0.933496  0.904505  \n0    0.999729  0.999729  0.933496   0.937926  0.933496  0.903062  \n26   0.931864  0.898998  0.931735   0.868130  0.931735  0.898809  \n5    0.999871  0.999871  0.922176   0.896158  0.922176  0.906817  \n4    0.999176  0.999176  0.918326   0.895816  0.918326  0.904959  \n3    0.999794  0.999794  0.917981   0.896207  0.917981  0.905666  \n7    0.999739  0.999739  0.913786   0.893155  0.913786  0.902476  \n2    0.999443  0.999443  0.911147   0.893146  0.911147  0.901177  \n6    0.999443  0.999443  0.909251   0.895514  0.909251  0.901808  \n19   0.997651  0.997651  0.905396   0.904404  0.905396  0.904897  \n18   0.994549  0.994549  0.896113   0.901739  0.896113  0.898845  \n21   0.996534  0.996534  0.890352   0.899949  0.890352  0.894982  \n16   0.994743  0.994743  0.887986   0.901167  0.887986  0.894202  \n17   0.996980  0.996980  0.887892   0.900993  0.887892  0.894133  \n20   0.995789  0.995789  0.887850   0.900422  0.887850  0.893800  \n43   0.948072  0.948057  0.857949   0.900116  0.857949  0.876850  \n42   0.941806  0.941785  0.848977   0.898356  0.848977  0.870578  \n41   0.931967  0.931950  0.841603   0.902923  0.841603  0.868058  \n45   0.932214  0.932202  0.835817   0.900703  0.835817  0.863911  \n40   0.928893  0.928871  0.834078   0.898682  0.834078  0.861683  \n44   0.929669  0.929637  0.829744   0.897243  0.829744  0.858625  \n12   0.799296  0.846950  0.711635   0.905412  0.711635  0.782027  \n30   0.661498  0.660278  0.693485   0.884205  0.693485  0.767804  \n31   0.669488  0.669021  0.684363   0.890649  0.684363  0.763719  \n13   0.771761  0.828229  0.667872   0.907749  0.667872  0.752252  \n29   0.659604  0.659480  0.656878   0.891162  0.656878  0.743972  \n32   0.657688  0.657684  0.645537   0.888848  0.645537  0.733368  \n35   0.587610  0.569670  0.639230   0.878632  0.639230  0.730830  \n28   0.662443  0.662000  0.614791   0.890127  0.614791  0.709803  \n34   0.601723  0.597021  0.572125   0.876333  0.572125  0.676406  \n33   0.662923  0.660201  0.568494   0.899303  0.568494  0.674314  \n23   0.999633  0.999633  0.505569   0.888524  0.505569  0.620631  \n22   0.999337  0.999337  0.489503   0.887529  0.489503  0.602656  \n47   0.999633  0.999633  0.484305   0.887628  0.484305  0.601085  \n46   0.998675  0.998675  0.459569   0.891732  0.459569  0.573111  \n8    0.999337  0.999337  0.425437   0.885160  0.425437  0.539718  \n9    0.999633  0.999633  0.423261   0.882394  0.423261  0.541775  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999419</td>\n      <td>0.936352</td>\n      <td>0.916800</td>\n      <td>0.936352</td>\n      <td>0.909647</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999420</td>\n      <td>0.999419</td>\n      <td>0.936352</td>\n      <td>0.916800</td>\n      <td>0.936352</td>\n      <td>0.909647</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.965926</td>\n      <td>0.967125</td>\n      <td>0.965926</td>\n      <td>0.960293</td>\n      <td>0.936062</td>\n      <td>0.922873</td>\n      <td>0.936062</td>\n      <td>0.906672</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.965926</td>\n      <td>0.967125</td>\n      <td>0.965926</td>\n      <td>0.960293</td>\n      <td>0.936062</td>\n      <td>0.922873</td>\n      <td>0.936062</td>\n      <td>0.906672</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>0.999710</td>\n      <td>0.935918</td>\n      <td>0.924098</td>\n      <td>0.935918</td>\n      <td>0.906055</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.966485</td>\n      <td>0.967646</td>\n      <td>0.966485</td>\n      <td>0.961052</td>\n      <td>0.935773</td>\n      <td>0.916859</td>\n      <td>0.935773</td>\n      <td>0.906250</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.935773</td>\n      <td>0.921662</td>\n      <td>0.935773</td>\n      <td>0.905707</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.999710</td>\n      <td>0.935773</td>\n      <td>0.918701</td>\n      <td>0.935773</td>\n      <td>0.905979</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.999566</td>\n      <td>0.999566</td>\n      <td>0.999566</td>\n      <td>0.999565</td>\n      <td>0.935773</td>\n      <td>0.912286</td>\n      <td>0.935773</td>\n      <td>0.909072</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.999142</td>\n      <td>0.999142</td>\n      <td>0.999142</td>\n      <td>0.999140</td>\n      <td>0.935663</td>\n      <td>0.931619</td>\n      <td>0.935663</td>\n      <td>0.909167</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.934224</td>\n      <td>0.872774</td>\n      <td>0.934224</td>\n      <td>0.902454</td>\n      <td>0.935339</td>\n      <td>0.874859</td>\n      <td>0.935339</td>\n      <td>0.904089</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.934074</td>\n      <td>0.872495</td>\n      <td>0.934074</td>\n      <td>0.902235</td>\n      <td>0.935339</td>\n      <td>0.874859</td>\n      <td>0.935339</td>\n      <td>0.904089</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.934074</td>\n      <td>0.872495</td>\n      <td>0.934074</td>\n      <td>0.902235</td>\n      <td>0.935339</td>\n      <td>0.874859</td>\n      <td>0.935339</td>\n      <td>0.904089</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.962568</td>\n      <td>0.964014</td>\n      <td>0.962568</td>\n      <td>0.955849</td>\n      <td>0.933496</td>\n      <td>0.922201</td>\n      <td>0.933496</td>\n      <td>0.904505</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.933496</td>\n      <td>0.937926</td>\n      <td>0.933496</td>\n      <td>0.903062</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.931864</td>\n      <td>0.868371</td>\n      <td>0.931864</td>\n      <td>0.898998</td>\n      <td>0.931735</td>\n      <td>0.868130</td>\n      <td>0.931735</td>\n      <td>0.898809</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.999871</td>\n      <td>0.999871</td>\n      <td>0.999871</td>\n      <td>0.999871</td>\n      <td>0.922176</td>\n      <td>0.896158</td>\n      <td>0.922176</td>\n      <td>0.906817</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999176</td>\n      <td>0.999178</td>\n      <td>0.999176</td>\n      <td>0.999176</td>\n      <td>0.918326</td>\n      <td>0.895816</td>\n      <td>0.918326</td>\n      <td>0.904959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>0.999794</td>\n      <td>0.999794</td>\n      <td>0.999794</td>\n      <td>0.999794</td>\n      <td>0.917981</td>\n      <td>0.896207</td>\n      <td>0.917981</td>\n      <td>0.905666</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>0.999739</td>\n      <td>0.999739</td>\n      <td>0.999739</td>\n      <td>0.999739</td>\n      <td>0.913786</td>\n      <td>0.893155</td>\n      <td>0.913786</td>\n      <td>0.902476</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.911147</td>\n      <td>0.893146</td>\n      <td>0.911147</td>\n      <td>0.901177</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999443</td>\n      <td>0.999444</td>\n      <td>0.999443</td>\n      <td>0.999443</td>\n      <td>0.909251</td>\n      <td>0.895514</td>\n      <td>0.909251</td>\n      <td>0.901808</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997651</td>\n      <td>0.997651</td>\n      <td>0.997651</td>\n      <td>0.997651</td>\n      <td>0.905396</td>\n      <td>0.904404</td>\n      <td>0.905396</td>\n      <td>0.904897</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.994549</td>\n      <td>0.994550</td>\n      <td>0.994549</td>\n      <td>0.994549</td>\n      <td>0.896113</td>\n      <td>0.901739</td>\n      <td>0.896113</td>\n      <td>0.898845</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.996534</td>\n      <td>0.996551</td>\n      <td>0.996534</td>\n      <td>0.996534</td>\n      <td>0.890352</td>\n      <td>0.899949</td>\n      <td>0.890352</td>\n      <td>0.894982</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.994743</td>\n      <td>0.994770</td>\n      <td>0.994743</td>\n      <td>0.994743</td>\n      <td>0.887986</td>\n      <td>0.901167</td>\n      <td>0.887986</td>\n      <td>0.894202</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.996980</td>\n      <td>0.996992</td>\n      <td>0.996980</td>\n      <td>0.996980</td>\n      <td>0.887892</td>\n      <td>0.900993</td>\n      <td>0.887892</td>\n      <td>0.894133</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.995789</td>\n      <td>0.995808</td>\n      <td>0.995789</td>\n      <td>0.995789</td>\n      <td>0.887850</td>\n      <td>0.900422</td>\n      <td>0.887850</td>\n      <td>0.893800</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.948072</td>\n      <td>0.948609</td>\n      <td>0.948072</td>\n      <td>0.948057</td>\n      <td>0.857949</td>\n      <td>0.900116</td>\n      <td>0.857949</td>\n      <td>0.876850</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.941806</td>\n      <td>0.942448</td>\n      <td>0.941806</td>\n      <td>0.941785</td>\n      <td>0.848977</td>\n      <td>0.898356</td>\n      <td>0.848977</td>\n      <td>0.870578</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.931967</td>\n      <td>0.932416</td>\n      <td>0.931967</td>\n      <td>0.931950</td>\n      <td>0.841603</td>\n      <td>0.902923</td>\n      <td>0.841603</td>\n      <td>0.868058</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.932214</td>\n      <td>0.932896</td>\n      <td>0.932214</td>\n      <td>0.932202</td>\n      <td>0.835817</td>\n      <td>0.900703</td>\n      <td>0.835817</td>\n      <td>0.863911</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.928893</td>\n      <td>0.929438</td>\n      <td>0.928893</td>\n      <td>0.928871</td>\n      <td>0.834078</td>\n      <td>0.898682</td>\n      <td>0.834078</td>\n      <td>0.861683</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.929669</td>\n      <td>0.930422</td>\n      <td>0.929669</td>\n      <td>0.929637</td>\n      <td>0.829744</td>\n      <td>0.897243</td>\n      <td>0.829744</td>\n      <td>0.858625</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.799296</td>\n      <td>0.949070</td>\n      <td>0.799296</td>\n      <td>0.846950</td>\n      <td>0.711635</td>\n      <td>0.905412</td>\n      <td>0.711635</td>\n      <td>0.782027</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.661498</td>\n      <td>0.663853</td>\n      <td>0.661498</td>\n      <td>0.660278</td>\n      <td>0.693485</td>\n      <td>0.884205</td>\n      <td>0.693485</td>\n      <td>0.767804</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.669488</td>\n      <td>0.670451</td>\n      <td>0.669488</td>\n      <td>0.669021</td>\n      <td>0.684363</td>\n      <td>0.890649</td>\n      <td>0.684363</td>\n      <td>0.763719</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.771712</td>\n      <td>0.948730</td>\n      <td>0.771761</td>\n      <td>0.828229</td>\n      <td>0.667872</td>\n      <td>0.907749</td>\n      <td>0.667872</td>\n      <td>0.752252</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.659604</td>\n      <td>0.659836</td>\n      <td>0.659604</td>\n      <td>0.659480</td>\n      <td>0.656878</td>\n      <td>0.891162</td>\n      <td>0.656878</td>\n      <td>0.743972</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.657688</td>\n      <td>0.657701</td>\n      <td>0.657688</td>\n      <td>0.657684</td>\n      <td>0.645537</td>\n      <td>0.888848</td>\n      <td>0.645537</td>\n      <td>0.733368</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.587610</td>\n      <td>0.605143</td>\n      <td>0.587610</td>\n      <td>0.569670</td>\n      <td>0.639230</td>\n      <td>0.878632</td>\n      <td>0.639230</td>\n      <td>0.730830</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.662443</td>\n      <td>0.663300</td>\n      <td>0.662443</td>\n      <td>0.662000</td>\n      <td>0.614791</td>\n      <td>0.890127</td>\n      <td>0.614791</td>\n      <td>0.709803</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.601723</td>\n      <td>0.606703</td>\n      <td>0.601723</td>\n      <td>0.597021</td>\n      <td>0.572125</td>\n      <td>0.876333</td>\n      <td>0.572125</td>\n      <td>0.676406</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.662923</td>\n      <td>0.669586</td>\n      <td>0.662923</td>\n      <td>0.660201</td>\n      <td>0.568494</td>\n      <td>0.899303</td>\n      <td>0.568494</td>\n      <td>0.674314</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.505569</td>\n      <td>0.888524</td>\n      <td>0.505569</td>\n      <td>0.620631</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.999337</td>\n      <td>0.999338</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.489503</td>\n      <td>0.887529</td>\n      <td>0.489503</td>\n      <td>0.602656</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.484305</td>\n      <td>0.887628</td>\n      <td>0.484305</td>\n      <td>0.601085</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.998675</td>\n      <td>0.998675</td>\n      <td>0.998675</td>\n      <td>0.998675</td>\n      <td>0.459569</td>\n      <td>0.891732</td>\n      <td>0.459569</td>\n      <td>0.573111</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.999337</td>\n      <td>0.999338</td>\n      <td>0.999337</td>\n      <td>0.999337</td>\n      <td>0.425437</td>\n      <td>0.885160</td>\n      <td>0.425437</td>\n      <td>0.539718</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>0.999633</td>\n      <td>0.999634</td>\n      <td>0.999633</td>\n      <td>0.999633</td>\n      <td>0.423261</td>\n      <td>0.882394</td>\n      <td>0.423261</td>\n      <td>0.541775</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:23.661977600Z",
     "start_time": "2024-11-10T18:46:23.527976400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T18:46:23.662976600Z",
     "start_time": "2024-11-10T18:46:23.576976900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
