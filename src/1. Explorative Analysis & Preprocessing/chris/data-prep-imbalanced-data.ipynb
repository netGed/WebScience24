{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports & Downloads"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NearMiss, CondensedNearestNeighbour, NeighbourhoodCleaningRule\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:51.584403800Z",
     "start_time": "2024-11-14T16:25:50.928131Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Einladen der Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Originaldaten ohne umfassende Vorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet\nid                                                          \n1       0   @user when a father is dysfunctional and is s...\n2       0  @user @user thanks for #lyft credit i can't us...\n3       0                                bihday your majesty\n4       0  #model   i love u take with u all the time in ...\n5       0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_basic_cleaned.csv'))\n",
    "df = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.089390Z",
     "start_time": "2024-11-14T16:25:50.968536800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 2013\n",
      "Negative: 27517\n",
      "Verhältnis: 13.669647292598112\n"
     ]
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "positive = len(df[df['label'] == 1])\n",
    "negative = len(df[df['label'] == 0])\n",
    "print(\"Positive:\", positive)\n",
    "print(\"Negative:\", negative)\n",
    "print(\"Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.232545100Z",
     "start_time": "2024-11-14T16:25:51.021087500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorverarbeitete Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet  \\\nid                                                             \n1       0   @user when a father is dysfunctional and is s...   \n2       0  @user @user thanks for #lyft credit i can't us...   \n3       0                                bihday your majesty   \n4       0  #model   i love u take with u all the time in ...   \n5       0             factsguide: society now    #motivation   \n\n                                        tweet_cleaned  user_handle  \\\nid                                                                   \n1                         father selfish drag kid run            1   \n2               thank lyft credit use cause offer van            2   \n3                                      bihday majesty            0   \n4   model take time mobile phone kiss sunglass mou...            0   \n5                       factsguide society motivation            0   \n\n                                    hashtags  \\\nid                                             \n1                                   ['#run']   \n2   ['#lyft', '#disapointed', '#getthanked']   \n3                                         []   \n4                                 ['#model']   \n5                            ['#motivation']   \n\n                                               emojis  \nid                                                     \n1                                                 NaN  \n2                                                 NaN  \n3                                                 NaN  \n4   :mobile_phone:,:kissing_face_with_smiling_eyes...  \n5                                                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_cleaned</th>\n      <th>user_handle</th>\n      <th>hashtags</th>\n      <th>emojis</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n      <td>father selfish drag kid run</td>\n      <td>1</td>\n      <td>['#run']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n      <td>thank lyft credit use cause offer van</td>\n      <td>2</td>\n      <td>['#lyft', '#disapointed', '#getthanked']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n      <td>bihday majesty</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n      <td>model take time mobile phone kiss sunglass mou...</td>\n      <td>0</td>\n      <td>['#model']</td>\n      <td>:mobile_phone:,:kissing_face_with_smiling_eyes...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n      <td>factsguide society motivation</td>\n      <td>0</td>\n      <td>['#motivation']</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df_cleaned.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.494961100Z",
     "start_time": "2024-11-14T16:25:51.041340500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_cleaned.dropna(inplace=True)  #irgendwoher kommt eine na row in tweet_cleaned, dadurch funktioniert der Vectorizer nicht"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.565640200Z",
     "start_time": "2024-11-14T16:25:51.162400900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 92\n",
      "Negative: 5819\n",
      "Verhältnis: 63.25\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['label'].value_counts()\n",
    "positive = len(df_cleaned[df_cleaned['label'] == 1])\n",
    "negative = len(df_cleaned[df_cleaned['label'] == 0])\n",
    "print(\"Positive:\", positive)\n",
    "print(\"Negative:\", negative)\n",
    "print(\"Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.626285800Z",
     "start_time": "2024-11-14T16:25:51.202740300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verhältnis hat sich durch die Bereinigung sogar noch weiter verschlechter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def print_pos_neg(y_train, y_test):\n",
    "    positive = np.count_nonzero(y_train == 1)\n",
    "    negative = np.count_nonzero(y_train == 0)\n",
    "    print(\"Train\")\n",
    "    print(\"- Positive:\", positive)\n",
    "    print(\"- Negative:\", negative)\n",
    "    print(\"- Verhältnis:\", negative / positive)\n",
    "\n",
    "    positive = np.count_nonzero(y_test == 1)\n",
    "    negative = np.count_nonzero(y_test == 0)\n",
    "    print(\"Test\")\n",
    "    print(\"- Positive:\", positive)\n",
    "    print(\"- Negative:\", negative)\n",
    "    print(\"- Verhältnis:\", negative / positive)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.696931500Z",
     "start_time": "2024-11-14T16:25:51.222922900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_base = df[\"tweet\"]\n",
    "y_base = df[\"label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.696931500Z",
     "start_time": "2024-11-14T16:25:51.243093900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 1401\n",
      "- Negative: 19270\n",
      "- Verhältnis: 13.754461099214847\n",
      "Test\n",
      "- Positive: 612\n",
      "- Negative: 8247\n",
      "- Verhältnis: 13.47549019607843\n"
     ]
    }
   ],
   "source": [
    "# Ohne stratify\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.3, random_state=42)\n",
    "print_pos_neg(y_train_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.777613Z",
     "start_time": "2024-11-14T16:25:51.263285400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 1409\n",
      "- Negative: 19262\n",
      "- Verhältnis: 13.67068843151171\n",
      "Test\n",
      "- Positive: 604\n",
      "- Negative: 8255\n",
      "- Verhältnis: 13.667218543046358\n"
     ]
    }
   ],
   "source": [
    "# mit stratify\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.3, stratify=y_base,\n",
    "                                                                        random_state=42)\n",
    "print_pos_neg(y_train_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:52.868311800Z",
     "start_time": "2024-11-14T16:25:51.283430300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "X_clean = df_cleaned[\"tweet_cleaned\"]\n",
    "y_clean = df_cleaned[\"label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.009639400Z",
     "start_time": "2024-11-14T16:25:51.303617500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 66\n",
      "- Negative: 4071\n",
      "- Verhältnis: 61.68181818181818\n",
      "Test\n",
      "- Positive: 26\n",
      "- Negative: 1748\n",
      "- Verhältnis: 67.23076923076923\n"
     ]
    }
   ],
   "source": [
    "# Ohne stratify\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.3,\n",
    "                                                                            random_state=42)\n",
    "print_pos_neg(y_train_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.009639400Z",
     "start_time": "2024-11-14T16:25:51.323764200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "- Positive: 64\n",
      "- Negative: 4073\n",
      "- Verhältnis: 63.640625\n",
      "Test\n",
      "- Positive: 28\n",
      "- Negative: 1746\n",
      "- Verhältnis: 62.357142857142854\n"
     ]
    }
   ],
   "source": [
    "# mit stratify\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.3,\n",
    "                                                                            stratify=y_clean, random_state=42)\n",
    "print_pos_neg(y_train_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.058056200Z",
     "start_time": "2024-11-14T16:25:51.343948400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vektorisierung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#Unsupervised_text_classification_Word2Vec\n",
    "\n",
    "# def vectorize(sentence, w2v_model):\n",
    "#     words = sentence.split()\n",
    "#     words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "#     if len(words_vecs) == 0:\n",
    "#         return np.zeros(100)\n",
    "#     words_vecs = np.array(words_vecs)\n",
    "#     return words_vecs.mean(axis=0)\n",
    "\n",
    "\n",
    "# def vectorize_df(df):\n",
    "#     X = df[\"tweet\"]\n",
    "#     y = df[\"label\"]\n",
    "#\n",
    "#     sentences_base = [sentence.split() for sentence in X]\n",
    "#     w2v_model_base = Word2Vec(sentences_base, window=5, min_count=5, workers=-1)\n",
    "#\n",
    "#     x_data = np.array([vectorize(sentence, w2v_model_base) for sentence in X])\n",
    "#     return x_data, y\n",
    "\n",
    "\n",
    "# def vectorize_df_cleaned(df):\n",
    "#     X = df[\"tweet_cleaned\"]\n",
    "#     y = df[\"label\"]\n",
    "#\n",
    "#     sentences_base = [sentence.split() for sentence in X]\n",
    "#     w2v_model_base = Word2Vec(sentences_base, window=5, min_count=5, workers=-1, )\n",
    "#\n",
    "#     x_data = np.array([vectorize(sentence, w2v_model_base) for sentence in X])\n",
    "#     return x_data, y\n",
    "\n",
    "\n",
    "# X_base, y_base = vectorize_df(df)\n",
    "# X_clean, y_clean = vectorize_df(df_cleaned)\n",
    "\n",
    "\n",
    "# nicht richtig genutzt, führt zu falschen train/test Daten"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.372579900Z",
     "start_time": "2024-11-14T16:25:51.364153800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train_base = vectorizer.fit_transform(X_train_base)\n",
    "X_test_base = vectorizer.transform(X_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.865001500Z",
     "start_time": "2024-11-14T16:25:51.384346600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_base shape (20671, 5000)\n",
      "y_train_base shape (20671,)\n",
      "X_test_base shape (8859, 5000)\n",
      "y_test_base shape (8859,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_base shape\", X_train_base.shape)\n",
    "print(\"y_train_base shape\", y_train_base.shape)\n",
    "\n",
    "print(\"X_test_base shape\", X_test_base.shape)\n",
    "print(\"y_test_base shape\", y_test_base.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.905306200Z",
     "start_time": "2024-11-14T16:25:51.970360200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "vectorizer_clean = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train_clean = vectorizer_clean.fit_transform(X_train_clean)\n",
    "X_test_clean = vectorizer_clean.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:53.905306200Z",
     "start_time": "2024-11-14T16:25:52.008683900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape (4137, 4093)\n",
      "y_train_clean shape (4137,)\n",
      "X_test_clean shape (1774, 4093)\n",
      "y_test_clean shape (1774,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_clean shape\", X_train_clean.shape)\n",
    "print(\"y_train_clean shape\", y_train_clean.shape)\n",
    "\n",
    "print(\"X_test_clean shape\", X_test_clean.shape)\n",
    "print(\"y_test_clean shape\", y_test_clean.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.091427100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Resampling Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def print_data(y_before, y_after, sampling_technique):\n",
    "    counter_before = Counter(y_before)\n",
    "    counter_after = Counter(y_after)\n",
    "    print(\"Before sampling with:\", sampling_technique, counter_before)\n",
    "    print(\"After sampling with:\", sampling_technique, counter_after)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.111582100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.1 SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "os_smote = SMOTE()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.131773400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 19262, 1: 1409})\n",
      "After sampling with: SMOTE Counter({1: 19262, 0: 19262})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_s, y_train_base_s = os_smote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.151934100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 4073, 1: 64})\n",
      "After sampling with: SMOTE Counter({0: 4073, 1: 4073})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_s, y_train_clean_s = os_smote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.535393100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.2 Borderline-SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "os_bsmote = BorderlineSMOTE()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.595967700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 19262, 1: 1409})\n",
      "After sampling with: BorderlineSMOTE Counter({1: 19262, 0: 19262})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_bs, y_train_base_bs = os_bsmote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:52.616182100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 4073, 1: 64})\n",
      "After sampling with: BorderlineSMOTE Counter({0: 4073, 1: 4073})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_bs, y_train_clean_bs = os_bsmote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:53.523853500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.3 ADASYN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "os_ada = ADASYN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.088863200Z",
     "start_time": "2024-11-14T16:25:53.624860500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 19262, 1: 1409})\n",
      "After sampling with: ADASYN Counter({0: 19262, 1: 18876})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_a, y_train_base_a = os_ada.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.643945400Z",
     "start_time": "2024-11-14T16:25:53.645069400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 4073, 1: 64})\n",
      "After sampling with: ADASYN Counter({0: 4073, 1: 4071})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_a, y_train_clean_a = os_ada.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.785292100Z",
     "start_time": "2024-11-14T16:25:54.613686100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.1 NearMiss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "us_near_miss = NearMiss(version=3, n_neighbors_ver3=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:54.785292100Z",
     "start_time": "2024-11-14T16:25:54.714587600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 19262, 1: 1409})\n",
      "After sampling with: NearMiss Counter({1: 1409, 0: 185})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_base_nm, y_train_base_nm = us_near_miss.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:56.843663300Z",
     "start_time": "2024-11-14T16:25:54.734887600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 4073, 1: 64})\n",
      "After sampling with: NearMiss Counter({0: 64, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_nm, y_train_clean_nm = us_near_miss.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:56.924394800Z",
     "start_time": "2024-11-14T16:25:56.823489500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.2 Condensed Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "us_cnn = CondensedNearestNeighbour(n_neighbors=1, n_jobs=-1)  # sehr langsam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:56.964772900Z",
     "start_time": "2024-11-14T16:25:56.924394800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# X_train_base_cnn, y_train_base_cnn = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:57.043534100Z",
     "start_time": "2024-11-14T16:25:56.944595200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# X_train_clean_cnn, y_train_clean_cnn = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:57.073880700Z",
     "start_time": "2024-11-14T16:25:56.964772900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.3 Neighborhood Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "us_cnn_cr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5, n_jobs=-1)  # sehr langsam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:57.073880700Z",
     "start_time": "2024-11-14T16:25:56.984960600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# X_train_base_ncr, y_train_base_ncr = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:57.073880700Z",
     "start_time": "2024-11-14T16:25:57.005147700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# X_train_clean_ncr, y_train_clean_ncr = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:57.073880700Z",
     "start_time": "2024-11-14T16:25:57.025377500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.4 Tomek Links Undersampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "us_tomek = TomekLinks()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:25:57.073880700Z",
     "start_time": "2024-11-14T16:25:57.045587900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: TomekLinks Counter({0: 19262, 1: 1409})\n",
      "After sampling with: TomekLinks Counter({0: 19223, 1: 1409})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_t, y_train_base_t = us_tomek.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_t, \"TomekLinks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:12.677901400Z",
     "start_time": "2024-11-14T16:25:57.065844500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: TomekLinks Counter({0: 4073, 1: 64})\n",
      "After sampling with: TomekLinks Counter({0: 4070, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_t, y_train_clean_t = us_tomek.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_t, \"TomekLinks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:12.695029400Z",
     "start_time": "2024-11-14T16:26:12.568745800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Ensemble Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(\n",
    "    columns=[\"model\", \"variant\", \"train_acc\", \"train_prec\", \"train_rec\", \"train_f1\", \"test_acc\", \"test_prec\",\n",
    "             \"test_rec\", \"test_f1\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:13.112591Z",
     "start_time": "2024-11-14T16:26:12.599102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model, model_name, variant, x_data_train, y_data_train, x_data_test, y_data_test):\n",
    "    train_acc = model.score(x_data_train, y_data_train)\n",
    "    train_precision = precision_score(y_data_train, model.predict(x_data_train))\n",
    "    train_recall = recall_score(y_data_train, model.predict(x_data_train))\n",
    "    train_f1 = f1_score(y_data_train, model.predict(x_data_train))\n",
    "\n",
    "    test_acc = model.score(x_data_test, y_data_test)\n",
    "    test_precision = precision_score(y_data_test, model.predict(x_data_test))\n",
    "    test_recall = recall_score(y_data_test, model.predict(x_data_test))\n",
    "    test_f1 = f1_score(y_data_test, model.predict(x_data_test))\n",
    "\n",
    "    evaluation.loc[len(evaluation.index)] = [model_name, variant, train_acc, train_precision, train_recall, train_f1,\n",
    "                                             test_acc, test_precision, test_recall, test_f1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:13.710177600Z",
     "start_time": "2024-11-14T16:26:13.119107100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, sampling_method):\n",
    "    pred = model.predict(x_test)\n",
    "    accscore = metrics.accuracy_score(pred, y_test)\n",
    "\n",
    "    print(f'{sampling_method} model accuracy for classification is =', str('{:04.2f}'.format(accscore * 100)) + '%')\n",
    "    print('------------------------------------------------')\n",
    "    print('Confusion Matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n",
    "    print('------------------------------------------------')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:13.766858700Z",
     "start_time": "2024-11-14T16:26:13.716954100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def fit_model(model, modelName):\n",
    "    print(\"Starting model fitting.\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"1/12 Fitting: \", modelName, \"BASE started...\")\n",
    "    model.fit(X_train_base, y_train_base)\n",
    "    add_to_eval_df(model, modelName, \"base\", X_train_base, y_train_base, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"2/12 Fitting: \", modelName, \"CLEAN started...\")\n",
    "    model.fit(X_train_clean, y_train_clean)\n",
    "    add_to_eval_df(model, modelName, \"clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"3/12 Fitting: \", modelName, \"SMOTE-base started...\")\n",
    "    model.fit(X_train_base_s, y_train_base_s)\n",
    "    add_to_eval_df(model, modelName, \"SMOTE base\", X_train_base_s, y_train_base_s, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"4/12 Fitting: \", modelName, \"SMOTE-clean started...\")\n",
    "    model.fit(X_train_clean_s, y_train_clean_s)\n",
    "    add_to_eval_df(model, modelName, \"SMOTE clean\", X_train_clean_s, y_train_clean_s, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"5/12 Fitting: \", modelName, \"BorderlineSMOTE-base started...\")\n",
    "    model.fit(X_train_base_bs, y_train_base_bs)\n",
    "    add_to_eval_df(model, modelName, \"BorderlineSMOTE base\", X_train_base_bs, y_train_base_bs, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"6/12 Fitting: \", modelName, \"BorderlineSMOTE-clean started...\")\n",
    "    model.fit(X_train_clean_bs, y_train_clean_bs)\n",
    "    add_to_eval_df(model, modelName, \"BorderlineSMOTE clean\", X_train_clean_bs, y_train_clean_bs, X_test_clean,\n",
    "                   y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"7/12 Fitting: \", modelName, \"ADASYN-base started...\")\n",
    "    model.fit(X_train_base_a, y_train_base_a)\n",
    "    add_to_eval_df(model, modelName, \"ADASYN base\", X_train_base_a, y_train_base_a, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"8/12 Fitting: \", modelName, \"ADASYN-clean started...\")\n",
    "    model.fit(X_train_clean_a, y_train_clean_a)\n",
    "    add_to_eval_df(model, modelName, \"ADASYN clean\", X_train_clean_a, y_train_clean_a, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"9/12 Fitting: \", modelName, \"NearMiss-base started...\")\n",
    "    model.fit(X_train_base_nm, y_train_base_nm)\n",
    "    add_to_eval_df(model, modelName, \"NearMiss base\", X_train_base_nm, y_train_base_nm, X_test_base, y_test_base)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"10/12 Fitting: \", modelName, \"NearMiss-clean started...\")\n",
    "    model.fit(X_train_clean_nm, y_train_clean_nm)\n",
    "    add_to_eval_df(model, modelName, \"NearMiss clean\", X_train_clean_nm, y_train_clean_nm, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"11/12 Fitting: \", modelName, \"TomekLink-base started...\")\n",
    "    model.fit(X_train_clean_t, y_train_clean_t)\n",
    "    add_to_eval_df(model, modelName, \"TomekLink base\", X_train_clean_t, y_train_clean_t, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"12/12 Fitting: \", modelName, \"TomekLink-clean started...\")\n",
    "    model.fit(X_train_clean_t, y_train_clean_t)\n",
    "    add_to_eval_df(model, modelName, \"TomekLink clean\", X_train_clean_t, y_train_clean_t, X_test_clean, y_test_clean)\n",
    "    end = time.time()\n",
    "    elapsed_time = round(end - start)\n",
    "    print(\"Fitting: \", modelName, \"finished. Elapsed time: \", elapsed_time, \"Seconds\")\n",
    "\n",
    "    print(\"Model fitting finished.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:13.844833800Z",
     "start_time": "2024-11-14T16:26:13.766858700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:13.844833800Z",
     "start_time": "2024-11-14T16:26:13.782482700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  RandomForest BASE started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  6 Seconds\n",
      "2/12 Fitting:  RandomForest CLEAN started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "3/12 Fitting:  RandomForest SMOTE-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  12 Seconds\n",
      "4/12 Fitting:  RandomForest SMOTE-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "5/12 Fitting:  RandomForest BorderlineSMOTE-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  5 Seconds\n",
      "6/12 Fitting:  RandomForest BorderlineSMOTE-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  RandomForest ADASYN-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  6 Seconds\n",
      "8/12 Fitting:  RandomForest ADASYN-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "9/12 Fitting:  RandomForest NearMiss-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "10/12 Fitting:  RandomForest NearMiss-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "11/12 Fitting:  RandomForest TomekLink-base started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "12/12 Fitting:  RandomForest TomekLink-clean started...\n",
      "Fitting:  RandomForest finished. Elapsed time:  1 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(rf, \"RandomForest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:49.391505700Z",
     "start_time": "2024-11-14T16:26:13.798109200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "brf = BalancedRandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:49.421777600Z",
     "start_time": "2024-11-14T16:26:49.391505700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BASE\n",
    "brf.fit(X_train_base, y_train_base)\n",
    "add_to_eval_df(brf, \"BalancedRandomForest\", \"BALANCED base\", X_train_base, y_train_base, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:51.314122900Z",
     "start_time": "2024-11-14T16:26:49.411690200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function delayed is deprecated; The function `delayed` has been moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`. This import path will be removed in 1.5.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:114: UserWarning: `sklearn.utils.parallel.delayed` should be used with `sklearn.utils.parallel.Parallel` to make it possible to propagate the scikit-learn configuration of the current thread to the joblib workers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CLEANED\n",
    "brf.fit(X_train_clean, y_train_clean)\n",
    "add_to_eval_df(brf, \"BalancedRandomForest\", \"BALANCED clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:52.338756800Z",
     "start_time": "2024-11-14T16:26:51.314122900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n1           RandomForest                  clean   1.000000    1.000000   \n3           RandomForest            SMOTE clean   1.000000    1.000000   \n5           RandomForest  BorderlineSMOTE clean   1.000000    1.000000   \n7           RandomForest           ADASYN clean   1.000000    1.000000   \n11          RandomForest        TomekLink clean   1.000000    1.000000   \n0           RandomForest                   base   0.999855    1.000000   \n4           RandomForest   BorderlineSMOTE base   0.999922    1.000000   \n10          RandomForest         TomekLink base   0.999758    1.000000   \n2           RandomForest             SMOTE base   0.999922    0.999948   \n6           RandomForest            ADASYN base   0.999921    0.999841   \n12  BalancedRandomForest          BALANCED base   0.857965    0.324281   \n13  BalancedRandomForest         BALANCED clean   0.940778    0.207120   \n9           RandomForest         NearMiss clean   1.000000    1.000000   \n8           RandomForest          NearMiss base   0.998118    1.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n1    1.000000  1.000000  0.986471   1.000000  0.142857  0.250000  \n3    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n5    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n7    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n11   1.000000  1.000000  0.987035   1.000000  0.178571  0.303030  \n0    0.997871  0.998934  0.955977   0.882143  0.408940  0.558824  \n4    0.999844  0.999922  0.950897   0.856540  0.336093  0.482759  \n10   0.984375  0.992126  0.985908   0.800000  0.142857  0.242424  \n2    0.999896  0.999922  0.953042   0.786585  0.427152  0.553648  \n6    1.000000  0.999921  0.952139   0.758621  0.437086  0.554622  \n12   1.000000  0.489746  0.817022   0.248889  0.834437  0.383416  \n13   1.000000  0.343164  0.937430   0.119266  0.464286  0.189781  \n9    1.000000  1.000000  0.924464   0.092308  0.428571  0.151899  \n8    0.997871  0.998934  0.230500   0.079350  0.970199  0.146702  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.986471</td>\n      <td>1.000000</td>\n      <td>0.142857</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>1.000000</td>\n      <td>0.178571</td>\n      <td>0.303030</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.955977</td>\n      <td>0.882143</td>\n      <td>0.408940</td>\n      <td>0.558824</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.950897</td>\n      <td>0.856540</td>\n      <td>0.336093</td>\n      <td>0.482759</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.985908</td>\n      <td>0.800000</td>\n      <td>0.142857</td>\n      <td>0.242424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999922</td>\n      <td>0.999948</td>\n      <td>0.999896</td>\n      <td>0.999922</td>\n      <td>0.953042</td>\n      <td>0.786585</td>\n      <td>0.427152</td>\n      <td>0.553648</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999921</td>\n      <td>0.999841</td>\n      <td>1.000000</td>\n      <td>0.999921</td>\n      <td>0.952139</td>\n      <td>0.758621</td>\n      <td>0.437086</td>\n      <td>0.554622</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.857965</td>\n      <td>0.324281</td>\n      <td>1.000000</td>\n      <td>0.489746</td>\n      <td>0.817022</td>\n      <td>0.248889</td>\n      <td>0.834437</td>\n      <td>0.383416</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.940778</td>\n      <td>0.207120</td>\n      <td>1.000000</td>\n      <td>0.343164</td>\n      <td>0.937430</td>\n      <td>0.119266</td>\n      <td>0.464286</td>\n      <td>0.189781</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.924464</td>\n      <td>0.092308</td>\n      <td>0.428571</td>\n      <td>0.151899</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998118</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.230500</td>\n      <td>0.079350</td>\n      <td>0.970199</td>\n      <td>0.146702</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[(evaluation.model == \"RandomForest\") | (evaluation.model == \"BalancedRandomForest\")].sort_values(\n",
    "    by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:52.358921500Z",
     "start_time": "2024-11-14T16:26:52.338756800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1a XGBClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:52.460175100Z",
     "start_time": "2024-11-14T16:26:52.358921500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  XGBClassifier BASE started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  11 Seconds\n",
      "2/12 Fitting:  XGBClassifier CLEAN started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  XGBClassifier SMOTE-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  6 Seconds\n",
      "4/12 Fitting:  XGBClassifier SMOTE-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "5/12 Fitting:  XGBClassifier BorderlineSMOTE-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  6 Seconds\n",
      "6/12 Fitting:  XGBClassifier BorderlineSMOTE-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  XGBClassifier ADASYN-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  6 Seconds\n",
      "8/12 Fitting:  XGBClassifier ADASYN-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  1 Seconds\n",
      "9/12 Fitting:  XGBClassifier NearMiss-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  XGBClassifier NearMiss-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  XGBClassifier TomekLink-base started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  XGBClassifier TomekLink-clean started...\n",
      "Fitting:  XGBClassifier finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(xgb, \"XGBClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.234542100Z",
     "start_time": "2024-11-14T16:26:52.379142300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "            model                variant  train_acc  train_prec  train_rec  \\\n14  XGBClassifier                   base   0.965120    0.972527   0.502484   \n21  XGBClassifier           ADASYN clean   0.998527    1.000000   0.997052   \n17  XGBClassifier            SMOTE clean   0.998772    1.000000   0.997545   \n19  XGBClassifier  BorderlineSMOTE clean   0.997668    1.000000   0.995335   \n18  XGBClassifier   BorderlineSMOTE base   0.978325    0.993096   0.963348   \n15  XGBClassifier                  clean   0.992265    1.000000   0.500000   \n20  XGBClassifier            ADASYN base   0.968824    0.990951   0.945645   \n16  XGBClassifier             SMOTE base   0.970642    0.991115   0.949798   \n24  XGBClassifier         TomekLink base   0.992259    1.000000   0.500000   \n25  XGBClassifier        TomekLink clean   0.992259    1.000000   0.500000   \n22  XGBClassifier          NearMiss base   0.966123    0.969508   0.992903   \n23  XGBClassifier         NearMiss clean   0.789062    0.877551   0.671875   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n14  0.662611  0.951010   0.824427  0.357616  0.498845  \n21  0.998524  0.988162   0.818182  0.321429  0.461538  \n17  0.998771  0.987035   0.727273  0.285714  0.410256  \n19  0.997662  0.986471   0.700000  0.250000  0.368421  \n18  0.977996  0.945818   0.676136  0.394040  0.497908  \n15  0.666667  0.985344   0.666667  0.142857  0.235294  \n20  0.967768  0.945705   0.659740  0.420530  0.513650  \n16  0.970017  0.944689   0.646907  0.415563  0.506048  \n24  0.666667  0.984780   0.600000  0.107143  0.181818  \n25  0.666667  0.984780   0.600000  0.107143  0.181818  \n22  0.981066  0.137600   0.070976  0.963576  0.132213  \n23  0.761062  0.757046   0.030303  0.464286  0.056893  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.965120</td>\n      <td>0.972527</td>\n      <td>0.502484</td>\n      <td>0.662611</td>\n      <td>0.951010</td>\n      <td>0.824427</td>\n      <td>0.357616</td>\n      <td>0.498845</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.998527</td>\n      <td>1.000000</td>\n      <td>0.997052</td>\n      <td>0.998524</td>\n      <td>0.988162</td>\n      <td>0.818182</td>\n      <td>0.321429</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.998772</td>\n      <td>1.000000</td>\n      <td>0.997545</td>\n      <td>0.998771</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997668</td>\n      <td>1.000000</td>\n      <td>0.995335</td>\n      <td>0.997662</td>\n      <td>0.986471</td>\n      <td>0.700000</td>\n      <td>0.250000</td>\n      <td>0.368421</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.978325</td>\n      <td>0.993096</td>\n      <td>0.963348</td>\n      <td>0.977996</td>\n      <td>0.945818</td>\n      <td>0.676136</td>\n      <td>0.394040</td>\n      <td>0.497908</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.992265</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.985344</td>\n      <td>0.666667</td>\n      <td>0.142857</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.968824</td>\n      <td>0.990951</td>\n      <td>0.945645</td>\n      <td>0.967768</td>\n      <td>0.945705</td>\n      <td>0.659740</td>\n      <td>0.420530</td>\n      <td>0.513650</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.970642</td>\n      <td>0.991115</td>\n      <td>0.949798</td>\n      <td>0.970017</td>\n      <td>0.944689</td>\n      <td>0.646907</td>\n      <td>0.415563</td>\n      <td>0.506048</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.966123</td>\n      <td>0.969508</td>\n      <td>0.992903</td>\n      <td>0.981066</td>\n      <td>0.137600</td>\n      <td>0.070976</td>\n      <td>0.963576</td>\n      <td>0.132213</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.789062</td>\n      <td>0.877551</td>\n      <td>0.671875</td>\n      <td>0.761062</td>\n      <td>0.757046</td>\n      <td>0.030303</td>\n      <td>0.464286</td>\n      <td>0.056893</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"XGBClassifier\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.295070800Z",
     "start_time": "2024-11-14T16:27:27.234542100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1b XGBClassifier tuning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# todo erneut machen\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test1, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.295070800Z",
     "start_time": "2024-11-14T16:27:27.274852900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# gsearch1.fit(X_train_clean, y_train_clean)\n",
    "# gsearch1.best_score_, gsearch1.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.315226600Z",
     "start_time": "2024-11-14T16:27:27.295070800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    "    'min_child_weight': range(1, 6, 2),\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test2, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.365649500Z",
     "start_time": "2024-11-14T16:27:27.315226600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# gsearch2.fit(X_train_clean, y_train_clean)\n",
    "# gsearch2.best_score_, gsearch2.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.393979600Z",
     "start_time": "2024-11-14T16:27:27.335410700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'gamma': [i / 10.0 for i in range(0, 5)],\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test3, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.495179Z",
     "start_time": "2024-11-14T16:27:27.355580700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# gsearch3.fit(X_train_clean, y_train_clean)\n",
    "# gsearch3.best_score_, gsearch3.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.375797900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    "    'subsample': [i / 10.0 for i in range(6, 10)],\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test4, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.396052200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# gsearch4.fit(X_train_clean, y_train_clean)\n",
    "# gsearch4.best_score_, gsearch4.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.416321300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    "    'colsample_bytree': [i / 10.0 for i in range(6, 10)],\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.456781200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# gsearch5.fit(X_train_clean, y_train_clean)\n",
    "# gsearch5.best_score_, gsearch5.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.456781200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator=XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "), param_grid=param_test6, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.477039100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# gsearch6.fit(X_train_clean, y_train_clean)\n",
    "# gsearch6.best_score_, gsearch6.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.537762300Z",
     "start_time": "2024-11-14T16:27:27.497232800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "xgb_tune = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=140,\n",
    "    max_depth=9,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.596420900Z",
     "start_time": "2024-11-14T16:27:27.517477600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# fit_model(xgb_tune, \"XGBClassifier-tuned\")\n",
    "# evaluation[evaluation.model == \"XGBClassifier-tuned\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.616796500Z",
     "start_time": "2024-11-14T16:27:27.537762300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1 CatBoostClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(iterations=2,\n",
    "                         depth=2,\n",
    "                         learning_rate=1,\n",
    "                         loss_function='Logloss',\n",
    "                         verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:27.715033400Z",
     "start_time": "2024-11-14T16:27:27.558045800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  CatBoostClassifier BASE started...\n",
      "0:\tlearn: 0.2487701\ttotal: 181ms\tremaining: 181ms\n",
      "1:\tlearn: 0.2343139\ttotal: 197ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "2/12 Fitting:  CatBoostClassifier CLEAN started...\n",
      "0:\tlearn: 0.0796309\ttotal: 6.38ms\tremaining: 6.38ms\n",
      "1:\tlearn: 0.0749569\ttotal: 12.4ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  CatBoostClassifier SMOTE-base started...\n",
      "0:\tlearn: 0.5973069\ttotal: 23.9ms\tremaining: 23.9ms\n",
      "1:\tlearn: 0.5473286\ttotal: 46.7ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "4/12 Fitting:  CatBoostClassifier SMOTE-clean started...\n",
      "0:\tlearn: 0.6081730\ttotal: 9.01ms\tremaining: 9.01ms\n",
      "1:\tlearn: 0.5165198\ttotal: 16.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  CatBoostClassifier BorderlineSMOTE-base started...\n",
      "0:\tlearn: 0.5944839\ttotal: 23.3ms\tremaining: 23.3ms\n",
      "1:\tlearn: 0.5373385\ttotal: 46.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "6/12 Fitting:  CatBoostClassifier BorderlineSMOTE-clean started...\n",
      "0:\tlearn: 0.5660557\ttotal: 17.4ms\tremaining: 17.4ms\n",
      "1:\tlearn: 0.4757402\ttotal: 26.2ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  CatBoostClassifier ADASYN-base started...\n",
      "0:\tlearn: 0.5948012\ttotal: 24.4ms\tremaining: 24.4ms\n",
      "1:\tlearn: 0.5487788\ttotal: 47.6ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  1 Seconds\n",
      "8/12 Fitting:  CatBoostClassifier ADASYN-clean started...\n",
      "0:\tlearn: 0.6072480\ttotal: 8ms\tremaining: 8ms\n",
      "1:\tlearn: 0.5267242\ttotal: 15.8ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  CatBoostClassifier NearMiss-base started...\n",
      "0:\tlearn: 0.3586037\ttotal: 4.74ms\tremaining: 4.74ms\n",
      "1:\tlearn: 0.3403802\ttotal: 9.1ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  CatBoostClassifier NearMiss-clean started...\n",
      "0:\tlearn: 0.6732156\ttotal: 1.84ms\tremaining: 1.84ms\n",
      "1:\tlearn: 0.6434392\ttotal: 3.5ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  CatBoostClassifier TomekLink-base started...\n",
      "0:\tlearn: 0.0797480\ttotal: 6.29ms\tremaining: 6.29ms\n",
      "1:\tlearn: 0.0743677\ttotal: 12.2ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  CatBoostClassifier TomekLink-clean started...\n",
      "0:\tlearn: 0.0797480\ttotal: 6.35ms\tremaining: 6.35ms\n",
      "1:\tlearn: 0.0743677\ttotal: 12.1ms\tremaining: 0us\n",
      "Fitting:  CatBoostClassifier finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(cat, \"CatBoostClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:32.409623Z",
     "start_time": "2024-11-14T16:27:27.596420900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "                 model                variant  train_acc  train_prec  \\\n26  CatBoostClassifier                   base   0.936191    0.736842   \n31  CatBoostClassifier  BorderlineSMOTE clean   0.767002    0.981834   \n33  CatBoostClassifier           ADASYN clean   0.719425    0.977540   \n32  CatBoostClassifier            ADASYN base   0.708349    0.678550   \n28  CatBoostClassifier             SMOTE base   0.715891    0.686371   \n30  CatBoostClassifier   BorderlineSMOTE base   0.713296    0.664914   \n29  CatBoostClassifier            SMOTE clean   0.743187    0.931967   \n34  CatBoostClassifier          NearMiss base   0.891468    0.891635   \n35  CatBoostClassifier         NearMiss clean   0.570312    0.846154   \n27  CatBoostClassifier                  clean   0.985738    1.000000   \n36  CatBoostClassifier         TomekLink base   0.985728    0.857143   \n37  CatBoostClassifier        TomekLink clean   0.985728    0.857143   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n26   0.099361  0.175109  0.936787   0.744444  0.110927  0.193084  \n31   0.544071  0.700158  0.975761   0.222222  0.214286  0.218182  \n33   0.449030  0.615385  0.971815   0.176471  0.214286  0.193548  \n32   0.780462  0.725947  0.641946   0.116716  0.647351  0.197774  \n28   0.795089  0.736741  0.639914   0.114030  0.632450  0.193222  \n30   0.859983  0.749972  0.576363   0.107063  0.710265  0.186077  \n29   0.524675  0.671379  0.950958   0.072464  0.178571  0.103093  \n34   0.998581  0.942082  0.072017   0.068148  0.995033  0.127560  \n35   0.171875  0.285714  0.967869   0.032258  0.035714  0.033898  \n27   0.078125  0.144928  0.983653   0.000000  0.000000  0.000000  \n36   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n37   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.936191</td>\n      <td>0.736842</td>\n      <td>0.099361</td>\n      <td>0.175109</td>\n      <td>0.936787</td>\n      <td>0.744444</td>\n      <td>0.110927</td>\n      <td>0.193084</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.767002</td>\n      <td>0.981834</td>\n      <td>0.544071</td>\n      <td>0.700158</td>\n      <td>0.975761</td>\n      <td>0.222222</td>\n      <td>0.214286</td>\n      <td>0.218182</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.719425</td>\n      <td>0.977540</td>\n      <td>0.449030</td>\n      <td>0.615385</td>\n      <td>0.971815</td>\n      <td>0.176471</td>\n      <td>0.214286</td>\n      <td>0.193548</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.708349</td>\n      <td>0.678550</td>\n      <td>0.780462</td>\n      <td>0.725947</td>\n      <td>0.641946</td>\n      <td>0.116716</td>\n      <td>0.647351</td>\n      <td>0.197774</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.715891</td>\n      <td>0.686371</td>\n      <td>0.795089</td>\n      <td>0.736741</td>\n      <td>0.639914</td>\n      <td>0.114030</td>\n      <td>0.632450</td>\n      <td>0.193222</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.713296</td>\n      <td>0.664914</td>\n      <td>0.859983</td>\n      <td>0.749972</td>\n      <td>0.576363</td>\n      <td>0.107063</td>\n      <td>0.710265</td>\n      <td>0.186077</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.743187</td>\n      <td>0.931967</td>\n      <td>0.524675</td>\n      <td>0.671379</td>\n      <td>0.950958</td>\n      <td>0.072464</td>\n      <td>0.178571</td>\n      <td>0.103093</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.891468</td>\n      <td>0.891635</td>\n      <td>0.998581</td>\n      <td>0.942082</td>\n      <td>0.072017</td>\n      <td>0.068148</td>\n      <td>0.995033</td>\n      <td>0.127560</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.570312</td>\n      <td>0.846154</td>\n      <td>0.171875</td>\n      <td>0.285714</td>\n      <td>0.967869</td>\n      <td>0.032258</td>\n      <td>0.035714</td>\n      <td>0.033898</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.985738</td>\n      <td>1.000000</td>\n      <td>0.078125</td>\n      <td>0.144928</td>\n      <td>0.983653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"CatBoostClassifier\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:32.447381300Z",
     "start_time": "2024-11-14T16:27:32.409623Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.1 LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "light = LGBMClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:32.494286400Z",
     "start_time": "2024-11-14T16:27:32.440866700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LGBMClassifier BASE started...\n",
      "[LightGBM] [Info] Number of positive: 1409, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45936\n",
      "[LightGBM] [Info] Number of data points in the train set: 20671, number of used features: 1379\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.068163 -> initscore=-2.615254\n",
      "[LightGBM] [Info] Start training from score -2.615254\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  4 Seconds\n",
      "2/12 Fitting:  LGBMClassifier CLEAN started...\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7842\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015470 -> initscore=-4.153252\n",
      "[LightGBM] [Info] Start training from score -4.153252\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  LGBMClassifier SMOTE-base started...\n",
      "[LightGBM] [Info] Number of positive: 19262, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108295\n",
      "[LightGBM] [Info] Number of data points in the train set: 38524, number of used features: 2583\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  7 Seconds\n",
      "4/12 Fitting:  LGBMClassifier SMOTE-clean started...\n",
      "[LightGBM] [Info] Number of positive: 4073, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29409\n",
      "[LightGBM] [Info] Number of data points in the train set: 8146, number of used features: 610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "5/12 Fitting:  LGBMClassifier BorderlineSMOTE-base started...\n",
      "[LightGBM] [Info] Number of positive: 19262, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 101208\n",
      "[LightGBM] [Info] Number of data points in the train set: 38524, number of used features: 1999\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  3 Seconds\n",
      "6/12 Fitting:  LGBMClassifier BorderlineSMOTE-clean started...\n",
      "[LightGBM] [Info] Number of positive: 4073, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28276\n",
      "[LightGBM] [Info] Number of data points in the train set: 8146, number of used features: 565\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "7/12 Fitting:  LGBMClassifier ADASYN-base started...\n",
      "[LightGBM] [Info] Number of positive: 18876, number of negative: 19262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 108802\n",
      "[LightGBM] [Info] Number of data points in the train set: 38138, number of used features: 2637\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494939 -> initscore=-0.020243\n",
      "[LightGBM] [Info] Start training from score -0.020243\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  3 Seconds\n",
      "8/12 Fitting:  LGBMClassifier ADASYN-clean started...\n",
      "[LightGBM] [Info] Number of positive: 4071, number of negative: 4073\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29621\n",
      "[LightGBM] [Info] Number of data points in the train set: 8144, number of used features: 610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499877 -> initscore=-0.000491\n",
      "[LightGBM] [Info] Start training from score -0.000491\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  1 Seconds\n",
      "9/12 Fitting:  LGBMClassifier NearMiss-base started...\n",
      "[LightGBM] [Info] Number of positive: 1409, number of negative: 185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2935\n",
      "[LightGBM] [Info] Number of data points in the train set: 1594, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.883940 -> initscore=2.030280\n",
      "[LightGBM] [Info] Start training from score 2.030280\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LGBMClassifier NearMiss-clean started...\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 64\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 128, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LGBMClassifier TomekLink-base started...\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 4070\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7829\n",
      "[LightGBM] [Info] Number of data points in the train set: 4134, number of used features: 356\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015481 -> initscore=-4.152515\n",
      "[LightGBM] [Info] Start training from score -4.152515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  LGBMClassifier TomekLink-clean started...\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 4070\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7829\n",
      "[LightGBM] [Info] Number of data points in the train set: 4134, number of used features: 356\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015481 -> initscore=-4.152515\n",
      "[LightGBM] [Info] Start training from score -4.152515\n",
      "Fitting:  LGBMClassifier finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(light, \"LGBMClassifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.145815600Z",
     "start_time": "2024-11-14T16:27:32.463022200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "             model                variant  train_acc  train_prec  train_rec  \\\n38  LGBMClassifier                   base   0.964298    0.944371   0.506033   \n41  LGBMClassifier            SMOTE clean   1.000000    1.000000   1.000000   \n43  LGBMClassifier  BorderlineSMOTE clean   1.000000    1.000000   1.000000   \n45  LGBMClassifier           ADASYN clean   1.000000    1.000000   1.000000   \n42  LGBMClassifier   BorderlineSMOTE base   0.977001    0.984957   0.968799   \n44  LGBMClassifier            ADASYN base   0.970135    0.978473   0.960797   \n40  LGBMClassifier             SMOTE base   0.969707    0.979033   0.959973   \n39  LGBMClassifier                  clean   0.999758    1.000000   0.984375   \n48  LGBMClassifier         TomekLink base   0.999758    0.984615   1.000000   \n49  LGBMClassifier        TomekLink clean   0.999758    0.984615   1.000000   \n46  LGBMClassifier          NearMiss base   0.971142    0.975576   0.992193   \n47  LGBMClassifier         NearMiss clean   0.500000    0.000000   0.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n38  0.658965  0.948301   0.753472  0.359272  0.486547  \n41  1.000000  0.987599   0.750000  0.321429  0.450000  \n43  1.000000  0.987035   0.727273  0.285714  0.410256  \n45  1.000000  0.987035   0.727273  0.285714  0.410256  \n42  0.976811  0.944237   0.626147  0.451987  0.525000  \n44  0.969554  0.940738   0.572212  0.518212  0.543875  \n40  0.969409  0.940400   0.571161  0.504967  0.536028  \n39  0.992126  0.981398   0.222222  0.071429  0.108108  \n48  0.992248  0.981398   0.222222  0.071429  0.108108  \n49  0.992248  0.981398   0.222222  0.071429  0.108108  \n46  0.983814  0.138052   0.070801  0.960265  0.131878  \n47  0.000000  0.984216   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.964298</td>\n      <td>0.944371</td>\n      <td>0.506033</td>\n      <td>0.658965</td>\n      <td>0.948301</td>\n      <td>0.753472</td>\n      <td>0.359272</td>\n      <td>0.486547</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.977001</td>\n      <td>0.984957</td>\n      <td>0.968799</td>\n      <td>0.976811</td>\n      <td>0.944237</td>\n      <td>0.626147</td>\n      <td>0.451987</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.970135</td>\n      <td>0.978473</td>\n      <td>0.960797</td>\n      <td>0.969554</td>\n      <td>0.940738</td>\n      <td>0.572212</td>\n      <td>0.518212</td>\n      <td>0.543875</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969707</td>\n      <td>0.979033</td>\n      <td>0.959973</td>\n      <td>0.969409</td>\n      <td>0.940400</td>\n      <td>0.571161</td>\n      <td>0.504967</td>\n      <td>0.536028</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.971142</td>\n      <td>0.975576</td>\n      <td>0.992193</td>\n      <td>0.983814</td>\n      <td>0.138052</td>\n      <td>0.070801</td>\n      <td>0.960265</td>\n      <td>0.131878</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LGBMClassifier\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.183596Z",
     "start_time": "2024-11-14T16:27:53.098940700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Stacking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', LinearSVC(random_state=42))\n",
    "]\n",
    "stack = StackingClassifier(estimators=base_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.183596Z",
     "start_time": "2024-11-14T16:27:53.145815600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# stack.fit(X_train_base, y_train_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.230471100Z",
     "start_time": "2024-11-14T16:27:53.145815600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model comparision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n3           RandomForest            SMOTE clean   1.000000    1.000000   \n5           RandomForest  BorderlineSMOTE clean   1.000000    1.000000   \n7           RandomForest           ADASYN clean   1.000000    1.000000   \n11          RandomForest        TomekLink clean   1.000000    1.000000   \n1           RandomForest                  clean   1.000000    1.000000   \n0           RandomForest                   base   0.999855    1.000000   \n4           RandomForest   BorderlineSMOTE base   0.999922    1.000000   \n14         XGBClassifier                   base   0.965120    0.972527   \n21         XGBClassifier           ADASYN clean   0.998527    1.000000   \n10          RandomForest         TomekLink base   0.999758    1.000000   \n2           RandomForest             SMOTE base   0.999922    0.999948   \n6           RandomForest            ADASYN base   0.999921    0.999841   \n38        LGBMClassifier                   base   0.964298    0.944371   \n41        LGBMClassifier            SMOTE clean   1.000000    1.000000   \n26    CatBoostClassifier                   base   0.936191    0.736842   \n17         XGBClassifier            SMOTE clean   0.998772    1.000000   \n43        LGBMClassifier  BorderlineSMOTE clean   1.000000    1.000000   \n45        LGBMClassifier           ADASYN clean   1.000000    1.000000   \n19         XGBClassifier  BorderlineSMOTE clean   0.997668    1.000000   \n18         XGBClassifier   BorderlineSMOTE base   0.978325    0.993096   \n15         XGBClassifier                  clean   0.992265    1.000000   \n20         XGBClassifier            ADASYN base   0.968824    0.990951   \n16         XGBClassifier             SMOTE base   0.970642    0.991115   \n42        LGBMClassifier   BorderlineSMOTE base   0.977001    0.984957   \n25         XGBClassifier        TomekLink clean   0.992259    1.000000   \n24         XGBClassifier         TomekLink base   0.992259    1.000000   \n44        LGBMClassifier            ADASYN base   0.970135    0.978473   \n40        LGBMClassifier             SMOTE base   0.969707    0.979033   \n12  BalancedRandomForest          BALANCED base   0.857965    0.324281   \n39        LGBMClassifier                  clean   0.999758    1.000000   \n48        LGBMClassifier         TomekLink base   0.999758    0.984615   \n49        LGBMClassifier        TomekLink clean   0.999758    0.984615   \n31    CatBoostClassifier  BorderlineSMOTE clean   0.767002    0.981834   \n33    CatBoostClassifier           ADASYN clean   0.719425    0.977540   \n13  BalancedRandomForest         BALANCED clean   0.940778    0.207120   \n32    CatBoostClassifier            ADASYN base   0.708349    0.678550   \n28    CatBoostClassifier             SMOTE base   0.715891    0.686371   \n30    CatBoostClassifier   BorderlineSMOTE base   0.713296    0.664914   \n9           RandomForest         NearMiss clean   1.000000    1.000000   \n8           RandomForest          NearMiss base   0.998118    1.000000   \n29    CatBoostClassifier            SMOTE clean   0.743187    0.931967   \n22         XGBClassifier          NearMiss base   0.966123    0.969508   \n46        LGBMClassifier          NearMiss base   0.971142    0.975576   \n34    CatBoostClassifier          NearMiss base   0.891468    0.891635   \n35    CatBoostClassifier         NearMiss clean   0.570312    0.846154   \n23         XGBClassifier         NearMiss clean   0.789062    0.877551   \n36    CatBoostClassifier         TomekLink base   0.985728    0.857143   \n47        LGBMClassifier         NearMiss clean   0.500000    0.000000   \n27    CatBoostClassifier                  clean   0.985738    1.000000   \n37    CatBoostClassifier        TomekLink clean   0.985728    0.857143   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n3    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n5    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n7    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n11   1.000000  1.000000  0.987035   1.000000  0.178571  0.303030  \n1    1.000000  1.000000  0.986471   1.000000  0.142857  0.250000  \n0    0.997871  0.998934  0.955977   0.882143  0.408940  0.558824  \n4    0.999844  0.999922  0.950897   0.856540  0.336093  0.482759  \n14   0.502484  0.662611  0.951010   0.824427  0.357616  0.498845  \n21   0.997052  0.998524  0.988162   0.818182  0.321429  0.461538  \n10   0.984375  0.992126  0.985908   0.800000  0.142857  0.242424  \n2    0.999896  0.999922  0.953042   0.786585  0.427152  0.553648  \n6    1.000000  0.999921  0.952139   0.758621  0.437086  0.554622  \n38   0.506033  0.658965  0.948301   0.753472  0.359272  0.486547  \n41   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n26   0.099361  0.175109  0.936787   0.744444  0.110927  0.193084  \n17   0.997545  0.998771  0.987035   0.727273  0.285714  0.410256  \n43   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n45   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n19   0.995335  0.997662  0.986471   0.700000  0.250000  0.368421  \n18   0.963348  0.977996  0.945818   0.676136  0.394040  0.497908  \n15   0.500000  0.666667  0.985344   0.666667  0.142857  0.235294  \n20   0.945645  0.967768  0.945705   0.659740  0.420530  0.513650  \n16   0.949798  0.970017  0.944689   0.646907  0.415563  0.506048  \n42   0.968799  0.976811  0.944237   0.626147  0.451987  0.525000  \n25   0.500000  0.666667  0.984780   0.600000  0.107143  0.181818  \n24   0.500000  0.666667  0.984780   0.600000  0.107143  0.181818  \n44   0.960797  0.969554  0.940738   0.572212  0.518212  0.543875  \n40   0.959973  0.969409  0.940400   0.571161  0.504967  0.536028  \n12   1.000000  0.489746  0.817022   0.248889  0.834437  0.383416  \n39   0.984375  0.992126  0.981398   0.222222  0.071429  0.108108  \n48   1.000000  0.992248  0.981398   0.222222  0.071429  0.108108  \n49   1.000000  0.992248  0.981398   0.222222  0.071429  0.108108  \n31   0.544071  0.700158  0.975761   0.222222  0.214286  0.218182  \n33   0.449030  0.615385  0.971815   0.176471  0.214286  0.193548  \n13   1.000000  0.343164  0.937430   0.119266  0.464286  0.189781  \n32   0.780462  0.725947  0.641946   0.116716  0.647351  0.197774  \n28   0.795089  0.736741  0.639914   0.114030  0.632450  0.193222  \n30   0.859983  0.749972  0.576363   0.107063  0.710265  0.186077  \n9    1.000000  1.000000  0.924464   0.092308  0.428571  0.151899  \n8    0.997871  0.998934  0.230500   0.079350  0.970199  0.146702  \n29   0.524675  0.671379  0.950958   0.072464  0.178571  0.103093  \n22   0.992903  0.981066  0.137600   0.070976  0.963576  0.132213  \n46   0.992193  0.983814  0.138052   0.070801  0.960265  0.131878  \n34   0.998581  0.942082  0.072017   0.068148  0.995033  0.127560  \n35   0.171875  0.285714  0.967869   0.032258  0.035714  0.033898  \n23   0.671875  0.761062  0.757046   0.030303  0.464286  0.056893  \n36   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n47   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  \n27   0.078125  0.144928  0.983653   0.000000  0.000000  0.000000  \n37   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>1.000000</td>\n      <td>0.178571</td>\n      <td>0.303030</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.986471</td>\n      <td>1.000000</td>\n      <td>0.142857</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.955977</td>\n      <td>0.882143</td>\n      <td>0.408940</td>\n      <td>0.558824</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.950897</td>\n      <td>0.856540</td>\n      <td>0.336093</td>\n      <td>0.482759</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.965120</td>\n      <td>0.972527</td>\n      <td>0.502484</td>\n      <td>0.662611</td>\n      <td>0.951010</td>\n      <td>0.824427</td>\n      <td>0.357616</td>\n      <td>0.498845</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.998527</td>\n      <td>1.000000</td>\n      <td>0.997052</td>\n      <td>0.998524</td>\n      <td>0.988162</td>\n      <td>0.818182</td>\n      <td>0.321429</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.985908</td>\n      <td>0.800000</td>\n      <td>0.142857</td>\n      <td>0.242424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999922</td>\n      <td>0.999948</td>\n      <td>0.999896</td>\n      <td>0.999922</td>\n      <td>0.953042</td>\n      <td>0.786585</td>\n      <td>0.427152</td>\n      <td>0.553648</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999921</td>\n      <td>0.999841</td>\n      <td>1.000000</td>\n      <td>0.999921</td>\n      <td>0.952139</td>\n      <td>0.758621</td>\n      <td>0.437086</td>\n      <td>0.554622</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.964298</td>\n      <td>0.944371</td>\n      <td>0.506033</td>\n      <td>0.658965</td>\n      <td>0.948301</td>\n      <td>0.753472</td>\n      <td>0.359272</td>\n      <td>0.486547</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.936191</td>\n      <td>0.736842</td>\n      <td>0.099361</td>\n      <td>0.175109</td>\n      <td>0.936787</td>\n      <td>0.744444</td>\n      <td>0.110927</td>\n      <td>0.193084</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.998772</td>\n      <td>1.000000</td>\n      <td>0.997545</td>\n      <td>0.998771</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997668</td>\n      <td>1.000000</td>\n      <td>0.995335</td>\n      <td>0.997662</td>\n      <td>0.986471</td>\n      <td>0.700000</td>\n      <td>0.250000</td>\n      <td>0.368421</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.978325</td>\n      <td>0.993096</td>\n      <td>0.963348</td>\n      <td>0.977996</td>\n      <td>0.945818</td>\n      <td>0.676136</td>\n      <td>0.394040</td>\n      <td>0.497908</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.992265</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.985344</td>\n      <td>0.666667</td>\n      <td>0.142857</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.968824</td>\n      <td>0.990951</td>\n      <td>0.945645</td>\n      <td>0.967768</td>\n      <td>0.945705</td>\n      <td>0.659740</td>\n      <td>0.420530</td>\n      <td>0.513650</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.970642</td>\n      <td>0.991115</td>\n      <td>0.949798</td>\n      <td>0.970017</td>\n      <td>0.944689</td>\n      <td>0.646907</td>\n      <td>0.415563</td>\n      <td>0.506048</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.977001</td>\n      <td>0.984957</td>\n      <td>0.968799</td>\n      <td>0.976811</td>\n      <td>0.944237</td>\n      <td>0.626147</td>\n      <td>0.451987</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.970135</td>\n      <td>0.978473</td>\n      <td>0.960797</td>\n      <td>0.969554</td>\n      <td>0.940738</td>\n      <td>0.572212</td>\n      <td>0.518212</td>\n      <td>0.543875</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969707</td>\n      <td>0.979033</td>\n      <td>0.959973</td>\n      <td>0.969409</td>\n      <td>0.940400</td>\n      <td>0.571161</td>\n      <td>0.504967</td>\n      <td>0.536028</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.857965</td>\n      <td>0.324281</td>\n      <td>1.000000</td>\n      <td>0.489746</td>\n      <td>0.817022</td>\n      <td>0.248889</td>\n      <td>0.834437</td>\n      <td>0.383416</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.767002</td>\n      <td>0.981834</td>\n      <td>0.544071</td>\n      <td>0.700158</td>\n      <td>0.975761</td>\n      <td>0.222222</td>\n      <td>0.214286</td>\n      <td>0.218182</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.719425</td>\n      <td>0.977540</td>\n      <td>0.449030</td>\n      <td>0.615385</td>\n      <td>0.971815</td>\n      <td>0.176471</td>\n      <td>0.214286</td>\n      <td>0.193548</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.940778</td>\n      <td>0.207120</td>\n      <td>1.000000</td>\n      <td>0.343164</td>\n      <td>0.937430</td>\n      <td>0.119266</td>\n      <td>0.464286</td>\n      <td>0.189781</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.708349</td>\n      <td>0.678550</td>\n      <td>0.780462</td>\n      <td>0.725947</td>\n      <td>0.641946</td>\n      <td>0.116716</td>\n      <td>0.647351</td>\n      <td>0.197774</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.715891</td>\n      <td>0.686371</td>\n      <td>0.795089</td>\n      <td>0.736741</td>\n      <td>0.639914</td>\n      <td>0.114030</td>\n      <td>0.632450</td>\n      <td>0.193222</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.713296</td>\n      <td>0.664914</td>\n      <td>0.859983</td>\n      <td>0.749972</td>\n      <td>0.576363</td>\n      <td>0.107063</td>\n      <td>0.710265</td>\n      <td>0.186077</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.924464</td>\n      <td>0.092308</td>\n      <td>0.428571</td>\n      <td>0.151899</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998118</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.230500</td>\n      <td>0.079350</td>\n      <td>0.970199</td>\n      <td>0.146702</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.743187</td>\n      <td>0.931967</td>\n      <td>0.524675</td>\n      <td>0.671379</td>\n      <td>0.950958</td>\n      <td>0.072464</td>\n      <td>0.178571</td>\n      <td>0.103093</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.966123</td>\n      <td>0.969508</td>\n      <td>0.992903</td>\n      <td>0.981066</td>\n      <td>0.137600</td>\n      <td>0.070976</td>\n      <td>0.963576</td>\n      <td>0.132213</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.971142</td>\n      <td>0.975576</td>\n      <td>0.992193</td>\n      <td>0.983814</td>\n      <td>0.138052</td>\n      <td>0.070801</td>\n      <td>0.960265</td>\n      <td>0.131878</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.891468</td>\n      <td>0.891635</td>\n      <td>0.998581</td>\n      <td>0.942082</td>\n      <td>0.072017</td>\n      <td>0.068148</td>\n      <td>0.995033</td>\n      <td>0.127560</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.570312</td>\n      <td>0.846154</td>\n      <td>0.171875</td>\n      <td>0.285714</td>\n      <td>0.967869</td>\n      <td>0.032258</td>\n      <td>0.035714</td>\n      <td>0.033898</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.789062</td>\n      <td>0.877551</td>\n      <td>0.671875</td>\n      <td>0.761062</td>\n      <td>0.757046</td>\n      <td>0.030303</td>\n      <td>0.464286</td>\n      <td>0.056893</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.985738</td>\n      <td>1.000000</td>\n      <td>0.078125</td>\n      <td>0.144928</td>\n      <td>0.983653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.431043400Z",
     "start_time": "2024-11-14T16:27:53.167970Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n34    CatBoostClassifier          NearMiss base   0.891468    0.891635   \n8           RandomForest          NearMiss base   0.998118    1.000000   \n22         XGBClassifier          NearMiss base   0.966123    0.969508   \n46        LGBMClassifier          NearMiss base   0.971142    0.975576   \n12  BalancedRandomForest          BALANCED base   0.857965    0.324281   \n30    CatBoostClassifier   BorderlineSMOTE base   0.713296    0.664914   \n32    CatBoostClassifier            ADASYN base   0.708349    0.678550   \n28    CatBoostClassifier             SMOTE base   0.715891    0.686371   \n44        LGBMClassifier            ADASYN base   0.970135    0.978473   \n40        LGBMClassifier             SMOTE base   0.969707    0.979033   \n23         XGBClassifier         NearMiss clean   0.789062    0.877551   \n13  BalancedRandomForest         BALANCED clean   0.940778    0.207120   \n42        LGBMClassifier   BorderlineSMOTE base   0.977001    0.984957   \n6           RandomForest            ADASYN base   0.999921    0.999841   \n9           RandomForest         NearMiss clean   1.000000    1.000000   \n2           RandomForest             SMOTE base   0.999922    0.999948   \n20         XGBClassifier            ADASYN base   0.968824    0.990951   \n16         XGBClassifier             SMOTE base   0.970642    0.991115   \n0           RandomForest                   base   0.999855    1.000000   \n18         XGBClassifier   BorderlineSMOTE base   0.978325    0.993096   \n38        LGBMClassifier                   base   0.964298    0.944371   \n14         XGBClassifier                   base   0.965120    0.972527   \n4           RandomForest   BorderlineSMOTE base   0.999922    1.000000   \n41        LGBMClassifier            SMOTE clean   1.000000    1.000000   \n21         XGBClassifier           ADASYN clean   0.998527    1.000000   \n17         XGBClassifier            SMOTE clean   0.998772    1.000000   \n43        LGBMClassifier  BorderlineSMOTE clean   1.000000    1.000000   \n45        LGBMClassifier           ADASYN clean   1.000000    1.000000   \n7           RandomForest           ADASYN clean   1.000000    1.000000   \n3           RandomForest            SMOTE clean   1.000000    1.000000   \n5           RandomForest  BorderlineSMOTE clean   1.000000    1.000000   \n19         XGBClassifier  BorderlineSMOTE clean   0.997668    1.000000   \n31    CatBoostClassifier  BorderlineSMOTE clean   0.767002    0.981834   \n33    CatBoostClassifier           ADASYN clean   0.719425    0.977540   \n11          RandomForest        TomekLink clean   1.000000    1.000000   \n29    CatBoostClassifier            SMOTE clean   0.743187    0.931967   \n10          RandomForest         TomekLink base   0.999758    1.000000   \n1           RandomForest                  clean   1.000000    1.000000   \n15         XGBClassifier                  clean   0.992265    1.000000   \n26    CatBoostClassifier                   base   0.936191    0.736842   \n25         XGBClassifier        TomekLink clean   0.992259    1.000000   \n24         XGBClassifier         TomekLink base   0.992259    1.000000   \n39        LGBMClassifier                  clean   0.999758    1.000000   \n48        LGBMClassifier         TomekLink base   0.999758    0.984615   \n49        LGBMClassifier        TomekLink clean   0.999758    0.984615   \n35    CatBoostClassifier         NearMiss clean   0.570312    0.846154   \n37    CatBoostClassifier        TomekLink clean   0.985728    0.857143   \n36    CatBoostClassifier         TomekLink base   0.985728    0.857143   \n27    CatBoostClassifier                  clean   0.985738    1.000000   \n47        LGBMClassifier         NearMiss clean   0.500000    0.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n34   0.998581  0.942082  0.072017   0.068148  0.995033  0.127560  \n8    0.997871  0.998934  0.230500   0.079350  0.970199  0.146702  \n22   0.992903  0.981066  0.137600   0.070976  0.963576  0.132213  \n46   0.992193  0.983814  0.138052   0.070801  0.960265  0.131878  \n12   1.000000  0.489746  0.817022   0.248889  0.834437  0.383416  \n30   0.859983  0.749972  0.576363   0.107063  0.710265  0.186077  \n32   0.780462  0.725947  0.641946   0.116716  0.647351  0.197774  \n28   0.795089  0.736741  0.639914   0.114030  0.632450  0.193222  \n44   0.960797  0.969554  0.940738   0.572212  0.518212  0.543875  \n40   0.959973  0.969409  0.940400   0.571161  0.504967  0.536028  \n23   0.671875  0.761062  0.757046   0.030303  0.464286  0.056893  \n13   1.000000  0.343164  0.937430   0.119266  0.464286  0.189781  \n42   0.968799  0.976811  0.944237   0.626147  0.451987  0.525000  \n6    1.000000  0.999921  0.952139   0.758621  0.437086  0.554622  \n9    1.000000  1.000000  0.924464   0.092308  0.428571  0.151899  \n2    0.999896  0.999922  0.953042   0.786585  0.427152  0.553648  \n20   0.945645  0.967768  0.945705   0.659740  0.420530  0.513650  \n16   0.949798  0.970017  0.944689   0.646907  0.415563  0.506048  \n0    0.997871  0.998934  0.955977   0.882143  0.408940  0.558824  \n18   0.963348  0.977996  0.945818   0.676136  0.394040  0.497908  \n38   0.506033  0.658965  0.948301   0.753472  0.359272  0.486547  \n14   0.502484  0.662611  0.951010   0.824427  0.357616  0.498845  \n4    0.999844  0.999922  0.950897   0.856540  0.336093  0.482759  \n41   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n21   0.997052  0.998524  0.988162   0.818182  0.321429  0.461538  \n17   0.997545  0.998771  0.987035   0.727273  0.285714  0.410256  \n43   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n45   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n7    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n3    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n5    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n19   0.995335  0.997662  0.986471   0.700000  0.250000  0.368421  \n31   0.544071  0.700158  0.975761   0.222222  0.214286  0.218182  \n33   0.449030  0.615385  0.971815   0.176471  0.214286  0.193548  \n11   1.000000  1.000000  0.987035   1.000000  0.178571  0.303030  \n29   0.524675  0.671379  0.950958   0.072464  0.178571  0.103093  \n10   0.984375  0.992126  0.985908   0.800000  0.142857  0.242424  \n1    1.000000  1.000000  0.986471   1.000000  0.142857  0.250000  \n15   0.500000  0.666667  0.985344   0.666667  0.142857  0.235294  \n26   0.099361  0.175109  0.936787   0.744444  0.110927  0.193084  \n25   0.500000  0.666667  0.984780   0.600000  0.107143  0.181818  \n24   0.500000  0.666667  0.984780   0.600000  0.107143  0.181818  \n39   0.984375  0.992126  0.981398   0.222222  0.071429  0.108108  \n48   1.000000  0.992248  0.981398   0.222222  0.071429  0.108108  \n49   1.000000  0.992248  0.981398   0.222222  0.071429  0.108108  \n35   0.171875  0.285714  0.967869   0.032258  0.035714  0.033898  \n37   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n36   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n27   0.078125  0.144928  0.983653   0.000000  0.000000  0.000000  \n47   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.891468</td>\n      <td>0.891635</td>\n      <td>0.998581</td>\n      <td>0.942082</td>\n      <td>0.072017</td>\n      <td>0.068148</td>\n      <td>0.995033</td>\n      <td>0.127560</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998118</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.230500</td>\n      <td>0.079350</td>\n      <td>0.970199</td>\n      <td>0.146702</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.966123</td>\n      <td>0.969508</td>\n      <td>0.992903</td>\n      <td>0.981066</td>\n      <td>0.137600</td>\n      <td>0.070976</td>\n      <td>0.963576</td>\n      <td>0.132213</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.971142</td>\n      <td>0.975576</td>\n      <td>0.992193</td>\n      <td>0.983814</td>\n      <td>0.138052</td>\n      <td>0.070801</td>\n      <td>0.960265</td>\n      <td>0.131878</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.857965</td>\n      <td>0.324281</td>\n      <td>1.000000</td>\n      <td>0.489746</td>\n      <td>0.817022</td>\n      <td>0.248889</td>\n      <td>0.834437</td>\n      <td>0.383416</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.713296</td>\n      <td>0.664914</td>\n      <td>0.859983</td>\n      <td>0.749972</td>\n      <td>0.576363</td>\n      <td>0.107063</td>\n      <td>0.710265</td>\n      <td>0.186077</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.708349</td>\n      <td>0.678550</td>\n      <td>0.780462</td>\n      <td>0.725947</td>\n      <td>0.641946</td>\n      <td>0.116716</td>\n      <td>0.647351</td>\n      <td>0.197774</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.715891</td>\n      <td>0.686371</td>\n      <td>0.795089</td>\n      <td>0.736741</td>\n      <td>0.639914</td>\n      <td>0.114030</td>\n      <td>0.632450</td>\n      <td>0.193222</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.970135</td>\n      <td>0.978473</td>\n      <td>0.960797</td>\n      <td>0.969554</td>\n      <td>0.940738</td>\n      <td>0.572212</td>\n      <td>0.518212</td>\n      <td>0.543875</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969707</td>\n      <td>0.979033</td>\n      <td>0.959973</td>\n      <td>0.969409</td>\n      <td>0.940400</td>\n      <td>0.571161</td>\n      <td>0.504967</td>\n      <td>0.536028</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.789062</td>\n      <td>0.877551</td>\n      <td>0.671875</td>\n      <td>0.761062</td>\n      <td>0.757046</td>\n      <td>0.030303</td>\n      <td>0.464286</td>\n      <td>0.056893</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.940778</td>\n      <td>0.207120</td>\n      <td>1.000000</td>\n      <td>0.343164</td>\n      <td>0.937430</td>\n      <td>0.119266</td>\n      <td>0.464286</td>\n      <td>0.189781</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.977001</td>\n      <td>0.984957</td>\n      <td>0.968799</td>\n      <td>0.976811</td>\n      <td>0.944237</td>\n      <td>0.626147</td>\n      <td>0.451987</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999921</td>\n      <td>0.999841</td>\n      <td>1.000000</td>\n      <td>0.999921</td>\n      <td>0.952139</td>\n      <td>0.758621</td>\n      <td>0.437086</td>\n      <td>0.554622</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.924464</td>\n      <td>0.092308</td>\n      <td>0.428571</td>\n      <td>0.151899</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999922</td>\n      <td>0.999948</td>\n      <td>0.999896</td>\n      <td>0.999922</td>\n      <td>0.953042</td>\n      <td>0.786585</td>\n      <td>0.427152</td>\n      <td>0.553648</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.968824</td>\n      <td>0.990951</td>\n      <td>0.945645</td>\n      <td>0.967768</td>\n      <td>0.945705</td>\n      <td>0.659740</td>\n      <td>0.420530</td>\n      <td>0.513650</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.970642</td>\n      <td>0.991115</td>\n      <td>0.949798</td>\n      <td>0.970017</td>\n      <td>0.944689</td>\n      <td>0.646907</td>\n      <td>0.415563</td>\n      <td>0.506048</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.955977</td>\n      <td>0.882143</td>\n      <td>0.408940</td>\n      <td>0.558824</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.978325</td>\n      <td>0.993096</td>\n      <td>0.963348</td>\n      <td>0.977996</td>\n      <td>0.945818</td>\n      <td>0.676136</td>\n      <td>0.394040</td>\n      <td>0.497908</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.964298</td>\n      <td>0.944371</td>\n      <td>0.506033</td>\n      <td>0.658965</td>\n      <td>0.948301</td>\n      <td>0.753472</td>\n      <td>0.359272</td>\n      <td>0.486547</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.965120</td>\n      <td>0.972527</td>\n      <td>0.502484</td>\n      <td>0.662611</td>\n      <td>0.951010</td>\n      <td>0.824427</td>\n      <td>0.357616</td>\n      <td>0.498845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.950897</td>\n      <td>0.856540</td>\n      <td>0.336093</td>\n      <td>0.482759</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.998527</td>\n      <td>1.000000</td>\n      <td>0.997052</td>\n      <td>0.998524</td>\n      <td>0.988162</td>\n      <td>0.818182</td>\n      <td>0.321429</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.998772</td>\n      <td>1.000000</td>\n      <td>0.997545</td>\n      <td>0.998771</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997668</td>\n      <td>1.000000</td>\n      <td>0.995335</td>\n      <td>0.997662</td>\n      <td>0.986471</td>\n      <td>0.700000</td>\n      <td>0.250000</td>\n      <td>0.368421</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.767002</td>\n      <td>0.981834</td>\n      <td>0.544071</td>\n      <td>0.700158</td>\n      <td>0.975761</td>\n      <td>0.222222</td>\n      <td>0.214286</td>\n      <td>0.218182</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.719425</td>\n      <td>0.977540</td>\n      <td>0.449030</td>\n      <td>0.615385</td>\n      <td>0.971815</td>\n      <td>0.176471</td>\n      <td>0.214286</td>\n      <td>0.193548</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>1.000000</td>\n      <td>0.178571</td>\n      <td>0.303030</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.743187</td>\n      <td>0.931967</td>\n      <td>0.524675</td>\n      <td>0.671379</td>\n      <td>0.950958</td>\n      <td>0.072464</td>\n      <td>0.178571</td>\n      <td>0.103093</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.985908</td>\n      <td>0.800000</td>\n      <td>0.142857</td>\n      <td>0.242424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.986471</td>\n      <td>1.000000</td>\n      <td>0.142857</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.992265</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.985344</td>\n      <td>0.666667</td>\n      <td>0.142857</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.936191</td>\n      <td>0.736842</td>\n      <td>0.099361</td>\n      <td>0.175109</td>\n      <td>0.936787</td>\n      <td>0.744444</td>\n      <td>0.110927</td>\n      <td>0.193084</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.570312</td>\n      <td>0.846154</td>\n      <td>0.171875</td>\n      <td>0.285714</td>\n      <td>0.967869</td>\n      <td>0.032258</td>\n      <td>0.035714</td>\n      <td>0.033898</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.985738</td>\n      <td>1.000000</td>\n      <td>0.078125</td>\n      <td>0.144928</td>\n      <td>0.983653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.468832300Z",
     "start_time": "2024-11-14T16:27:53.230471100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model                variant  train_acc  train_prec  \\\n0           RandomForest                   base   0.999855    1.000000   \n6           RandomForest            ADASYN base   0.999921    0.999841   \n2           RandomForest             SMOTE base   0.999922    0.999948   \n44        LGBMClassifier            ADASYN base   0.970135    0.978473   \n40        LGBMClassifier             SMOTE base   0.969707    0.979033   \n42        LGBMClassifier   BorderlineSMOTE base   0.977001    0.984957   \n20         XGBClassifier            ADASYN base   0.968824    0.990951   \n16         XGBClassifier             SMOTE base   0.970642    0.991115   \n14         XGBClassifier                   base   0.965120    0.972527   \n18         XGBClassifier   BorderlineSMOTE base   0.978325    0.993096   \n38        LGBMClassifier                   base   0.964298    0.944371   \n4           RandomForest   BorderlineSMOTE base   0.999922    1.000000   \n21         XGBClassifier           ADASYN clean   0.998527    1.000000   \n41        LGBMClassifier            SMOTE clean   1.000000    1.000000   \n45        LGBMClassifier           ADASYN clean   1.000000    1.000000   \n43        LGBMClassifier  BorderlineSMOTE clean   1.000000    1.000000   \n17         XGBClassifier            SMOTE clean   0.998772    1.000000   \n7           RandomForest           ADASYN clean   1.000000    1.000000   \n3           RandomForest            SMOTE clean   1.000000    1.000000   \n5           RandomForest  BorderlineSMOTE clean   1.000000    1.000000   \n12  BalancedRandomForest          BALANCED base   0.857965    0.324281   \n19         XGBClassifier  BorderlineSMOTE clean   0.997668    1.000000   \n11          RandomForest        TomekLink clean   1.000000    1.000000   \n1           RandomForest                  clean   1.000000    1.000000   \n10          RandomForest         TomekLink base   0.999758    1.000000   \n15         XGBClassifier                  clean   0.992265    1.000000   \n31    CatBoostClassifier  BorderlineSMOTE clean   0.767002    0.981834   \n32    CatBoostClassifier            ADASYN base   0.708349    0.678550   \n33    CatBoostClassifier           ADASYN clean   0.719425    0.977540   \n28    CatBoostClassifier             SMOTE base   0.715891    0.686371   \n26    CatBoostClassifier                   base   0.936191    0.736842   \n13  BalancedRandomForest         BALANCED clean   0.940778    0.207120   \n30    CatBoostClassifier   BorderlineSMOTE base   0.713296    0.664914   \n25         XGBClassifier        TomekLink clean   0.992259    1.000000   \n24         XGBClassifier         TomekLink base   0.992259    1.000000   \n9           RandomForest         NearMiss clean   1.000000    1.000000   \n8           RandomForest          NearMiss base   0.998118    1.000000   \n22         XGBClassifier          NearMiss base   0.966123    0.969508   \n46        LGBMClassifier          NearMiss base   0.971142    0.975576   \n34    CatBoostClassifier          NearMiss base   0.891468    0.891635   \n39        LGBMClassifier                  clean   0.999758    1.000000   \n48        LGBMClassifier         TomekLink base   0.999758    0.984615   \n49        LGBMClassifier        TomekLink clean   0.999758    0.984615   \n29    CatBoostClassifier            SMOTE clean   0.743187    0.931967   \n23         XGBClassifier         NearMiss clean   0.789062    0.877551   \n35    CatBoostClassifier         NearMiss clean   0.570312    0.846154   \n36    CatBoostClassifier         TomekLink base   0.985728    0.857143   \n37    CatBoostClassifier        TomekLink clean   0.985728    0.857143   \n27    CatBoostClassifier                  clean   0.985738    1.000000   \n47        LGBMClassifier         NearMiss clean   0.500000    0.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n0    0.997871  0.998934  0.955977   0.882143  0.408940  0.558824  \n6    1.000000  0.999921  0.952139   0.758621  0.437086  0.554622  \n2    0.999896  0.999922  0.953042   0.786585  0.427152  0.553648  \n44   0.960797  0.969554  0.940738   0.572212  0.518212  0.543875  \n40   0.959973  0.969409  0.940400   0.571161  0.504967  0.536028  \n42   0.968799  0.976811  0.944237   0.626147  0.451987  0.525000  \n20   0.945645  0.967768  0.945705   0.659740  0.420530  0.513650  \n16   0.949798  0.970017  0.944689   0.646907  0.415563  0.506048  \n14   0.502484  0.662611  0.951010   0.824427  0.357616  0.498845  \n18   0.963348  0.977996  0.945818   0.676136  0.394040  0.497908  \n38   0.506033  0.658965  0.948301   0.753472  0.359272  0.486547  \n4    0.999844  0.999922  0.950897   0.856540  0.336093  0.482759  \n21   0.997052  0.998524  0.988162   0.818182  0.321429  0.461538  \n41   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n45   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n43   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n17   0.997545  0.998771  0.987035   0.727273  0.285714  0.410256  \n7    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n3    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n5    1.000000  1.000000  0.988162   1.000000  0.250000  0.400000  \n12   1.000000  0.489746  0.817022   0.248889  0.834437  0.383416  \n19   0.995335  0.997662  0.986471   0.700000  0.250000  0.368421  \n11   1.000000  1.000000  0.987035   1.000000  0.178571  0.303030  \n1    1.000000  1.000000  0.986471   1.000000  0.142857  0.250000  \n10   0.984375  0.992126  0.985908   0.800000  0.142857  0.242424  \n15   0.500000  0.666667  0.985344   0.666667  0.142857  0.235294  \n31   0.544071  0.700158  0.975761   0.222222  0.214286  0.218182  \n32   0.780462  0.725947  0.641946   0.116716  0.647351  0.197774  \n33   0.449030  0.615385  0.971815   0.176471  0.214286  0.193548  \n28   0.795089  0.736741  0.639914   0.114030  0.632450  0.193222  \n26   0.099361  0.175109  0.936787   0.744444  0.110927  0.193084  \n13   1.000000  0.343164  0.937430   0.119266  0.464286  0.189781  \n30   0.859983  0.749972  0.576363   0.107063  0.710265  0.186077  \n25   0.500000  0.666667  0.984780   0.600000  0.107143  0.181818  \n24   0.500000  0.666667  0.984780   0.600000  0.107143  0.181818  \n9    1.000000  1.000000  0.924464   0.092308  0.428571  0.151899  \n8    0.997871  0.998934  0.230500   0.079350  0.970199  0.146702  \n22   0.992903  0.981066  0.137600   0.070976  0.963576  0.132213  \n46   0.992193  0.983814  0.138052   0.070801  0.960265  0.131878  \n34   0.998581  0.942082  0.072017   0.068148  0.995033  0.127560  \n39   0.984375  0.992126  0.981398   0.222222  0.071429  0.108108  \n48   1.000000  0.992248  0.981398   0.222222  0.071429  0.108108  \n49   1.000000  0.992248  0.981398   0.222222  0.071429  0.108108  \n29   0.524675  0.671379  0.950958   0.072464  0.178571  0.103093  \n23   0.671875  0.761062  0.757046   0.030303  0.464286  0.056893  \n35   0.171875  0.285714  0.967869   0.032258  0.035714  0.033898  \n36   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n37   0.093750  0.169014  0.983089   0.000000  0.000000  0.000000  \n27   0.078125  0.144928  0.983653   0.000000  0.000000  0.000000  \n47   0.000000  0.000000  0.984216   0.000000  0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999855</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.955977</td>\n      <td>0.882143</td>\n      <td>0.408940</td>\n      <td>0.558824</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999921</td>\n      <td>0.999841</td>\n      <td>1.000000</td>\n      <td>0.999921</td>\n      <td>0.952139</td>\n      <td>0.758621</td>\n      <td>0.437086</td>\n      <td>0.554622</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999922</td>\n      <td>0.999948</td>\n      <td>0.999896</td>\n      <td>0.999922</td>\n      <td>0.953042</td>\n      <td>0.786585</td>\n      <td>0.427152</td>\n      <td>0.553648</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.970135</td>\n      <td>0.978473</td>\n      <td>0.960797</td>\n      <td>0.969554</td>\n      <td>0.940738</td>\n      <td>0.572212</td>\n      <td>0.518212</td>\n      <td>0.543875</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.969707</td>\n      <td>0.979033</td>\n      <td>0.959973</td>\n      <td>0.969409</td>\n      <td>0.940400</td>\n      <td>0.571161</td>\n      <td>0.504967</td>\n      <td>0.536028</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.977001</td>\n      <td>0.984957</td>\n      <td>0.968799</td>\n      <td>0.976811</td>\n      <td>0.944237</td>\n      <td>0.626147</td>\n      <td>0.451987</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.968824</td>\n      <td>0.990951</td>\n      <td>0.945645</td>\n      <td>0.967768</td>\n      <td>0.945705</td>\n      <td>0.659740</td>\n      <td>0.420530</td>\n      <td>0.513650</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.970642</td>\n      <td>0.991115</td>\n      <td>0.949798</td>\n      <td>0.970017</td>\n      <td>0.944689</td>\n      <td>0.646907</td>\n      <td>0.415563</td>\n      <td>0.506048</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.965120</td>\n      <td>0.972527</td>\n      <td>0.502484</td>\n      <td>0.662611</td>\n      <td>0.951010</td>\n      <td>0.824427</td>\n      <td>0.357616</td>\n      <td>0.498845</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.978325</td>\n      <td>0.993096</td>\n      <td>0.963348</td>\n      <td>0.977996</td>\n      <td>0.945818</td>\n      <td>0.676136</td>\n      <td>0.394040</td>\n      <td>0.497908</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LGBMClassifier</td>\n      <td>base</td>\n      <td>0.964298</td>\n      <td>0.944371</td>\n      <td>0.506033</td>\n      <td>0.658965</td>\n      <td>0.948301</td>\n      <td>0.753472</td>\n      <td>0.359272</td>\n      <td>0.486547</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999922</td>\n      <td>1.000000</td>\n      <td>0.999844</td>\n      <td>0.999922</td>\n      <td>0.950897</td>\n      <td>0.856540</td>\n      <td>0.336093</td>\n      <td>0.482759</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>XGBClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.998527</td>\n      <td>1.000000</td>\n      <td>0.997052</td>\n      <td>0.998524</td>\n      <td>0.988162</td>\n      <td>0.818182</td>\n      <td>0.321429</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LGBMClassifier</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>LGBMClassifier</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>LGBMClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.998772</td>\n      <td>1.000000</td>\n      <td>0.997545</td>\n      <td>0.998771</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988162</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED base</td>\n      <td>0.857965</td>\n      <td>0.324281</td>\n      <td>1.000000</td>\n      <td>0.489746</td>\n      <td>0.817022</td>\n      <td>0.248889</td>\n      <td>0.834437</td>\n      <td>0.383416</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.997668</td>\n      <td>1.000000</td>\n      <td>0.995335</td>\n      <td>0.997662</td>\n      <td>0.986471</td>\n      <td>0.700000</td>\n      <td>0.250000</td>\n      <td>0.368421</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandomForest</td>\n      <td>TomekLink clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>1.000000</td>\n      <td>0.178571</td>\n      <td>0.303030</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.986471</td>\n      <td>1.000000</td>\n      <td>0.142857</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForest</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.985908</td>\n      <td>0.800000</td>\n      <td>0.142857</td>\n      <td>0.242424</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBClassifier</td>\n      <td>clean</td>\n      <td>0.992265</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.985344</td>\n      <td>0.666667</td>\n      <td>0.142857</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.767002</td>\n      <td>0.981834</td>\n      <td>0.544071</td>\n      <td>0.700158</td>\n      <td>0.975761</td>\n      <td>0.222222</td>\n      <td>0.214286</td>\n      <td>0.218182</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN base</td>\n      <td>0.708349</td>\n      <td>0.678550</td>\n      <td>0.780462</td>\n      <td>0.725947</td>\n      <td>0.641946</td>\n      <td>0.116716</td>\n      <td>0.647351</td>\n      <td>0.197774</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>CatBoostClassifier</td>\n      <td>ADASYN clean</td>\n      <td>0.719425</td>\n      <td>0.977540</td>\n      <td>0.449030</td>\n      <td>0.615385</td>\n      <td>0.971815</td>\n      <td>0.176471</td>\n      <td>0.214286</td>\n      <td>0.193548</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE base</td>\n      <td>0.715891</td>\n      <td>0.686371</td>\n      <td>0.795089</td>\n      <td>0.736741</td>\n      <td>0.639914</td>\n      <td>0.114030</td>\n      <td>0.632450</td>\n      <td>0.193222</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>CatBoostClassifier</td>\n      <td>base</td>\n      <td>0.936191</td>\n      <td>0.736842</td>\n      <td>0.099361</td>\n      <td>0.175109</td>\n      <td>0.936787</td>\n      <td>0.744444</td>\n      <td>0.110927</td>\n      <td>0.193084</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BalancedRandomForest</td>\n      <td>BALANCED clean</td>\n      <td>0.940778</td>\n      <td>0.207120</td>\n      <td>1.000000</td>\n      <td>0.343164</td>\n      <td>0.937430</td>\n      <td>0.119266</td>\n      <td>0.464286</td>\n      <td>0.189781</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>CatBoostClassifier</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.713296</td>\n      <td>0.664914</td>\n      <td>0.859983</td>\n      <td>0.749972</td>\n      <td>0.576363</td>\n      <td>0.107063</td>\n      <td>0.710265</td>\n      <td>0.186077</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.992259</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.984780</td>\n      <td>0.600000</td>\n      <td>0.107143</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.924464</td>\n      <td>0.092308</td>\n      <td>0.428571</td>\n      <td>0.151899</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998118</td>\n      <td>1.000000</td>\n      <td>0.997871</td>\n      <td>0.998934</td>\n      <td>0.230500</td>\n      <td>0.079350</td>\n      <td>0.970199</td>\n      <td>0.146702</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.966123</td>\n      <td>0.969508</td>\n      <td>0.992903</td>\n      <td>0.981066</td>\n      <td>0.137600</td>\n      <td>0.070976</td>\n      <td>0.963576</td>\n      <td>0.132213</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.971142</td>\n      <td>0.975576</td>\n      <td>0.992193</td>\n      <td>0.983814</td>\n      <td>0.138052</td>\n      <td>0.070801</td>\n      <td>0.960265</td>\n      <td>0.131878</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss base</td>\n      <td>0.891468</td>\n      <td>0.891635</td>\n      <td>0.998581</td>\n      <td>0.942082</td>\n      <td>0.072017</td>\n      <td>0.068148</td>\n      <td>0.995033</td>\n      <td>0.127560</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LGBMClassifier</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>1.000000</td>\n      <td>0.984375</td>\n      <td>0.992126</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>LGBMClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.981398</td>\n      <td>0.222222</td>\n      <td>0.071429</td>\n      <td>0.108108</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>CatBoostClassifier</td>\n      <td>SMOTE clean</td>\n      <td>0.743187</td>\n      <td>0.931967</td>\n      <td>0.524675</td>\n      <td>0.671379</td>\n      <td>0.950958</td>\n      <td>0.072464</td>\n      <td>0.178571</td>\n      <td>0.103093</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>XGBClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.789062</td>\n      <td>0.877551</td>\n      <td>0.671875</td>\n      <td>0.761062</td>\n      <td>0.757046</td>\n      <td>0.030303</td>\n      <td>0.464286</td>\n      <td>0.056893</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>CatBoostClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.570312</td>\n      <td>0.846154</td>\n      <td>0.171875</td>\n      <td>0.285714</td>\n      <td>0.967869</td>\n      <td>0.032258</td>\n      <td>0.035714</td>\n      <td>0.033898</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink base</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>CatBoostClassifier</td>\n      <td>TomekLink clean</td>\n      <td>0.985728</td>\n      <td>0.857143</td>\n      <td>0.093750</td>\n      <td>0.169014</td>\n      <td>0.983089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>CatBoostClassifier</td>\n      <td>clean</td>\n      <td>0.985738</td>\n      <td>1.000000</td>\n      <td>0.078125</td>\n      <td>0.144928</td>\n      <td>0.983653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LGBMClassifier</td>\n      <td>NearMiss clean</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.984216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_f1\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.468832300Z",
     "start_time": "2024-11-14T16:27:53.268254800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Einfache SVM / Bayes-Classifier zum Vergleich"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.1 LinearSVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "svc = LinearSVC()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:53.468832300Z",
     "start_time": "2024-11-14T16:27:53.315127600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LinearSVC BASE started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  LinearSVC CLEAN started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  LinearSVC SMOTE-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "4/12 Fitting:  LinearSVC SMOTE-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  LinearSVC BorderlineSMOTE-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "6/12 Fitting:  LinearSVC BorderlineSMOTE-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  LinearSVC ADASYN-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "8/12 Fitting:  LinearSVC ADASYN-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  LinearSVC NearMiss-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LinearSVC NearMiss-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LinearSVC TomekLink-base started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  LinearSVC TomekLink-clean started...\n",
      "Fitting:  LinearSVC finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(svc, \"LinearSVC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:54.470859900Z",
     "start_time": "2024-11-14T16:27:53.330753600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "        model                variant  train_acc  train_prec  train_rec  \\\n50  LinearSVC                   base   0.980891    0.967712   0.744500   \n51  LinearSVC                  clean   0.998550    1.000000   0.906250   \n53  LinearSVC            SMOTE clean   1.000000    1.000000   1.000000   \n57  LinearSVC           ADASYN clean   1.000000    1.000000   1.000000   \n60  LinearSVC         TomekLink base   0.998549    1.000000   0.906250   \n61  LinearSVC        TomekLink clean   0.998549    1.000000   0.906250   \n55  LinearSVC  BorderlineSMOTE clean   1.000000    1.000000   1.000000   \n54  LinearSVC   BorderlineSMOTE base   0.989747    0.990945   0.988527   \n52  LinearSVC             SMOTE base   0.988449    0.978439   0.998910   \n56  LinearSVC            ADASYN base   0.987939    0.977000   0.999152   \n58  LinearSVC          NearMiss base   0.975533    0.977019   0.995742   \n59  LinearSVC         NearMiss clean   1.000000    1.000000   1.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n50  0.841556  0.957896   0.800000  0.509934  0.622851  \n51  0.950820  0.986471   0.750000  0.214286  0.333333  \n53  1.000000  0.987599   0.750000  0.321429  0.450000  \n57  1.000000  0.987599   0.750000  0.321429  0.450000  \n60  0.950820  0.986471   0.750000  0.214286  0.333333  \n61  0.950820  0.986471   0.750000  0.214286  0.333333  \n55  1.000000  0.987035   0.727273  0.285714  0.410256  \n54  0.989734  0.947285   0.619130  0.589404  0.603902  \n52  0.988568  0.933627   0.509709  0.695364  0.588235  \n56  0.987952  0.933062   0.506587  0.700331  0.587908  \n58  0.986292  0.165594   0.074473  0.983444  0.138462  \n59  1.000000  0.810034   0.054755  0.678571  0.101333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50</th>\n      <td>LinearSVC</td>\n      <td>base</td>\n      <td>0.980891</td>\n      <td>0.967712</td>\n      <td>0.744500</td>\n      <td>0.841556</td>\n      <td>0.957896</td>\n      <td>0.800000</td>\n      <td>0.509934</td>\n      <td>0.622851</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>LinearSVC</td>\n      <td>clean</td>\n      <td>0.998550</td>\n      <td>1.000000</td>\n      <td>0.906250</td>\n      <td>0.950820</td>\n      <td>0.986471</td>\n      <td>0.750000</td>\n      <td>0.214286</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>LinearSVC</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>LinearSVC</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>LinearSVC</td>\n      <td>TomekLink base</td>\n      <td>0.998549</td>\n      <td>1.000000</td>\n      <td>0.906250</td>\n      <td>0.950820</td>\n      <td>0.986471</td>\n      <td>0.750000</td>\n      <td>0.214286</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>LinearSVC</td>\n      <td>TomekLink clean</td>\n      <td>0.998549</td>\n      <td>1.000000</td>\n      <td>0.906250</td>\n      <td>0.950820</td>\n      <td>0.986471</td>\n      <td>0.750000</td>\n      <td>0.214286</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>LinearSVC</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>LinearSVC</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.989747</td>\n      <td>0.990945</td>\n      <td>0.988527</td>\n      <td>0.989734</td>\n      <td>0.947285</td>\n      <td>0.619130</td>\n      <td>0.589404</td>\n      <td>0.603902</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>LinearSVC</td>\n      <td>SMOTE base</td>\n      <td>0.988449</td>\n      <td>0.978439</td>\n      <td>0.998910</td>\n      <td>0.988568</td>\n      <td>0.933627</td>\n      <td>0.509709</td>\n      <td>0.695364</td>\n      <td>0.588235</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>LinearSVC</td>\n      <td>ADASYN base</td>\n      <td>0.987939</td>\n      <td>0.977000</td>\n      <td>0.999152</td>\n      <td>0.987952</td>\n      <td>0.933062</td>\n      <td>0.506587</td>\n      <td>0.700331</td>\n      <td>0.587908</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>LinearSVC</td>\n      <td>NearMiss base</td>\n      <td>0.975533</td>\n      <td>0.977019</td>\n      <td>0.995742</td>\n      <td>0.986292</td>\n      <td>0.165594</td>\n      <td>0.074473</td>\n      <td>0.983444</td>\n      <td>0.138462</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>LinearSVC</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.810034</td>\n      <td>0.054755</td>\n      <td>0.678571</td>\n      <td>0.101333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LinearSVC\"].sort_values(by=[\"test_prec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:54.517735700Z",
     "start_time": "2024-11-14T16:27:54.486485100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "svc = LinearSVC(\n",
    "    class_weight=\"balanced\")  # ohne balanced wird die SVC in einigen Fällen nur auf 0 trainiert, d.h. precision = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:54.571141600Z",
     "start_time": "2024-11-14T16:27:54.502109900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  LinearSVC-balanced BASE started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  LinearSVC-balanced CLEAN started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  LinearSVC-balanced SMOTE-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "4/12 Fitting:  LinearSVC-balanced SMOTE-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  LinearSVC-balanced BorderlineSMOTE-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "6/12 Fitting:  LinearSVC-balanced BorderlineSMOTE-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  LinearSVC-balanced ADASYN-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "8/12 Fitting:  LinearSVC-balanced ADASYN-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  LinearSVC-balanced NearMiss-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  LinearSVC-balanced NearMiss-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  LinearSVC-balanced TomekLink-base started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  LinearSVC-balanced TomekLink-clean started...\n",
      "Fitting:  LinearSVC-balanced finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(svc, \"LinearSVC-balanced\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:55.673389800Z",
     "start_time": "2024-11-14T16:27:54.517735700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "                 model                variant  train_acc  train_prec  \\\n66  LinearSVC-balanced   BorderlineSMOTE base   0.989747    0.990945   \n62  LinearSVC-balanced                   base   0.969619    0.692270   \n64  LinearSVC-balanced             SMOTE base   0.988449    0.978439   \n68  LinearSVC-balanced            ADASYN base   0.987781    0.976597   \n63  LinearSVC-balanced                  clean   0.999758    0.984615   \n65  LinearSVC-balanced            SMOTE clean   1.000000    1.000000   \n69  LinearSVC-balanced           ADASYN clean   1.000000    1.000000   \n72  LinearSVC-balanced         TomekLink base   0.999758    0.984615   \n73  LinearSVC-balanced        TomekLink clean   0.999758    0.984615   \n67  LinearSVC-balanced  BorderlineSMOTE clean   1.000000    1.000000   \n70  LinearSVC-balanced          NearMiss base   0.967378    0.997799   \n71  LinearSVC-balanced         NearMiss clean   1.000000    1.000000   \n\n    train_rec  train_f1  test_acc  test_prec  test_rec   test_f1  \n66   0.988527  0.989734  0.947285   0.619130  0.589404  0.603902  \n62   0.997871  0.817442  0.930128   0.491803  0.745033  0.592495  \n64   0.998910  0.988568  0.933627   0.509709  0.695364  0.588235  \n68   0.999258  0.987798  0.932950   0.505967  0.701987  0.588072  \n63   1.000000  0.992248  0.987599   0.750000  0.321429  0.450000  \n65   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n69   1.000000  1.000000  0.987599   0.750000  0.321429  0.450000  \n72   1.000000  0.992248  0.987599   0.750000  0.321429  0.450000  \n73   1.000000  0.992248  0.987599   0.750000  0.321429  0.450000  \n67   1.000000  1.000000  0.987035   0.727273  0.285714  0.410256  \n70   0.965224  0.981241  0.386274   0.093250  0.917219  0.169290  \n71   1.000000  1.000000  0.810034   0.054755  0.678571  0.101333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>66</th>\n      <td>LinearSVC-balanced</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.989747</td>\n      <td>0.990945</td>\n      <td>0.988527</td>\n      <td>0.989734</td>\n      <td>0.947285</td>\n      <td>0.619130</td>\n      <td>0.589404</td>\n      <td>0.603902</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>LinearSVC-balanced</td>\n      <td>base</td>\n      <td>0.969619</td>\n      <td>0.692270</td>\n      <td>0.997871</td>\n      <td>0.817442</td>\n      <td>0.930128</td>\n      <td>0.491803</td>\n      <td>0.745033</td>\n      <td>0.592495</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>LinearSVC-balanced</td>\n      <td>SMOTE base</td>\n      <td>0.988449</td>\n      <td>0.978439</td>\n      <td>0.998910</td>\n      <td>0.988568</td>\n      <td>0.933627</td>\n      <td>0.509709</td>\n      <td>0.695364</td>\n      <td>0.588235</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>LinearSVC-balanced</td>\n      <td>ADASYN base</td>\n      <td>0.987781</td>\n      <td>0.976597</td>\n      <td>0.999258</td>\n      <td>0.987798</td>\n      <td>0.932950</td>\n      <td>0.505967</td>\n      <td>0.701987</td>\n      <td>0.588072</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>LinearSVC-balanced</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>LinearSVC-balanced</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>LinearSVC-balanced</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>LinearSVC-balanced</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>LinearSVC-balanced</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>LinearSVC-balanced</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>LinearSVC-balanced</td>\n      <td>NearMiss base</td>\n      <td>0.967378</td>\n      <td>0.997799</td>\n      <td>0.965224</td>\n      <td>0.981241</td>\n      <td>0.386274</td>\n      <td>0.093250</td>\n      <td>0.917219</td>\n      <td>0.169290</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>LinearSVC-balanced</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.810034</td>\n      <td>0.054755</td>\n      <td>0.678571</td>\n      <td>0.101333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"LinearSVC-balanced\"].sort_values(by=[\"test_f1\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:55.720265400Z",
     "start_time": "2024-11-14T16:27:55.673389800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2 Bayes-Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:55.836177200Z",
     "start_time": "2024-11-14T16:27:55.704640800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "bayes = GaussianNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:55.905228500Z",
     "start_time": "2024-11-14T16:27:55.735892300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting.\n",
      "1/12 Fitting:  GaussianNB BASE started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "2/12 Fitting:  GaussianNB CLEAN started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "3/12 Fitting:  GaussianNB SMOTE-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "4/12 Fitting:  GaussianNB SMOTE-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "5/12 Fitting:  GaussianNB BorderlineSMOTE-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "6/12 Fitting:  GaussianNB BorderlineSMOTE-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "7/12 Fitting:  GaussianNB ADASYN-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "8/12 Fitting:  GaussianNB ADASYN-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "9/12 Fitting:  GaussianNB NearMiss-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "10/12 Fitting:  GaussianNB NearMiss-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "11/12 Fitting:  GaussianNB TomekLink-base started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "12/12 Fitting:  GaussianNB TomekLink-clean started...\n",
      "Fitting:  GaussianNB finished. Elapsed time:  0 Seconds\n",
      "Model fitting finished.\n"
     ]
    }
   ],
   "source": [
    "fit_model(svc, \"GaussianNB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:56.931960300Z",
     "start_time": "2024-11-14T16:27:55.773674500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "         model                variant  train_acc  train_prec  train_rec  \\\n78  GaussianNB   BorderlineSMOTE base   0.989747    0.990945   0.988527   \n74  GaussianNB                   base   0.969619    0.692270   0.997871   \n76  GaussianNB             SMOTE base   0.988449    0.978439   0.998910   \n80  GaussianNB            ADASYN base   0.987781    0.976597   0.999258   \n75  GaussianNB                  clean   0.999758    0.984615   1.000000   \n77  GaussianNB            SMOTE clean   1.000000    1.000000   1.000000   \n81  GaussianNB           ADASYN clean   1.000000    1.000000   1.000000   \n84  GaussianNB         TomekLink base   0.999758    0.984615   1.000000   \n85  GaussianNB        TomekLink clean   0.999758    0.984615   1.000000   \n79  GaussianNB  BorderlineSMOTE clean   1.000000    1.000000   1.000000   \n82  GaussianNB          NearMiss base   0.967378    0.997799   0.965224   \n83  GaussianNB         NearMiss clean   1.000000    1.000000   1.000000   \n\n    train_f1  test_acc  test_prec  test_rec   test_f1  \n78  0.989734  0.947285   0.619130  0.589404  0.603902  \n74  0.817442  0.930128   0.491803  0.745033  0.592495  \n76  0.988568  0.933627   0.509709  0.695364  0.588235  \n80  0.987798  0.932950   0.505967  0.701987  0.588072  \n75  0.992248  0.987599   0.750000  0.321429  0.450000  \n77  1.000000  0.987599   0.750000  0.321429  0.450000  \n81  1.000000  0.987599   0.750000  0.321429  0.450000  \n84  0.992248  0.987599   0.750000  0.321429  0.450000  \n85  0.992248  0.987599   0.750000  0.321429  0.450000  \n79  1.000000  0.987035   0.727273  0.285714  0.410256  \n82  0.981241  0.386274   0.093250  0.917219  0.169290  \n83  1.000000  0.810034   0.054755  0.678571  0.101333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>78</th>\n      <td>GaussianNB</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.989747</td>\n      <td>0.990945</td>\n      <td>0.988527</td>\n      <td>0.989734</td>\n      <td>0.947285</td>\n      <td>0.619130</td>\n      <td>0.589404</td>\n      <td>0.603902</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>GaussianNB</td>\n      <td>base</td>\n      <td>0.969619</td>\n      <td>0.692270</td>\n      <td>0.997871</td>\n      <td>0.817442</td>\n      <td>0.930128</td>\n      <td>0.491803</td>\n      <td>0.745033</td>\n      <td>0.592495</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>GaussianNB</td>\n      <td>SMOTE base</td>\n      <td>0.988449</td>\n      <td>0.978439</td>\n      <td>0.998910</td>\n      <td>0.988568</td>\n      <td>0.933627</td>\n      <td>0.509709</td>\n      <td>0.695364</td>\n      <td>0.588235</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>GaussianNB</td>\n      <td>ADASYN base</td>\n      <td>0.987781</td>\n      <td>0.976597</td>\n      <td>0.999258</td>\n      <td>0.987798</td>\n      <td>0.932950</td>\n      <td>0.505967</td>\n      <td>0.701987</td>\n      <td>0.588072</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>GaussianNB</td>\n      <td>clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>GaussianNB</td>\n      <td>SMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>GaussianNB</td>\n      <td>ADASYN clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>GaussianNB</td>\n      <td>TomekLink base</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>GaussianNB</td>\n      <td>TomekLink clean</td>\n      <td>0.999758</td>\n      <td>0.984615</td>\n      <td>1.000000</td>\n      <td>0.992248</td>\n      <td>0.987599</td>\n      <td>0.750000</td>\n      <td>0.321429</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>GaussianNB</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987035</td>\n      <td>0.727273</td>\n      <td>0.285714</td>\n      <td>0.410256</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>GaussianNB</td>\n      <td>NearMiss base</td>\n      <td>0.967378</td>\n      <td>0.997799</td>\n      <td>0.965224</td>\n      <td>0.981241</td>\n      <td>0.386274</td>\n      <td>0.093250</td>\n      <td>0.917219</td>\n      <td>0.169290</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>GaussianNB</td>\n      <td>NearMiss clean</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.810034</td>\n      <td>0.054755</td>\n      <td>0.678571</td>\n      <td>0.101333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[evaluation.model == \"GaussianNB\"].sort_values(by=[\"test_f1\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:56.974532300Z",
     "start_time": "2024-11-14T16:27:56.903685900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:27:56.974532300Z",
     "start_time": "2024-11-14T16:27:56.931960300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
