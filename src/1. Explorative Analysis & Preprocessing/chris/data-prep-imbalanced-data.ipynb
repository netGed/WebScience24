{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports & Downloads"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NearMiss, CondensedNearestNeighbour, NeighbourhoodCleaningRule\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Einladen der Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Originaldaten ohne umfassende Vorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet\nid                                                          \n1       0   @user when a father is dysfunctional and is s...\n2       0  @user @user thanks for #lyft credit i can't us...\n3       0                                bihday your majesty\n4       0  #model   i love u take with u all the time in ...\n5       0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_basic_cleaned.csv'))\n",
    "df = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "13.669647292598112"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "positive = len(df[df['label'] == 1])\n",
    "negative = len(df[df['label'] == 0])\n",
    "negative/positive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorverarbeitete Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                              tweet  \\\nid                                                             \n1       0   @user when a father is dysfunctional and is s...   \n2       0  @user @user thanks for #lyft credit i can't us...   \n3       0                                bihday your majesty   \n4       0  #model   i love u take with u all the time in ...   \n5       0             factsguide: society now    #motivation   \n\n                                        tweet_cleaned  user_handle  \\\nid                                                                   \n1                         father selfish drag kid run            1   \n2               thank lyft credit use cause offer van            2   \n3                                      bihday majesty            0   \n4   model take time mobile phone kiss sunglass mou...            0   \n5                       factsguide society motivation            0   \n\n                                    hashtags  \\\nid                                             \n1                                   ['#run']   \n2   ['#lyft', '#disapointed', '#getthanked']   \n3                                         []   \n4                                 ['#model']   \n5                            ['#motivation']   \n\n                                               emojis  \nid                                                     \n1                                                 NaN  \n2                                                 NaN  \n3                                                 NaN  \n4   :mobile_phone:,:kissing_face_with_smiling_eyes...  \n5                                                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_cleaned</th>\n      <th>user_handle</th>\n      <th>hashtags</th>\n      <th>emojis</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n      <td>father selfish drag kid run</td>\n      <td>1</td>\n      <td>['#run']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n      <td>thank lyft credit use cause offer van</td>\n      <td>2</td>\n      <td>['#lyft', '#disapointed', '#getthanked']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>bihday your majesty</td>\n      <td>bihday majesty</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n      <td>model take time mobile phone kiss sunglass mou...</td>\n      <td>0</td>\n      <td>['#model']</td>\n      <td>:mobile_phone:,:kissing_face_with_smiling_eyes...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n      <td>factsguide society motivation</td>\n      <td>0</td>\n      <td>['#motivation']</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "csv_path_train = os.path.abspath(os.path.join(current_dir, '../../../data/twitter_hate-speech/train_cleaned.csv'))\n",
    "df_cleaned = pd.read_csv(csv_path_train, encoding='utf-8', index_col=0)\n",
    "\n",
    "df_cleaned.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "14.26780784097184"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['label'].value_counts()\n",
    "positive = len(df_cleaned[df_cleaned['label'] == 1])\n",
    "negative = len(df_cleaned[df_cleaned['label'] == 0])\n",
    "negative/positive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verh√§ltnis hat sich durch die Bereinigung sogar noch weiter verschlechter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vektorisierung der Daten\n",
    "https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#Unsupervised_text_classification_Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def vectorize(sentence, w2v_model):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def vectorize_df(df):\n",
    "    X = df[\"tweet\"]\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    sentences_base = [sentence.split() for sentence in X]\n",
    "    w2v_model_base = Word2Vec(sentences_base, window=5, min_count=5, workers=-1)\n",
    "\n",
    "    x_data = np.array([vectorize(sentence, w2v_model_base) for sentence in X])\n",
    "    return x_data, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_base, y_base = vectorize_df(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.30374171e-03, -6.65663800e-04,  3.21442029e-03, ...,\n        -2.68328539e-03,  1.41547900e-03, -2.84765265e-03],\n       [ 3.36569443e-04, -9.82483965e-04,  9.05304274e-04, ...,\n        -4.07109677e-04,  5.64215006e-04,  1.94166932e-04],\n       [ 1.23032148e-03, -2.46845209e-03,  2.51201470e-03, ...,\n         2.88697542e-03,  4.11413144e-03,  4.88469563e-03],\n       ...,\n       [-9.87032778e-04,  5.68386691e-04, -1.85755307e-05, ...,\n         3.09016541e-05, -3.14187346e-04, -8.47426010e-04],\n       [ 1.40571001e-03,  4.23042104e-03,  2.36720010e-03, ...,\n        -4.67062840e-04,  2.66610738e-03, -7.61655625e-04],\n       [ 8.88627619e-05, -6.70738227e-04,  2.82955565e-03, ...,\n        -3.34652583e-03,  8.70123040e-04,  3.40033951e-03]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "id\n1        0\n2        0\n3        0\n4        0\n5        0\n        ..\n31957    0\n31958    0\n31959    0\n31960    0\n31962    0\nName: label, Length: 29530, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_clean, y_clean = vectorize_df(df_cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.000164  , -0.00097227,  0.00330843, ..., -0.00523365,\n         0.00096938, -0.00285136],\n       [-0.00232347, -0.0016694 ,  0.00038817, ..., -0.00020569,\n         0.00022666,  0.0038221 ],\n       [-0.00620588, -0.00316428,  0.00138663, ...,  0.00165645,\n         0.00093876, -0.00017074],\n       ...,\n       [ 0.0017181 ,  0.00186271,  0.00110266, ..., -0.0023023 ,\n        -0.00016485,  0.00787419],\n       [-0.00182129,  0.00049515,  0.0007572 , ..., -0.00087936,\n        -0.00065907, -0.00146304],\n       [-0.00335515, -0.00040929, -0.00032946, ..., -0.00268573,\n         0.00366877, -0.0030683 ]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "id\n1        0\n2        0\n3        0\n4        0\n5        0\n        ..\n31956    0\n31957    0\n31958    0\n31959    0\n31960    0\nName: label, Length: 27650, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Resampling Methods\n",
    "https://www.analyticsvidhya.com/blog/2022/05/handling-imbalanced-data-with-imbalance-learn-in-python/#h-techniques-for-handling-imbalanced-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def print_data(y_before, y_after, sampling_technique):\n",
    "    counter_before = Counter(y_before)\n",
    "    counter_after = Counter(y_after)\n",
    "    print(\"Before sampling with:\", sampling_technique, counter_before)\n",
    "    print(\"After sampling with:\", sampling_technique, counter_after)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.1 SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "os_smote = SMOTE()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 20650, 1: 1497})\n",
      "After sampling with: SMOTE Counter({0: 20650, 1: 20650})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_s, y_train_base_s = os_smote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: SMOTE Counter({0: 19342, 1: 1395})\n",
      "After sampling with: SMOTE Counter({0: 19342, 1: 19342})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_s, y_train_clean_s = os_smote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_s, \"SMOTE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.2 Borderline-SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "os_bsmote = BorderlineSMOTE()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 20650, 1: 1497})\n",
      "After sampling with: BorderlineSMOTE Counter({0: 20650, 1: 20650})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_bs, y_train_base_bs = os_bsmote.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: BorderlineSMOTE Counter({0: 19342, 1: 1395})\n",
      "After sampling with: BorderlineSMOTE Counter({0: 19342, 1: 19342})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_bs, y_train_clean_bs = os_bsmote.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_bs, \"BorderlineSMOTE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1.3 ADASYN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "os_ada = ADASYN()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 20650, 1: 1497})\n",
      "After sampling with: ADASYN Counter({1: 21007, 0: 20650})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_a, y_train_base_a = os_ada.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: ADASYN Counter({0: 19342, 1: 1395})\n",
      "After sampling with: ADASYN Counter({1: 19362, 0: 19342})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_a, y_train_clean_a = os_ada.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_a, \"ADASYN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.1 NearMiss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "us_near_miss = NearMiss(version = 3, n_neighbors_ver3=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 20650, 1: 1497})\n",
      "After sampling with: NearMiss Counter({0: 1497, 1: 1497})\n"
     ]
    }
   ],
   "source": [
    "X_train_base_nm, y_train_base_nm = us_near_miss.fit_resample(X_train_base, y_train_base)\n",
    "print_data(y_train_base, y_train_base_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling with: NearMiss Counter({0: 19342, 1: 1395})\n",
      "After sampling with: NearMiss Counter({0: 1395, 1: 1395})\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_nm, y_train_clean_nm = us_near_miss.fit_resample(X_train_clean, y_train_clean)\n",
    "print_data(y_train_clean, y_train_clean_nm, \"NearMiss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.2 Condensed Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "us_cnn = CondensedNearestNeighbour(n_neighbors=1, n_jobs=-1) # sehr langsam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# X_train_base_cnn, y_train_base_cnn = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_train_base_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# X_train_clean_cnn, y_train_clean_cnn = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_train_clean_cnn, \"CondensedNearestNeighbour\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2.3 Neighborhood Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "us_cnn_cr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5, n_jobs=-1) # sehr langsam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# X_base_ncr, y_base_ncr = us_cnn.fit_resample(X_train_base, y_train_base)\n",
    "# print_data(y_train_base, y_base_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# X_clean_ncr, y_clean_ncr = us_cnn.fit_resample(X_train_clean, y_train_clean)\n",
    "# print_data(y_train_clean, y_clean_ncr, \"NeighbourhoodCleaningRule\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Ensemble Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(columns=[\"model\", \"variant\", \"train_acc\", \"train_prec\", \"train_rec\", \"train_f1\", \"test_acc\", \"test_prec\", \"test_rec\", \"test_f1\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def add_to_eval_df(model, model_name, variant, x_data_train, y_data_train, x_data_test, y_data_test):\n",
    "    train_acc = model.score(x_data_train, y_data_train)\n",
    "    train_precision = precision_score(y_data_train, model.predict(x_data_train), average=\"weighted\")\n",
    "    train_recall = recall_score(y_data_train, model.predict(x_data_train), average=\"weighted\")\n",
    "    train_f1 = f1_score(y_data_train, model.predict(x_data_train), average=\"weighted\")\n",
    "\n",
    "    test_acc = model.score(x_data_test, y_data_test)\n",
    "    test_precision = precision_score(y_data_test, model.predict(x_data_test), average=\"weighted\")\n",
    "    test_recall = recall_score(y_data_test, model.predict(x_data_test), average=\"weighted\")\n",
    "    test_f1 = f1_score(y_data_test, model.predict(x_data_test), average=\"weighted\")\n",
    "\n",
    "    evaluation.loc[len(evaluation.index)] = [model_name, variant, train_acc, train_precision, train_recall, train_f1, test_acc, test_precision, test_recall, test_f1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, sampling_method):\n",
    "    pred = model.predict(x_test)\n",
    "    accscore = metrics.accuracy_score(pred, y_test)\n",
    "\n",
    "    print(f'{sampling_method} model accuracy for classification is =', str('{:04.2f}'.format(accscore * 100)) + '%')\n",
    "    print('------------------------------------------------')\n",
    "    print('Confusion Matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n",
    "    print('------------------------------------------------')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 RandomForest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# BASE\n",
    "rf.fit(X_train_base, y_train_base)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"base\", X_train_base, y_train_base, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# CLEANED\n",
    "rf.fit(X_train_clean, y_train_clean)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"clean\", X_train_clean, y_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# SMOTE --- BASE\n",
    "rf.fit(X_train_base_s, y_train_base_s)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"SMOTE base\", X_train_base_s, y_train_base_s, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# SMOTE --- CLEANED\n",
    "rf.fit(X_train_clean_s, y_train_clean_s)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"SMOTE clean\", X_train_clean_s, y_train_clean_s, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# BorderlineSMOTE --- BASE\n",
    "rf.fit(X_train_base_bs, y_train_base_bs)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"BorderlineSMOTE base\", X_train_base_bs, y_train_base_bs, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# BorderlineSMOTE --- CLEANED\n",
    "rf.fit(X_train_clean_bs, y_train_clean_bs)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"BorderlineSMOTE clean\", X_train_clean_bs, y_train_clean_bs, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# ADASYN --- BASE\n",
    "rf.fit(X_train_base_a, y_train_base_a)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"ADASYN base\", X_train_base_a, y_train_base_a, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# ADASYN --- CLEANED\n",
    "rf.fit(X_train_clean_a, y_train_clean_a)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"ADASYN clean\", X_train_clean_a, y_train_clean_a, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# NearMiss --- BASE\n",
    "rf.fit(X_train_base_nm, y_train_base_nm)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"NearMiss base\", X_train_base_nm, y_train_base_nm, X_test_base, y_test_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# NearMiss --- CLEANED\n",
    "rf.fit(X_train_clean_nm, y_train_clean_nm)\n",
    "add_to_eval_df(rf, \"RandomForest\", \"NearMiss clean\", X_train_clean_nm, y_train_clean_nm, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "          model                variant  train_acc  train_prec  train_rec  \\\n1  RandomForest                  clean   0.999711    0.999711   0.999711   \n0  RandomForest                   base   0.999729    0.999729   0.999729   \n5  RandomForest  BorderlineSMOTE clean   0.999586    0.999587   0.999586   \n4  RandomForest   BorderlineSMOTE base   0.999855    0.999855   0.999855   \n3  RandomForest            SMOTE clean   0.999741    0.999742   0.999741   \n6  RandomForest            ADASYN base   0.999688    0.999688   0.999688   \n7  RandomForest           ADASYN clean   0.999638    0.999639   0.999638   \n2  RandomForest             SMOTE base   0.999661    0.999661   0.999661   \n9  RandomForest         NearMiss clean   0.999642    0.999642   0.999642   \n8  RandomForest          NearMiss base   0.998998    0.999000   0.998998   \n\n   train_f1  test_acc  test_prec  test_rec   test_f1  \n1  0.999710  0.940257   0.943828  0.940257  0.911734  \n0  0.999729  0.931735   0.931520  0.931735  0.900609  \n5  0.999586  0.925503   0.901707  0.925503  0.911836  \n4  0.999855  0.923608   0.899890  0.923608  0.907758  \n3  0.999741  0.917257   0.898812  0.917257  0.907318  \n6  0.999688  0.916023   0.897853  0.916023  0.905434  \n7  0.999638  0.915521   0.900077  0.915521  0.907285  \n2  0.999661  0.915346   0.896838  0.915346  0.904609  \n9  0.999642  0.422537   0.895341  0.422537  0.543189  \n8  0.998998  0.422322   0.880350  0.422322  0.535741  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>variant</th>\n      <th>train_acc</th>\n      <th>train_prec</th>\n      <th>train_rec</th>\n      <th>train_f1</th>\n      <th>test_acc</th>\n      <th>test_prec</th>\n      <th>test_rec</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>clean</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>0.999710</td>\n      <td>0.940257</td>\n      <td>0.943828</td>\n      <td>0.940257</td>\n      <td>0.911734</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>RandomForest</td>\n      <td>base</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.999729</td>\n      <td>0.931735</td>\n      <td>0.931520</td>\n      <td>0.931735</td>\n      <td>0.900609</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE clean</td>\n      <td>0.999586</td>\n      <td>0.999587</td>\n      <td>0.999586</td>\n      <td>0.999586</td>\n      <td>0.925503</td>\n      <td>0.901707</td>\n      <td>0.925503</td>\n      <td>0.911836</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForest</td>\n      <td>BorderlineSMOTE base</td>\n      <td>0.999855</td>\n      <td>0.999855</td>\n      <td>0.999855</td>\n      <td>0.999855</td>\n      <td>0.923608</td>\n      <td>0.899890</td>\n      <td>0.923608</td>\n      <td>0.907758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForest</td>\n      <td>SMOTE clean</td>\n      <td>0.999741</td>\n      <td>0.999742</td>\n      <td>0.999741</td>\n      <td>0.999741</td>\n      <td>0.917257</td>\n      <td>0.898812</td>\n      <td>0.917257</td>\n      <td>0.907318</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForest</td>\n      <td>ADASYN base</td>\n      <td>0.999688</td>\n      <td>0.999688</td>\n      <td>0.999688</td>\n      <td>0.999688</td>\n      <td>0.916023</td>\n      <td>0.897853</td>\n      <td>0.916023</td>\n      <td>0.905434</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForest</td>\n      <td>ADASYN clean</td>\n      <td>0.999638</td>\n      <td>0.999639</td>\n      <td>0.999638</td>\n      <td>0.999638</td>\n      <td>0.915521</td>\n      <td>0.900077</td>\n      <td>0.915521</td>\n      <td>0.907285</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>SMOTE base</td>\n      <td>0.999661</td>\n      <td>0.999661</td>\n      <td>0.999661</td>\n      <td>0.999661</td>\n      <td>0.915346</td>\n      <td>0.896838</td>\n      <td>0.915346</td>\n      <td>0.904609</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForest</td>\n      <td>NearMiss clean</td>\n      <td>0.999642</td>\n      <td>0.999642</td>\n      <td>0.999642</td>\n      <td>0.999642</td>\n      <td>0.422537</td>\n      <td>0.895341</td>\n      <td>0.422537</td>\n      <td>0.543189</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForest</td>\n      <td>NearMiss base</td>\n      <td>0.998998</td>\n      <td>0.999000</td>\n      <td>0.998998</td>\n      <td>0.998998</td>\n      <td>0.422322</td>\n      <td>0.880350</td>\n      <td>0.422322</td>\n      <td>0.535741</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by=[\"test_rec\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
