{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe51bf5d",
   "metadata": {},
   "source": [
    "# Vektorisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2016a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7d715",
   "metadata": {},
   "source": [
    "Dataset \"train_cleaned\" importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117a74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/twitter_hate-speech/train_cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e15cf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father selfish drag kid run</td>\n",
       "      <td>1</td>\n",
       "      <td>['#run']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank lyft credit use cause offer van</td>\n",
       "      <td>2</td>\n",
       "      <td>['#lyft', '#disapointed', '#getthanked']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model take time mobile phone kiss sunglass mou...</td>\n",
       "      <td>0</td>\n",
       "      <td>['#model']</td>\n",
       "      <td>:mobile_phone:,:kissing_face_with_smiling_eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>['#motivation']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet  \\\n",
       "id                                                             \n",
       "1       0   @user when a father is dysfunctional and is s...   \n",
       "2       0  @user @user thanks for #lyft credit i can't us...   \n",
       "3       0                                bihday your majesty   \n",
       "4       0  #model   i love u take with u all the time in ...   \n",
       "5       0             factsguide: society now    #motivation   \n",
       "\n",
       "                                        tweet_cleaned  user_handle  \\\n",
       "id                                                                   \n",
       "1                         father selfish drag kid run            1   \n",
       "2               thank lyft credit use cause offer van            2   \n",
       "3                                      bihday majesty            0   \n",
       "4   model take time mobile phone kiss sunglass mou...            0   \n",
       "5                       factsguide society motivation            0   \n",
       "\n",
       "                                    hashtags  \\\n",
       "id                                             \n",
       "1                                   ['#run']   \n",
       "2   ['#lyft', '#disapointed', '#getthanked']   \n",
       "3                                         []   \n",
       "4                                 ['#model']   \n",
       "5                            ['#motivation']   \n",
       "\n",
       "                                               emojis  \n",
       "id                                                     \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4   :mobile_phone:,:kissing_face_with_smiling_eyes...  \n",
       "5                                                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d46687",
   "metadata": {},
   "source": [
    "Da es leere tweet_cleaned gibt müssen diese hier entfernt werden. Ansonsten werfen alle 3 Methoden Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff7d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tweet_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780468d9",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3127a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doku: https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() # CountVectorizer(binary=True) würde nur 0 und 1 ausgeben\n",
    "X_bow = vectorizer.fit_transform(df.tweet_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac836c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aamp' 'aap' 'ab' ... 'zootopia' 'zoro' 'zzz']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323d9532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7562d5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9523671742196824\n"
     ]
    }
   ],
   "source": [
    "# Erster Test NB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = df.label\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(X_bow,y)\n",
    "\n",
    "ypred = clf.predict(X_bow)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d898b8",
   "metadata": {},
   "source": [
    "#### Ergebnis Bag of Word in X_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ccd4a",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f0d079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doku https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df.tweet_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a66df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aamp' 'aap' 'ab' ... 'zootopia' 'zoro' 'zzz']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c9e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef72bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.954609569966364\n"
     ]
    }
   ],
   "source": [
    "# Erster Test NB\n",
    "\n",
    "y = df.label\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(X_tfidf,y)\n",
    "\n",
    "ypred_tfidf = clf.predict(X_tfidf)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y, ypred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c3bbd",
   "metadata": {},
   "source": [
    "#### Ergebnis TF-IDF in X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995e9b4",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d0c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "data = df['tweet_cleaned'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c945862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1                        [father, selfish, drag, kid, run]\n",
       "2            [thank, lyft, credit, use, cause, offer, van]\n",
       "3                                        [bihday, majesty]\n",
       "4        [model, take, time, mobile, phone, kiss, sungl...\n",
       "5                        [factsguide, society, motivation]\n",
       "                               ...                        \n",
       "31956    [less, week, grin, sweat, fold, hand, medium, ...\n",
       "31957         [fishing, tomorrow, wait, first, time, year]\n",
       "31958                                    [eat, youuu, red]\n",
       "31959    [see, turner, try, wrap, genuine, hero, like, ...\n",
       "31960    [listen, sad, song, monday, morning, otw, work...\n",
       "Name: tweet_cleaned, Length: 27649, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783fbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(data,window=4, min_count=1, sg=0) \n",
    "# sg=1: Skip-Gram\n",
    "# sg=0: Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77cb2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3895247, 4126720)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(data, total_examples=len(df['tweet_cleaned']), epochs=20)\n",
    "# epochs = Anzahl Iterationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e13e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inspiration', 0.8637232184410095),\n",
       " ('positivity', 0.8471518754959106),\n",
       " ('inspirational', 0.8018321990966797),\n",
       " ('bestseller', 0.7903605103492737),\n",
       " ('quoteoftheday', 0.7853137850761414),\n",
       " ('belief', 0.7619601488113403),\n",
       " ('entrepreneur', 0.7595241665840149),\n",
       " ('factsguide', 0.7569527626037598),\n",
       " ('motivate', 0.7558882832527161),\n",
       " ('positivevibe', 0.7505861520767212)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=\"motivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e412b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meet', 0.3771251440048218),\n",
       " ('august', 0.352364182472229),\n",
       " ('july', 0.34603098034858704),\n",
       " ('bus', 0.3416936993598938),\n",
       " ('driver', 0.33455905318260193),\n",
       " ('release', 0.3304154574871063),\n",
       " ('st', 0.32495012879371643),\n",
       " ('th', 0.32050198316574097),\n",
       " ('yr', 0.3202992081642151),\n",
       " ('rd', 0.31380757689476013)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(negative=\"motivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c942d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "\n",
    "def w2v_vector(tokenized_tweet, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokenized_tweet:\n",
    "        try:\n",
    "            vec += w2v.wv[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "                         \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c42d088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v = np.zeros((len(data),size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65fd6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    X_w2v[i,:] = w2v_vector(data.iloc[i],size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feee32ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03039333,  0.14097588, -0.40483578, ..., -1.17256047,\n",
       "        -0.42760487, -0.77401052],\n",
       "       [-0.46381379,  0.53667628,  0.16405297, ..., -0.27580128,\n",
       "        -0.1997893 , -0.49546429],\n",
       "       [ 0.08214973,  0.24564286, -0.4936442 , ..., -0.20577175,\n",
       "         0.18469378,  0.70640232],\n",
       "       ...,\n",
       "       [-0.6783981 , -0.73566437,  0.89766298, ..., -0.63281615,\n",
       "         0.49310272, -0.25537541],\n",
       "       [-0.3309418 ,  0.46646499, -0.08161603, ..., -0.17433416,\n",
       "        -0.06822646, -0.09428725],\n",
       "       [-0.65280033,  0.43611948, -0.79287506, ...,  0.21845217,\n",
       "         0.28302161,  0.13811521]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1a3c7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19140\\95857139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mypred_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_w2v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Erster Test NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "y = df.label\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_w2v,y)\n",
    "\n",
    "ypred_tfidf = clf.predict(X_w2v)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y, ypred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68f8c6",
   "metadata": {},
   "source": [
    "#### Ergebnis Word2Vec in X_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e499c6b",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a7c642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3789191, 4126720)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText \n",
    "\n",
    "ft = FastText(data, window = 4)\n",
    "ft.train(data, total_examples=len(df['tweet_cleaned']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da8cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motivational', 0.9571335315704346),\n",
       " ('mondaymotivation', 0.9560210704803467),\n",
       " ('tuesdaymotivation', 0.9544017910957336),\n",
       " ('inspiration', 0.8639123439788818),\n",
       " ('meditation', 0.8313320279121399),\n",
       " ('affirmation', 0.807649552822113),\n",
       " ('transformation', 0.8043513894081116),\n",
       " ('innovation', 0.7998110055923462),\n",
       " ('inspirational', 0.7940093278884888),\n",
       " ('motivated', 0.7821134924888611)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar(positive=\"motivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d3ed0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yr', 0.3835121691226959),\n",
       " ('v', 0.3463435471057892),\n",
       " ('hi', 0.34137162566185),\n",
       " ('gator', 0.3400598168373108),\n",
       " ('sit', 0.32863670587539673),\n",
       " ('cox', 0.3283883035182953),\n",
       " ('xbox', 0.3270142078399658),\n",
       " ('die', 0.32616955041885376),\n",
       " ('snatch', 0.3259742558002472),\n",
       " ('bro', 0.32236719131469727)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar(negative=\"motivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "192d9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "\n",
    "def ft_vector(tokenized_tweet, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokenized_tweet:\n",
    "        try:\n",
    "            vec += ft.wv[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except KeyError: \n",
    "                         \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "913fe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft = np.zeros((len(data),size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efc330ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    X_ft[i,:] = ft_vector(data.iloc[i],size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36d19786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76547772, -0.21383475, -0.40605466, ..., -0.95944892,\n",
       "        -0.78261749,  0.35719954],\n",
       "       [-0.5774988 , -0.04261827, -0.24013078, ..., -0.04634736,\n",
       "         0.61478294,  0.17527176],\n",
       "       [ 0.81800085,  0.57611634,  0.08267095, ..., -1.20095155,\n",
       "        -0.38159819, -0.06786457],\n",
       "       ...,\n",
       "       [-0.16428977, -0.29616243,  0.1838846 , ..., -0.87193196,\n",
       "         0.509852  , -0.64583018],\n",
       "       [-0.16578822, -0.05996855, -0.39674566, ...,  0.05825424,\n",
       "         0.52146263,  0.31040981],\n",
       "       [-0.51245216,  0.18201927, -0.49733237, ..., -0.3617763 ,\n",
       "        -0.34870465, -0.19760916]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65a1b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7548555101450324\n"
     ]
    }
   ],
   "source": [
    "# Erster Test NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "y = df.label\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_ft,y)\n",
    "\n",
    "ypred_tfidf = clf.predict(X_ft)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y, ypred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a05e85",
   "metadata": {},
   "source": [
    "#### Ergebnis FastText in X_ft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
