{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dieses Notebook √ºberpr√ºft die Cleaning-Funktionen und dokumentiert deren Ergebnisse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codeabschnitt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports & Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "src_path = os.path.abspath(os.path.join(current_dir, '../../../1. Explorative Analysis & Preprocessing/nasiba/'))\n",
    "os.chdir(src_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import os\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer, PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from ftfy import fix_encoding\n",
    "import spacy\n",
    "from src.preprocessing.cleaning.shotcut_lists import shortcuts\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einladen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "filepath_name = os.path.abspath(os.path.join(src_path, 'data/train_cleaned.csv'))\n",
    "dict_path = os.path.abspath(os.path.join(src_path, 'data/frequency_dictionary_en_82_765.txt'))\n",
    "df_cleaned = pd.read_csv(filepath_name, encoding='utf-8', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spell Correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelled_words</th>\n",
       "      <th>corrected_words</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[lyft]</td>\n",
       "      <td>[left]</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thank lyft credit use cause offer van</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bihday]</td>\n",
       "      <td>[birthday]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[allin, cavs]</td>\n",
       "      <td>[allen, cars]</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  ‚Ä¶</td>\n",
       "      <td>win land allin cavs cleveland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[(, mom, ), forex]</td>\n",
       "      <td>[a, mon, a, fore]</td>\n",
       "      <td>‚Üù #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex</td>\n",
       "      <td>ireland consumer price index ( mom ) climb previous may blog silver gold forex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[cnn, tcot]</td>\n",
       "      <td>[can, tot]</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'build the wall' chant '' #tcot</td>\n",
       "      <td>cnn call middle school build wall chant tcot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>[hashtag]</td>\n",
       "      <td>[hashing]</td>\n",
       "      <td>@user @user you don't have the balls to hashtag me as a  but you say i am to weasel away.. lumpy tony.. dipshit.</td>\n",
       "      <td>ball hashtag say away lumpy tony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31949</th>\n",
       "      <td>[oh]</td>\n",
       "      <td>[of]</td>\n",
       "      <td>makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!</td>\n",
       "      <td>make ask anybody god oh thank god</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31954</th>\n",
       "      <td>[newyork]</td>\n",
       "      <td>[network]</td>\n",
       "      <td>good morning #instagram #shower #water #berlin #berlincitygirl   #girl #newyork #z√ºrich #genf #bern</td>\n",
       "      <td>good morning instagram shower water berlin girl newyork</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>[youuu]</td>\n",
       "      <td>[you]</td>\n",
       "      <td>ate @user isz that youuu?üòçüòçüòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è</td>\n",
       "      <td>eat youuu red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>[otw]</td>\n",
       "      <td>[tow]</td>\n",
       "      <td>listening to sad songs on a monday morning otw to work is sad</td>\n",
       "      <td>listen sad song monday morning otw work sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11837 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         misspelled_words    corrected_words  \\\n",
       "id                                             \n",
       "2                  [lyft]             [left]   \n",
       "3                [bihday]         [birthday]   \n",
       "9           [allin, cavs]      [allen, cars]   \n",
       "11     [(, mom, ), forex]  [a, mon, a, fore]   \n",
       "14            [cnn, tcot]         [can, tot]   \n",
       "...                   ...                ...   \n",
       "31948           [hashtag]          [hashing]   \n",
       "31949                [oh]               [of]   \n",
       "31954           [newyork]          [network]   \n",
       "31958             [youuu]              [you]   \n",
       "31960               [otw]              [tow]   \n",
       "\n",
       "                                                                                                                            tweet  \\\n",
       "id                                                                                                                                  \n",
       "2      @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "3                                                                                                             bihday your majesty   \n",
       "9                                           we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  ‚Ä¶    \n",
       "11                   ‚Üù #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex   \n",
       "14                                                     @user #cnn calls #michigan middle school 'build the wall' chant '' #tcot     \n",
       "...                                                                                                                           ...   \n",
       "31948            @user @user you don't have the balls to hashtag me as a  but you say i am to weasel away.. lumpy tony.. dipshit.   \n",
       "31949                                      makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!   \n",
       "31954                        good morning #instagram #shower #water #berlin #berlincitygirl   #girl #newyork #z√ºrich #genf #bern    \n",
       "31958                                                                                       ate @user isz that youuu?üòçüòçüòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è    \n",
       "31960                                                             listening to sad songs on a monday morning otw to work is sad     \n",
       "\n",
       "                                                                        tweet_cleaned  \\\n",
       "id                                                                                      \n",
       "2                                               thank lyft credit use cause offer van   \n",
       "3                                                                      bihday majesty   \n",
       "9                                                       win land allin cavs cleveland   \n",
       "11     ireland consumer price index ( mom ) climb previous may blog silver gold forex   \n",
       "14                                       cnn call middle school build wall chant tcot   \n",
       "...                                                                               ...   \n",
       "31948                                                ball hashtag say away lumpy tony   \n",
       "31949                                               make ask anybody god oh thank god   \n",
       "31954                         good morning instagram shower water berlin girl newyork   \n",
       "31958                                                                   eat youuu red   \n",
       "31960                                     listen sad song monday morning otw work sad   \n",
       "\n",
       "       label  \n",
       "id            \n",
       "2          0  \n",
       "3          0  \n",
       "9          0  \n",
       "11         0  \n",
       "14         1  \n",
       "...      ...  \n",
       "31948      1  \n",
       "31949      1  \n",
       "31954      0  \n",
       "31958      0  \n",
       "31960      0  \n",
       "\n",
       "[11837 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "def apply_symspell_to_dataframe(df, column_name,path):\n",
    "    # SymSpell initialisieren\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    sym_spell.load_dictionary(path, term_index=0, count_index=1)\n",
    "\n",
    "    # Funktion zur Rechtschreibpr√ºfung f√ºr einen Text\n",
    "    def correct_spelling(text):\n",
    "        if not isinstance(text, str):\n",
    "            return {\"misspelled\": [], \"corrected\": []}  # F√ºr nicht-String-Eingaben (z. B. NaN)\n",
    "        \n",
    "        words = text.split()\n",
    "        misspelled = []\n",
    "        corrected = []\n",
    "        \n",
    "        for word in words:\n",
    "            lookup_result = sym_spell.lookup(word.lower(), Verbosity.CLOSEST, max_edit_distance=2)\n",
    "            if lookup_result:\n",
    "                suggestion = lookup_result[0].term\n",
    "                if suggestion.lower() != word.lower():  # Wenn das Wort korrigiert wurde\n",
    "                    misspelled.append(word)\n",
    "                    corrected.append(suggestion)\n",
    "        \n",
    "        return {\"misspelled\": misspelled, \"corrected\": corrected}\n",
    "\n",
    "    # Anwenden der Rechtschreibpr√ºfung auf die Spalte\n",
    "    spellcheck_results = df[column_name].apply(correct_spelling)\n",
    "    \n",
    "    # Hinzuf√ºgen der Ergebnisse zu neuen Spalten\n",
    "    df[\"misspelled_words\"] = spellcheck_results.apply(lambda x: x[\"misspelled\"])\n",
    "    df[\"corrected_words\"] = spellcheck_results.apply(lambda x: x[\"corrected\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Anwendung der Funktion\n",
    "df_cleaned = apply_symspell_to_dataframe(df_cleaned, \"tweet_cleaned\",dict_path)\n",
    "\n",
    "# Filtern der Zeilen mit falsch geschriebenen W√∂rtern\n",
    "df_filtered = df_cleaned[df_cleaned[\"misspelled_words\"].apply(len) > 0]\n",
    "\n",
    "# Anzeigen der gew√ºnschten Spalten\n",
    "df_filtered[['misspelled_words', 'corrected_words', 'tweet', 'tweet_cleaned','label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>misspelled_words</th>\n",
       "      <th>corrected_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'build the wall' chant '' #tcot</td>\n",
       "      <td>cnn call middle school build wall chant tcot</td>\n",
       "      <td>1</td>\n",
       "      <td>['#cnn', '#michigan', '#tcot']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cnn, tcot]</td>\n",
       "      <td>[can, tot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #seashepherd #helpcovedolphins #thecove  #helpcovedolphins</td>\n",
       "      <td>comment australia opkillingbay seashepherd thecove</td>\n",
       "      <td>0</td>\n",
       "      <td>['#australia', '#opkillingbay', '#seashepherd', '#helpcovedolphins', '#thecove', '#helpcovedolphins']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[thecove]</td>\n",
       "      <td>[they've]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>retweet agree</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[retweet]</td>\n",
       "      <td>[between]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>how the #altright uses  &amp;amp; insecurity to lure men into #whitesupremacy</td>\n",
       "      <td>altright use amp man whitesupremacy</td>\n",
       "      <td>0</td>\n",
       "      <td>['#altright', '#whitesupremacy']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[altright]</td>\n",
       "      <td>[alright]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>@user why not @user mocked obama for being black.  @user @user @user @user #brexit</td>\n",
       "      <td>mock obama black brexit</td>\n",
       "      <td>6</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[brexit]</td>\n",
       "      <td>[credit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31934</th>\n",
       "      <td>1</td>\n",
       "      <td>@user judd is a  &amp;amp; #homophobic #freemilo #milo #freemilo #milo #freemilo #milo #freemilo #milo #freemilo</td>\n",
       "      <td>amp homophobic freemilo milo freemilo milo freemilo milo freemilo milo freemilo</td>\n",
       "      <td>1</td>\n",
       "      <td>['#homophobic', '#freemilo', '#milo', '#freemilo', '#milo', '#freemilo', '#milo', '#freemilo', '#milo', '#freemilo']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[freemilo, freemilo, freemilo, freemilo, freemilo]</td>\n",
       "      <td>[freewill, freewill, freewill, freewill, freewill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31935</th>\n",
       "      <td>1</td>\n",
       "      <td>lady banned from kentucky mall. @user  #jcpenny #kentucky</td>\n",
       "      <td>lady ban kentucky mall jcpenny kentucky</td>\n",
       "      <td>1</td>\n",
       "      <td>['#jcpenny', '#kentucky']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[jcpenny]</td>\n",
       "      <td>[penny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>1</td>\n",
       "      <td>@user omfg i'm offended! i'm a  mailbox and i'm proud! #mailboxpride  #liberalisme</td>\n",
       "      <td>omfg offend proud</td>\n",
       "      <td>1</td>\n",
       "      <td>['#mailboxpride', '#liberalisme']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[omfg]</td>\n",
       "      <td>[mfg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user you don't have the balls to hashtag me as a  but you say i am to weasel away.. lumpy tony.. dipshit.</td>\n",
       "      <td>ball hashtag say away lumpy tony</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[hashtag]</td>\n",
       "      <td>[hashing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31949</th>\n",
       "      <td>1</td>\n",
       "      <td>makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!</td>\n",
       "      <td>make ask anybody god oh thank god</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[oh]</td>\n",
       "      <td>[of]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  \\\n",
       "id             \n",
       "14         1   \n",
       "15         1   \n",
       "18         1   \n",
       "83         1   \n",
       "115        1   \n",
       "...      ...   \n",
       "31934      1   \n",
       "31935      1   \n",
       "31947      1   \n",
       "31948      1   \n",
       "31949      1   \n",
       "\n",
       "                                                                                                                  tweet  \\\n",
       "id                                                                                                                        \n",
       "14                                           @user #cnn calls #michigan middle school 'build the wall' chant '' #tcot     \n",
       "15                no comment!  in #australia   #opkillingbay #seashepherd #helpcovedolphins #thecove  #helpcovedolphins   \n",
       "18                                                                                               retweet if you agree!    \n",
       "83                                        how the #altright uses  &amp; insecurity to lure men into #whitesupremacy       \n",
       "115                                  @user why not @user mocked obama for being black.  @user @user @user @user #brexit   \n",
       "...                                                                                                                 ...   \n",
       "31934      @user judd is a  &amp; #homophobic #freemilo #milo #freemilo #milo #freemilo #milo #freemilo #milo #freemilo   \n",
       "31935                                                       lady banned from kentucky mall. @user  #jcpenny #kentucky     \n",
       "31947                                @user omfg i'm offended! i'm a  mailbox and i'm proud! #mailboxpride  #liberalisme   \n",
       "31948  @user @user you don't have the balls to hashtag me as a  but you say i am to weasel away.. lumpy tony.. dipshit.   \n",
       "31949                            makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!   \n",
       "\n",
       "                                                                         tweet_cleaned  \\\n",
       "id                                                                                       \n",
       "14                                        cnn call middle school build wall chant tcot   \n",
       "15                                  comment australia opkillingbay seashepherd thecove   \n",
       "18                                                                       retweet agree   \n",
       "83                                                 altright use amp man whitesupremacy   \n",
       "115                                                            mock obama black brexit   \n",
       "...                                                                                ...   \n",
       "31934  amp homophobic freemilo milo freemilo milo freemilo milo freemilo milo freemilo   \n",
       "31935                                          lady ban kentucky mall jcpenny kentucky   \n",
       "31947                                                                omfg offend proud   \n",
       "31948                                                 ball hashtag say away lumpy tony   \n",
       "31949                                                make ask anybody god oh thank god   \n",
       "\n",
       "       user_handle  \\\n",
       "id                   \n",
       "14               1   \n",
       "15               0   \n",
       "18               0   \n",
       "83               0   \n",
       "115              6   \n",
       "...            ...   \n",
       "31934            1   \n",
       "31935            1   \n",
       "31947            1   \n",
       "31948            2   \n",
       "31949            0   \n",
       "\n",
       "                                                                                                                   hashtags  \\\n",
       "id                                                                                                                            \n",
       "14                                                                                           ['#cnn', '#michigan', '#tcot']   \n",
       "15                    ['#australia', '#opkillingbay', '#seashepherd', '#helpcovedolphins', '#thecove', '#helpcovedolphins']   \n",
       "18                                                                                                                       []   \n",
       "83                                                                                         ['#altright', '#whitesupremacy']   \n",
       "115                                                                                                             ['#brexit']   \n",
       "...                                                                                                                     ...   \n",
       "31934  ['#homophobic', '#freemilo', '#milo', '#freemilo', '#milo', '#freemilo', '#milo', '#freemilo', '#milo', '#freemilo']   \n",
       "31935                                                                                             ['#jcpenny', '#kentucky']   \n",
       "31947                                                                                     ['#mailboxpride', '#liberalisme']   \n",
       "31948                                                                                                                    []   \n",
       "31949                                                                                                                    []   \n",
       "\n",
       "      emojis                                    misspelled_words  \\\n",
       "id                                                                 \n",
       "14       NaN                                         [cnn, tcot]   \n",
       "15       NaN                                           [thecove]   \n",
       "18       NaN                                           [retweet]   \n",
       "83       NaN                                          [altright]   \n",
       "115      NaN                                            [brexit]   \n",
       "...      ...                                                 ...   \n",
       "31934    NaN  [freemilo, freemilo, freemilo, freemilo, freemilo]   \n",
       "31935    NaN                                           [jcpenny]   \n",
       "31947    NaN                                              [omfg]   \n",
       "31948    NaN                                           [hashtag]   \n",
       "31949    NaN                                                [oh]   \n",
       "\n",
       "                                          corrected_words  \n",
       "id                                                         \n",
       "14                                             [can, tot]  \n",
       "15                                              [they've]  \n",
       "18                                              [between]  \n",
       "83                                              [alright]  \n",
       "115                                              [credit]  \n",
       "...                                                   ...  \n",
       "31934  [freewill, freewill, freewill, freewill, freewill]  \n",
       "31935                                             [penny]  \n",
       "31947                                               [mfg]  \n",
       "31948                                           [hashing]  \n",
       "31949                                                [of]  \n",
       "\n",
       "[815 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[df_filtered['label']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between\n",
      "retreat\n",
      "retest\n",
      "tweet\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m suggestion \u001b[38;5;129;01min\u001b[39;00m suggestions:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(suggestion\u001b[38;5;241m.\u001b[39mterm)  \u001b[38;5;66;03m# \"spelling\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprocess\u001b[49m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeling\u001b[39m\u001b[38;5;124m\"\u001b[39m, words))  \u001b[38;5;66;03m# [('spelling', 90), ('spilling', 80)]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process' is not defined"
     ]
    }
   ],
   "source": [
    "# spell= SpellChecker()\n",
    "# spell_aut = Speller(lang='en')\n",
    "# misspelled = spell.unknown('retweet')\n",
    "# print(misspelled)  # Output: {'wrld'}\n",
    "\n",
    "# suggestions = spell.candidates('retweet')\n",
    "# print(suggestions)  # Output: {'world'}\n",
    "\n",
    "# # correction_spell = spell.correction('I havv a guud ideea')\n",
    "# # print(correction_spell)  # Output: 'world'\n",
    "\n",
    "\n",
    "# suggestions_unk = spell_aut.autocorrect_sentence('retweet')\n",
    "# print(suggestions_unk  )  # Output: 'world'\n",
    "\n",
    "# suggestions_aut = spell_aut.get_candidates('retweet')\n",
    "# print(suggestions_aut )  # Output: 'world'\n",
    "\n",
    "# # correction_aut = spell_aut('I havv a guud ideea')\n",
    "# # print(correction_aut )  # Output: 'world'\n",
    "\n",
    "# text = TextBlob('retweet')\n",
    "# print(text.correct())  # \"I have a spelling error in this sentence.\"\n",
    "\n",
    "sym_spell = SymSpell()\n",
    "sym_spell.load_dictionary(dict_path, 0, 1)\n",
    "words = ['retweet','bihday']\n",
    "suggestions = sym_spell.lookup('retweet', Verbosity.CLOSEST, max_edit_distance=2)\n",
    "for suggestion in suggestions:\n",
    "    print(suggestion.term)  # \"spelling\"\n",
    "\n",
    "\n",
    "print(process.extract(\"speling\", words))  # [('spelling', 90), ('spilling', 80)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15204\n",
      "27626\n",
      "Prozentualer Anteil der Zeilen mit falsch geschriebenen W√∂rtern: 55.04%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spell = SpellChecker()\n",
    "def identify_misspelled_words(text):\n",
    "    # Sicherstellen, dass text ein String ist\n",
    "    if not isinstance(text, str):\n",
    "        return []  # Leere Liste zur√ºckgeben, wenn der Wert kein String ist\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    misspelled = [\n",
    "        word for word in words \n",
    "        if not any(emoji.is_emoji(char) for char in word)  # Ignoriere Emojis\n",
    "        and not word.startswith('@')  # Ignoriere W√∂rter, die mit @ beginnen\n",
    "        and not word.startswith('#')  # Ignoriere W√∂rter, die mit # beginnen\n",
    "        and word in spell.unknown([word])  # F√ºhre Rechtschreibpr√ºfung auf verbleibende W√∂rter durch\n",
    "        and not word.endswith('!')\n",
    "        and not word.endswith(']')\n",
    "        and not word.startswith('[')\n",
    "        and not word.endswith('.')\n",
    "    ]\n",
    "    return misspelled\n",
    "\n",
    "\n",
    "df_cleaned['misspelled_words'] = df_cleaned['tweet_cleaned'].apply(identify_misspelled_words)\n",
    "\n",
    "# Zeilen z√§hlen, bei denen die Spalte 'misspelled_words' nicht leer ist\n",
    "misspelled_count = df_cleaned[df_cleaned['misspelled_words'].str.len() > 0].shape[0]\n",
    "total_count = df_cleaned.shape[0]\n",
    "\n",
    "print(misspelled_count)\n",
    "print(total_count )\n",
    "percentage = (misspelled_count / total_count) * 100\n",
    "print(f\"Prozentualer Anteil der Zeilen mit falsch geschriebenen W√∂rtern: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyse_label_0= df_cleaned[df_cleaned['label']==0]\n",
    "df_analyse_label_1= df_cleaned[df_cleaned['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082\n",
      "1809\n",
      "Prozentualer Anteil der Zeilen mit falsch geschriebenen W√∂rtern: 59.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nasiba\\AppData\\Local\\Temp\\ipykernel_19996\\2653595961.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analyse_label_1['misspelled_words'] = df_analyse_label_1['tweet_cleaned'].apply(identify_misspelled_words)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spell = SpellChecker()\n",
    "def identify_misspelled_words(text):\n",
    "    # Sicherstellen, dass text ein String ist\n",
    "    if not isinstance(text, str):\n",
    "        return []  # Leere Liste zur√ºckgeben, wenn der Wert kein String ist\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    misspelled = [\n",
    "        word for word in words \n",
    "        if not any(emoji.is_emoji(char) for char in word)  # Ignoriere Emojis\n",
    "        and not word.startswith('@')  # Ignoriere W√∂rter, die mit @ beginnen\n",
    "        and not word.startswith('#')  # Ignoriere W√∂rter, die mit # beginnen\n",
    "        and word in spell.unknown([word])  # F√ºhre Rechtschreibpr√ºfung auf verbleibende W√∂rter durch\n",
    "        and not word.endswith('!')\n",
    "        and not word.endswith(']')\n",
    "        and not word.startswith('[')\n",
    "        and not word.endswith('.')\n",
    "    ]\n",
    "    return misspelled\n",
    "\n",
    "\n",
    "df_analyse_label_1['misspelled_words'] = df_analyse_label_1['tweet_cleaned'].apply(identify_misspelled_words)\n",
    "\n",
    "# Zeilen z√§hlen, bei denen die Spalte 'misspelled_words' nicht leer ist\n",
    "misspelled_count = df_analyse_label_1[df_analyse_label_1['misspelled_words'].str.len() > 0].shape[0]\n",
    "total_count = df_analyse_label_1.shape[0]\n",
    "\n",
    "print(misspelled_count)\n",
    "print(total_count )\n",
    "percentage = (misspelled_count / total_count) * 100\n",
    "print(f\"Prozentualer Anteil der Zeilen mit falsch geschriebenen W√∂rtern: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelled_words</th>\n",
       "      <th>corrected_words</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[lyft]</td>\n",
       "      <td>[left]</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thank lyft credit use cause offer van</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bihday]</td>\n",
       "      <td>[birthday]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[allin, cavs]</td>\n",
       "      <td>[allen, cars]</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  ‚Ä¶</td>\n",
       "      <td>win land allin cavs cleveland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[(, mom, ), forex]</td>\n",
       "      <td>[a, mon, a, fore]</td>\n",
       "      <td>‚Üù #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex</td>\n",
       "      <td>ireland consumer price index ( mom ) climb previous may blog silver gold forex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[cnn, tcot]</td>\n",
       "      <td>[can, tot]</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'build the wall' chant '' #tcot</td>\n",
       "      <td>cnn call middle school build wall chant tcot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>[hashtag]</td>\n",
       "      <td>[hashing]</td>\n",
       "      <td>@user @user you don't have the balls to hashtag me as a  but you say i am to weasel away.. lumpy tony.. dipshit.</td>\n",
       "      <td>ball hashtag say away lumpy tony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31949</th>\n",
       "      <td>[oh]</td>\n",
       "      <td>[of]</td>\n",
       "      <td>makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!</td>\n",
       "      <td>make ask anybody god oh thank god</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31954</th>\n",
       "      <td>[newyork]</td>\n",
       "      <td>[network]</td>\n",
       "      <td>good morning #instagram #shower #water #berlin #berlincitygirl   #girl #newyork #z√ºrich #genf #bern</td>\n",
       "      <td>good morning instagram shower water berlin girl newyork</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>[youuu]</td>\n",
       "      <td>[you]</td>\n",
       "      <td>ate @user isz that youuu?üòçüòçüòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è</td>\n",
       "      <td>eat youuu red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>[otw]</td>\n",
       "      <td>[tow]</td>\n",
       "      <td>listening to sad songs on a monday morning otw to work is sad</td>\n",
       "      <td>listen sad song monday morning otw work sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11837 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         misspelled_words    corrected_words  \\\n",
       "id                                             \n",
       "2                  [lyft]             [left]   \n",
       "3                [bihday]         [birthday]   \n",
       "9           [allin, cavs]      [allen, cars]   \n",
       "11     [(, mom, ), forex]  [a, mon, a, fore]   \n",
       "14            [cnn, tcot]         [can, tot]   \n",
       "...                   ...                ...   \n",
       "31948           [hashtag]          [hashing]   \n",
       "31949                [oh]               [of]   \n",
       "31954           [newyork]          [network]   \n",
       "31958             [youuu]              [you]   \n",
       "31960               [otw]              [tow]   \n",
       "\n",
       "                                                                                                                            tweet  \\\n",
       "id                                                                                                                                  \n",
       "2      @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "3                                                                                                             bihday your majesty   \n",
       "9                                           we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  ‚Ä¶    \n",
       "11                   ‚Üù #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex   \n",
       "14                                                     @user #cnn calls #michigan middle school 'build the wall' chant '' #tcot     \n",
       "...                                                                                                                           ...   \n",
       "31948            @user @user you don't have the balls to hashtag me as a  but you say i am to weasel away.. lumpy tony.. dipshit.   \n",
       "31949                                      makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!   \n",
       "31954                        good morning #instagram #shower #water #berlin #berlincitygirl   #girl #newyork #z√ºrich #genf #bern    \n",
       "31958                                                                                       ate @user isz that youuu?üòçüòçüòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è    \n",
       "31960                                                             listening to sad songs on a monday morning otw to work is sad     \n",
       "\n",
       "                                                                        tweet_cleaned  \\\n",
       "id                                                                                      \n",
       "2                                               thank lyft credit use cause offer van   \n",
       "3                                                                      bihday majesty   \n",
       "9                                                       win land allin cavs cleveland   \n",
       "11     ireland consumer price index ( mom ) climb previous may blog silver gold forex   \n",
       "14                                       cnn call middle school build wall chant tcot   \n",
       "...                                                                               ...   \n",
       "31948                                                ball hashtag say away lumpy tony   \n",
       "31949                                               make ask anybody god oh thank god   \n",
       "31954                         good morning instagram shower water berlin girl newyork   \n",
       "31958                                                                   eat youuu red   \n",
       "31960                                     listen sad song monday morning otw work sad   \n",
       "\n",
       "       label  \n",
       "id            \n",
       "2          0  \n",
       "3          0  \n",
       "9          0  \n",
       "11         0  \n",
       "14         1  \n",
       "...      ...  \n",
       "31948      1  \n",
       "31949      1  \n",
       "31954      0  \n",
       "31958      0  \n",
       "31960      0  \n",
       "\n",
       "[11837 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "def apply_symspell_to_dataframe(df, column_name,path):\n",
    "    # SymSpell initialisieren\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    sym_spell.load_dictionary(path, term_index=0, count_index=1)\n",
    "\n",
    "    # Funktion zur Rechtschreibpr√ºfung f√ºr einen Text\n",
    "    def correct_spelling(text):\n",
    "        if not isinstance(text, str):\n",
    "            return {\"misspelled\": [], \"corrected\": []}  # F√ºr nicht-String-Eingaben (z. B. NaN)\n",
    "        \n",
    "        words = text.split()\n",
    "        misspelled = []\n",
    "        corrected = []\n",
    "        \n",
    "        for word in words:\n",
    "            lookup_result = sym_spell.lookup(word.lower(), Verbosity.CLOSEST, max_edit_distance=2)\n",
    "            if lookup_result:\n",
    "                suggestion = lookup_result[0].term\n",
    "                if suggestion.lower() != word.lower():  # Wenn das Wort korrigiert wurde\n",
    "                    misspelled.append(word)\n",
    "                    corrected.append(suggestion)\n",
    "        \n",
    "        return {\"misspelled\": misspelled, \"corrected\": corrected}\n",
    "\n",
    "    # Anwenden der Rechtschreibpr√ºfung auf die Spalte\n",
    "    spellcheck_results = df[column_name].apply(correct_spelling)\n",
    "    \n",
    "    # Hinzuf√ºgen der Ergebnisse zu neuen Spalten\n",
    "    df[\"misspelled_words\"] = spellcheck_results.apply(lambda x: x[\"misspelled\"])\n",
    "    df[\"corrected_words\"] = spellcheck_results.apply(lambda x: x[\"corrected\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Anwendung der Funktion\n",
    "df_cleaned = apply_symspell_to_dataframe(df_cleaned, \"tweet_cleaned\",dict_path)\n",
    "\n",
    "# Filtern der Zeilen mit falsch geschriebenen W√∂rtern\n",
    "df_filtered = df_cleaned[df_cleaned[\"misspelled_words\"].apply(len) > 0]\n",
    "\n",
    "# Anzeigen der gew√ºnschten Spalten\n",
    "df_filtered[['misspelled_words', 'corrected_words', 'tweet', 'tweet_cleaned','label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "# Initialisiere den Autocorrect-Checker f√ºr Englisch\n",
    "spell = Speller(lang='en')\n",
    "def apply_spell_to_dataframe(df, column_name):\n",
    "    def correct_spelling(text):\n",
    "        if not isinstance(text, str):\n",
    "            return {\"misspelled\": [], \"corrected\": []}  # Leeres Dictionary, wenn kein String\n",
    "\n",
    "        words = text.split()\n",
    "\n",
    "        misspelled = []\n",
    "        corrected = []\n",
    "\n",
    "        for word in words:\n",
    "        # √úberpr√ºfen, ob das Wort korrigiert werden muss\n",
    "            corrected_word = spell(word)\n",
    "            if corrected_word != word:  # Nur korrigierte W√∂rter ber√ºcksichtigen\n",
    "                misspelled.append(word)\n",
    "                corrected.append(corrected_word)\n",
    "\n",
    "    # R√ºckgabe von None, wenn keine Fehler gefunden werden\n",
    "        if len(misspelled) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return {\"misspelled\": misspelled, \"corrected\": corrected}\n",
    "\n",
    "    spellcheck_results = df[column_name].apply(correct_spelling)\n",
    "    \n",
    "    # Hinzuf√ºgen der Ergebnisse zu neuen Spalten\n",
    "    df[\"misspelled_words\"] = spellcheck_results.apply(lambda x: x[\"misspelled\"])\n",
    "    df[\"corrected_words\"] = spellcheck_results.apply(lambda x: x[\"corrected\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Anwendung der Funktion\n",
    "df_cleaned = apply_spell_to_dataframe(df_cleaned, \"tweet_cleaned\")\n",
    "\n",
    "# Filtern der Zeilen mit falsch geschriebenen W√∂rtern\n",
    "df_filtered = df_cleaned[df_cleaned[\"misspelled_words\"].apply(len) > 0]\n",
    "\n",
    "# Anzeigen der gew√ºnschten Spalten\n",
    "df_filtered[['misspelled_words', 'corrected_words', 'tweet', 'tweet_cleaned','label']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Schimpfw√∂rter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl Tweets mit '**': 18\n",
      "Anzahl in Label 1: 4\n",
      "Anteil von Label 1: 22.22%\n"
     ]
    }
   ],
   "source": [
    "df_analyse_label_0= df_cleaned[df_cleaned['label']==0]\n",
    "df_analyse_label_1= df_cleaned[df_cleaned['label']==1]\n",
    "# Anzahl der Tweets mit \"**\" (gesamt und pro Label)\n",
    "anzahl_gesamt = df_cleaned['tweet'].str.contains(r'\\*\\*', na=False).sum()\n",
    "anzahl_label_1 = df_cleaned[df_cleaned['label'] == 1]['tweet'].str.contains(r'\\*\\*', na=False).sum()\n",
    "\n",
    "# Anteil berechnen\n",
    "anteil = (anzahl_label_1 / anzahl_gesamt) * 100 if anzahl_gesamt > 0 else 0\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Gesamtanzahl Tweets mit '**': {anzahl_gesamt}\")\n",
    "print(f\"Anzahl in Label 1: {anzahl_label_1}\")\n",
    "print(f\"Anteil von Label 1: {anteil:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_swear_words = [\n",
    "    \"asshole\", \"bastard\", \"bitch\", \"bollocks\", \"bugger\", \"bullshit\",\n",
    "    \"crap\", \"damn\", \"dick\", \"dickhead\", \"faggot\", \"fuck\", \"fucked\",\n",
    "    \"fucker\", \"fucking\", \"goddamn\", \"hell\", \"jackass\", \"jerk\",\n",
    "    \"motherfucker\", \"piss\", \"prick\", \"shit\", \"shithead\", \"slut\",\n",
    "    \"son of a bitch\", \"twat\", \"wanker\", \"whore\",'offensive', 'fool'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nasiba\\AppData\\Local\\Temp\\ipykernel_16412\\2861876478.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analyse_label_1['contains_bad_words'] = df_analyse_label_1['tweet'].apply(lambda x: profanity.contains_profanity(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>contains_bad_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>everytime i wear soccer shis joie fries me and says i look mexican as fuck üòí</td>\n",
       "      <td>everytime wear soccer shis joie fry say look mexican fuck unamused</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>:unamused_face:</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>bullshit, he was thrown out for being a muslim</td>\n",
       "      <td>bullshit throw muslim</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>1743</td>\n",
       "      <td>1</td>\n",
       "      <td>i wanna be fucked !  my id  13479   meet me here</td>\n",
       "      <td>wanna fuck meet</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1935</td>\n",
       "      <td>1</td>\n",
       "      <td>names for women fucking hard teen</td>\n",
       "      <td>name woman fuck hard teen</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>1943</td>\n",
       "      <td>1</td>\n",
       "      <td>chick gets fucked nude superhero</td>\n",
       "      <td>chick get fuck nude superhero</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25532</th>\n",
       "      <td>29399</td>\n",
       "      <td>1</td>\n",
       "      <td>yeah man fuck feminism</td>\n",
       "      <td>yeah man fuck feminism</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27228</th>\n",
       "      <td>31444</td>\n",
       "      <td>1</td>\n",
       "      <td>@user is a  &amp;amp; a sick fuck! he looks like his pedophile friend @user</td>\n",
       "      <td>amp sick fuck look like friend</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27298</th>\n",
       "      <td>31537</td>\n",
       "      <td>1</td>\n",
       "      <td>the fuck done with #mansplaining and other  bullshit.</td>\n",
       "      <td>fuck bullshit</td>\n",
       "      <td>0</td>\n",
       "      <td>['#mansplaining']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27355</th>\n",
       "      <td>31604</td>\n",
       "      <td>1</td>\n",
       "      <td>girl get fuck bondage leather girl</td>\n",
       "      <td>girl get fuck leather girl</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27419</th>\n",
       "      <td>31681</td>\n",
       "      <td>1</td>\n",
       "      <td>chick gets fucked crazy european sex</td>\n",
       "      <td>chick get fuck crazy european sex</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "723      750      1   \n",
       "1597    1673      1   \n",
       "1660    1743      1   \n",
       "1836    1935      1   \n",
       "1844    1943      1   \n",
       "...      ...    ...   \n",
       "25532  29399      1   \n",
       "27228  31444      1   \n",
       "27298  31537      1   \n",
       "27355  31604      1   \n",
       "27419  31681      1   \n",
       "\n",
       "                                                                               tweet  \\\n",
       "723    everytime i wear soccer shis joie fries me and says i look mexican as fuck üòí    \n",
       "1597                               bullshit, he was thrown out for being a muslim      \n",
       "1660                            i wanna be fucked !  my id  13479   meet me here       \n",
       "1836                                              names for women fucking hard teen    \n",
       "1844                                               chick gets fucked nude superhero    \n",
       "...                                                                              ...   \n",
       "25532                                                        yeah man fuck feminism    \n",
       "27228       @user is a  &amp; a sick fuck! he looks like his pedophile friend @user    \n",
       "27298                         the fuck done with #mansplaining and other  bullshit.    \n",
       "27355                                             girl get fuck bondage leather girl   \n",
       "27419                                           chick gets fucked crazy european sex   \n",
       "\n",
       "                                                            tweet_cleaned  \\\n",
       "723    everytime wear soccer shis joie fry say look mexican fuck unamused   \n",
       "1597                                                bullshit throw muslim   \n",
       "1660                                                      wanna fuck meet   \n",
       "1836                                            name woman fuck hard teen   \n",
       "1844                                        chick get fuck nude superhero   \n",
       "...                                                                   ...   \n",
       "25532                                              yeah man fuck feminism   \n",
       "27228                                      amp sick fuck look like friend   \n",
       "27298                                                       fuck bullshit   \n",
       "27355                                          girl get fuck leather girl   \n",
       "27419                                   chick get fuck crazy european sex   \n",
       "\n",
       "       user_handle           hashtags           emojis  contains_bad_words  \n",
       "723              0                 []  :unamused_face:                True  \n",
       "1597             0                 []              NaN                True  \n",
       "1660             0                 []              NaN                True  \n",
       "1836             0                 []              NaN                True  \n",
       "1844             0                 []              NaN                True  \n",
       "...            ...                ...              ...                 ...  \n",
       "25532            0                 []              NaN                True  \n",
       "27228            2                 []              NaN                True  \n",
       "27298            0  ['#mansplaining']              NaN                True  \n",
       "27355            0                 []              NaN                True  \n",
       "27419            0                 []              NaN                True  \n",
       "\n",
       "[82 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from better_profanity import profanity\n",
    "\n",
    "# Initialisiere die Schimpfwortliste\n",
    "profanity.load_censor_words(english_swear_words)  # Deine benutzerdefinierte Liste\n",
    "\n",
    "# Pr√ºfen auf Schimpfw√∂rter\n",
    "df_analyse_label_1['contains_bad_words'] = df_analyse_label_1['tweet'].apply(lambda x: profanity.contains_profanity(x))\n",
    "\n",
    "df_analyse_label_1[df_analyse_label_1['contains_bad_words']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nasiba\\AppData\\Local\\Temp\\ipykernel_16412\\3803445381.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analyse_label_0['contains_bad_words'] = df_analyse_label_0['tweet'].apply(lambda x: profanity.contains_profanity(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>contains_bad_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>hbd to this dick suckin tequila lovin slut, i wouldnt want u any other way üíïüòò   #justalillate #butstillontime</td>\n",
       "      <td>happy dick tequila lovin slut would want way two blow kiss</td>\n",
       "      <td>0</td>\n",
       "      <td>['#justalillate', '#butstillontime']</td>\n",
       "      <td>:two_hearts:,:face_blowing_a_kiss:</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>this really takes the piss. i'm so angry. just goes to show who is valued and who isn't. you complete and utter moron.</td>\n",
       "      <td>really take piss angry go show value complete utter moron</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>if you have never lost a loved one to senseless violence you don't get a fucking opinion on the 2nd amendment</td>\n",
       "      <td>never lose one senseless violence get fucking opinion nd amendment</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>twinklatinboys - na: #slut #snapshot #hot #nasty #naughty #sexy #horny #shy #porn #nude   #kinky #xxx #y...</td>\n",
       "      <td>na slut snapshot hot nasty naughty sexy horny shy porn nude kinky xxx</td>\n",
       "      <td>0</td>\n",
       "      <td>['#slut', '#snapshot', '#hot', '#nasty', '#naughty', '#sexy', '#horny', '#shy', '#porn', '#nude', '#kinky', '#xxx', '#y']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>sexy as fuck #directioner   #niall #nialhoranfacts #niallerwins #hot #justindrewbieber #justindb #believetou...</td>\n",
       "      <td>sexy fuck hot</td>\n",
       "      <td>0</td>\n",
       "      <td>['#directioner', '#niall', '#nialhoranfacts', '#niallerwins', '#hot', '#justindrewbieber', '#justindb', '#believetou']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27473</th>\n",
       "      <td>31742</td>\n",
       "      <td>0</td>\n",
       "      <td>i dont want a world like this... homophonia? its not a phobie there are just asshole!  #praygay     #orlando #prayfororlando</td>\n",
       "      <td>want world like asshole orlando prayfororlando</td>\n",
       "      <td>0</td>\n",
       "      <td>['#praygay', '#orlando', '#prayfororlando']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27527</th>\n",
       "      <td>31809</td>\n",
       "      <td>0</td>\n",
       "      <td>so much   shit going on in the world... ‚òπÔ∏è. 50 people. geeesh!</td>\n",
       "      <td>much shit go world frown people</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>:frowning_face:</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27561</th>\n",
       "      <td>31854</td>\n",
       "      <td>0</td>\n",
       "      <td>@user shit i just realized your account isn't a month old. it's only a few weeks old. that's more like 110 tweets a day. just</td>\n",
       "      <td>shit realize account month old week old like tweet</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>31909</td>\n",
       "      <td>0</td>\n",
       "      <td>if dudes wana fuck eachother n get married, i can never be mad at tht. jus means more females for me! #damn50 #orlando # #omg50 #gay</td>\n",
       "      <td>dude fuck n get marry never mad tht jus mean female damn orlando omg gay</td>\n",
       "      <td>0</td>\n",
       "      <td>['#damn50', '#orlando', '#omg50', '#gay']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27615</th>\n",
       "      <td>31919</td>\n",
       "      <td>0</td>\n",
       "      <td>what the hell is wrong with humanity? why would anyone need to do anything to prove his faith?#ridiculous</td>\n",
       "      <td>hell wrong humanity would anyone need anything prove</td>\n",
       "      <td>0</td>\n",
       "      <td>['#ridiculous']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "152      156      0   \n",
       "204      210      0   \n",
       "281      289      0   \n",
       "288      296      0   \n",
       "317      325      0   \n",
       "...      ...    ...   \n",
       "27473  31742      0   \n",
       "27527  31809      0   \n",
       "27561  31854      0   \n",
       "27605  31909      0   \n",
       "27615  31919      0   \n",
       "\n",
       "                                                                                                                                        tweet  \\\n",
       "152                            hbd to this dick suckin tequila lovin slut, i wouldnt want u any other way üíïüòò   #justalillate #butstillontime    \n",
       "204                  this really takes the piss. i'm so angry. just goes to show who is valued and who isn't. you complete and utter moron.     \n",
       "281                          if you have never lost a loved one to senseless violence you don't get a fucking opinion on the 2nd amendment      \n",
       "288                              twinklatinboys - na: #slut #snapshot #hot #nasty #naughty #sexy #horny #shy #porn #nude   #kinky #xxx #y...    \n",
       "317                          sexy as fuck #directioner   #niall #nialhoranfacts #niallerwins #hot #justindrewbieber #justindb #believetou...    \n",
       "...                                                                                                                                       ...   \n",
       "27473            i dont want a world like this... homophonia? its not a phobie there are just asshole!  #praygay     #orlando #prayfororlando   \n",
       "27527                                                                          so much   shit going on in the world... ‚òπÔ∏è. 50 people. geeesh!   \n",
       "27561         @user shit i just realized your account isn't a month old. it's only a few weeks old. that's more like 110 tweets a day. just     \n",
       "27605  if dudes wana fuck eachother n get married, i can never be mad at tht. jus means more females for me! #damn50 #orlando # #omg50 #gay     \n",
       "27615                            what the hell is wrong with humanity? why would anyone need to do anything to prove his faith?#ridiculous      \n",
       "\n",
       "                                                                  tweet_cleaned  \\\n",
       "152                  happy dick tequila lovin slut would want way two blow kiss   \n",
       "204                   really take piss angry go show value complete utter moron   \n",
       "281          never lose one senseless violence get fucking opinion nd amendment   \n",
       "288       na slut snapshot hot nasty naughty sexy horny shy porn nude kinky xxx   \n",
       "317                                                               sexy fuck hot   \n",
       "...                                                                         ...   \n",
       "27473                            want world like asshole orlando prayfororlando   \n",
       "27527                                           much shit go world frown people   \n",
       "27561                        shit realize account month old week old like tweet   \n",
       "27605  dude fuck n get marry never mad tht jus mean female damn orlando omg gay   \n",
       "27615                      hell wrong humanity would anyone need anything prove   \n",
       "\n",
       "       user_handle  \\\n",
       "152              0   \n",
       "204              0   \n",
       "281              0   \n",
       "288              0   \n",
       "317              0   \n",
       "...            ...   \n",
       "27473            0   \n",
       "27527            0   \n",
       "27561            1   \n",
       "27605            0   \n",
       "27615            0   \n",
       "\n",
       "                                                                                                                        hashtags  \\\n",
       "152                                                                                         ['#justalillate', '#butstillontime']   \n",
       "204                                                                                                                           []   \n",
       "281                                                                                                                           []   \n",
       "288    ['#slut', '#snapshot', '#hot', '#nasty', '#naughty', '#sexy', '#horny', '#shy', '#porn', '#nude', '#kinky', '#xxx', '#y']   \n",
       "317       ['#directioner', '#niall', '#nialhoranfacts', '#niallerwins', '#hot', '#justindrewbieber', '#justindb', '#believetou']   \n",
       "...                                                                                                                          ...   \n",
       "27473                                                                                ['#praygay', '#orlando', '#prayfororlando']   \n",
       "27527                                                                                                                         []   \n",
       "27561                                                                                                                         []   \n",
       "27605                                                                                  ['#damn50', '#orlando', '#omg50', '#gay']   \n",
       "27615                                                                                                            ['#ridiculous']   \n",
       "\n",
       "                                   emojis  contains_bad_words  \n",
       "152    :two_hearts:,:face_blowing_a_kiss:                True  \n",
       "204                                   NaN                True  \n",
       "281                                   NaN                True  \n",
       "288                                   NaN                True  \n",
       "317                                   NaN                True  \n",
       "...                                   ...                 ...  \n",
       "27473                                 NaN                True  \n",
       "27527                     :frowning_face:                True  \n",
       "27561                                 NaN                True  \n",
       "27605                                 NaN                True  \n",
       "27615                                 NaN                True  \n",
       "\n",
       "[474 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pr√ºfen auf Schimpfw√∂rter\n",
    "df_analyse_label_0['contains_bad_words'] = df_analyse_label_0['tweet'].apply(lambda x: profanity.contains_profanity(x))\n",
    "\n",
    "df_analyse_label_0[df_analyse_label_0['contains_bad_words']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>count_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>father selfish drag kid run</td>\n",
       "      <td>1</td>\n",
       "      <td>['#run']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thank lyft credit use cause offer van</td>\n",
       "      <td>2</td>\n",
       "      <td>['#lyft', '#disapointed', '#getthanked']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urüì±!!! üòôüòéüëÑüëÖüí¶üí¶üí¶</td>\n",
       "      <td>model take time mobile phone kiss sunglass mouth tongue sweat droplet sweat droplet sweat droplet</td>\n",
       "      <td>0</td>\n",
       "      <td>['#model']</td>\n",
       "      <td>:mobile_phone:,:kissing_face_with_smiling_eyes:,:smiling_face_with_sunglasses:,:mouth:,:tongue:,:sweat_droplets:,:sweat_droplets:,:sweat_droplets:</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>['#motivation']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>31956</td>\n",
       "      <td>0</td>\n",
       "      <td>less than 2 weeks üòÖüôèüèºüçπüòéüéµ @user #ibiza#bringiton#mallorca#holidays#summer</td>\n",
       "      <td>less week grin sweat fold hand medium light skin tone tropical drink sunglass musical note</td>\n",
       "      <td>1</td>\n",
       "      <td>['#ibiza', '#bringiton', '#mallorca', '#holidays', '#summer']</td>\n",
       "      <td>:grinning_face_with_sweat:,:folded_hands:,:medium-light_skin_tone:,:tropical_drink:,:smiling_face_with_sunglasses:,:musical_note:</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>31957</td>\n",
       "      <td>0</td>\n",
       "      <td>off fishing tomorrow @user carnt wait first time in 2 years</td>\n",
       "      <td>fishing tomorrow wait first time year</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?üòçüòçüòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è</td>\n",
       "      <td>eat youuu red</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:red_heart:</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisolm. #shame #imwithher</td>\n",
       "      <td>see turner try wrap genuine hero like shame imwithher</td>\n",
       "      <td>0</td>\n",
       "      <td>['#shame', '#imwithher']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27649</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw to work is sad</td>\n",
       "      <td>listen sad song monday morning otw work sad</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27650 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "0          1      0   \n",
       "1          2      0   \n",
       "2          3      0   \n",
       "3          4      0   \n",
       "4          5      0   \n",
       "...      ...    ...   \n",
       "27645  31956      0   \n",
       "27646  31957      0   \n",
       "27647  31958      0   \n",
       "27648  31959      0   \n",
       "27649  31960      0   \n",
       "\n",
       "                                                                                                                                     tweet  \\\n",
       "0                                    @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1               @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                                      bihday your majesty   \n",
       "3                                                                           #model   i love u take with u all the time in urüì±!!! üòôüòéüëÑüëÖüí¶üí¶üí¶     \n",
       "4                                                                                                   factsguide: society now    #motivation   \n",
       "...                                                                                                                                    ...   \n",
       "27645                                                           less than 2 weeks üòÖüôèüèºüçπüòéüéµ @user #ibiza#bringiton#mallorca#holidays#summer     \n",
       "27646                                                                        off fishing tomorrow @user carnt wait first time in 2 years     \n",
       "27647                                                                                                ate @user isz that youuu?üòçüòçüòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è    \n",
       "27648    to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisolm. #shame #imwithher   \n",
       "27649                                                                      listening to sad songs on a monday morning otw to work is sad     \n",
       "\n",
       "                                                                                           tweet_cleaned  \\\n",
       "0                                                                            father selfish drag kid run   \n",
       "1                                                                  thank lyft credit use cause offer van   \n",
       "2                                                                                         bihday majesty   \n",
       "3      model take time mobile phone kiss sunglass mouth tongue sweat droplet sweat droplet sweat droplet   \n",
       "4                                                                          factsguide society motivation   \n",
       "...                                                                                                  ...   \n",
       "27645         less week grin sweat fold hand medium light skin tone tropical drink sunglass musical note   \n",
       "27646                                                              fishing tomorrow wait first time year   \n",
       "27647                                                                                      eat youuu red   \n",
       "27648                                              see turner try wrap genuine hero like shame imwithher   \n",
       "27649                                                        listen sad song monday morning otw work sad   \n",
       "\n",
       "       user_handle  \\\n",
       "0                1   \n",
       "1                2   \n",
       "2                0   \n",
       "3                0   \n",
       "4                0   \n",
       "...            ...   \n",
       "27645            1   \n",
       "27646            1   \n",
       "27647            1   \n",
       "27648            0   \n",
       "27649            0   \n",
       "\n",
       "                                                            hashtags  \\\n",
       "0                                                           ['#run']   \n",
       "1                           ['#lyft', '#disapointed', '#getthanked']   \n",
       "2                                                                 []   \n",
       "3                                                         ['#model']   \n",
       "4                                                    ['#motivation']   \n",
       "...                                                              ...   \n",
       "27645  ['#ibiza', '#bringiton', '#mallorca', '#holidays', '#summer']   \n",
       "27646                                                             []   \n",
       "27647                                                             []   \n",
       "27648                                       ['#shame', '#imwithher']   \n",
       "27649                                                             []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                   emojis  \\\n",
       "0                                                                                                                                                                                                                                                                                                     NaN   \n",
       "1                                                                                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                                                                                                                                                                                                                                     NaN   \n",
       "3                                                                                                                                                      :mobile_phone:,:kissing_face_with_smiling_eyes:,:smiling_face_with_sunglasses:,:mouth:,:tongue:,:sweat_droplets:,:sweat_droplets:,:sweat_droplets:   \n",
       "4                                                                                                                                                                                                                                                                                                     NaN   \n",
       "...                                                                                                                                                                                                                                                                                                   ...   \n",
       "27645                                                                                                                                                                   :grinning_face_with_sweat:,:folded_hands:,:medium-light_skin_tone:,:tropical_drink:,:smiling_face_with_sunglasses:,:musical_note:   \n",
       "27646                                                                                                                                                                                                                                                                                                 NaN   \n",
       "27647  :smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:smiling_face_with_heart-eyes:,:red_heart:   \n",
       "27648                                                                                                                                                                                                                                                                                                 NaN   \n",
       "27649                                                                                                                                                                                                                                                                                                 NaN   \n",
       "\n",
       "       count_of_words  \n",
       "0                   5  \n",
       "1                   7  \n",
       "2                   2  \n",
       "3                  15  \n",
       "4                   3  \n",
       "...               ...  \n",
       "27645              15  \n",
       "27646               6  \n",
       "27647               3  \n",
       "27648               9  \n",
       "27649               8  \n",
       "\n",
       "[27650 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(df):\n",
    "    df['count_of_words'] = df['tweet_cleaned'].apply(lambda x: len(str(x).split(\" \")))\n",
    "    return df\n",
    "\n",
    "\n",
    "df_cleaned = word_count(df_cleaned)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ausrei√üerpr√ºfung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier(data):\n",
    "    for num_col in data.select_dtypes([\"number\"]).columns:\n",
    "        sd = data[num_col].std()\n",
    "        mean = data[num_col].mean()\n",
    "        result = [out for out in data[num_col] if (out > mean + 3 * sd) or (out < mean - 3 * sd)]\n",
    "        print()\n",
    "        print(\"Column: \", num_col)\n",
    "        print(\"Mean: \", mean, \"; Std: \", sd)\n",
    "        print(\"Outlier: \", len(result), \"; Values: \", sorted(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.4835016587500816\n",
      "19.381367843198543\n"
     ]
    }
   ],
   "source": [
    "sd = df_cleaned['count_of_words'].std()\n",
    "mean = df_cleaned['count_of_words'].mean()\n",
    "result = [out for out in df_cleaned['count_of_words'] if (out > mean + 3 * sd) or (out < mean - 3 * sd)]\n",
    "out_threshold_min = mean - 3 * sd\n",
    "out_threshold_max = mean + 3 * sd\n",
    "print(out_threshold_min)\n",
    "print(out_threshold_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>count_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>12643</td>\n",
       "      <td>0</td>\n",
       "      <td>has this happened to you? ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè #dj #host #enteainer  ‚Ä¶</td>\n",
       "      <td>happen ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè dj host</td>\n",
       "      <td>0</td>\n",
       "      <td>['#dj', '#host', '#enteainer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16184</th>\n",
       "      <td>18115</td>\n",
       "      <td>0</td>\n",
       "      <td>f.a.t.h.e.r.s. #day ‚Äúf‚Äù faithful.  ‚Äúa‚Äù lays there.  ‚Äút‚Äù trustwohy.  ‚Äúh‚Äù honoring.  ‚Äúe‚Äù very-loving.  ‚Äúr‚Äù righteous.  ‚Äús‚Äù suppoive</td>\n",
       "      <td>father \" f \" faithful \" \" lay \" \" \" h \" honor \" e \" \" r \" righteous \" \" suppoive</td>\n",
       "      <td>0</td>\n",
       "      <td>['#day']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25207</th>\n",
       "      <td>29023</td>\n",
       "      <td>0</td>\n",
       "      <td>=&amp;gt; =&amp;gt; =&amp;gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send t...</td>\n",
       "      <td>= gt = gt = gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi + follow send</td>\n",
       "      <td>1</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>23146</td>\n",
       "      <td>0</td>\n",
       "      <td>****** #thequeen ******* ***   bihday ** from the qc's !!  thoroughly enjoyed our 3 day weekend in london...</td>\n",
       "      <td>* * * * * * * * * * * * * * * * bihday * * 's enjoy weekend london</td>\n",
       "      <td>0</td>\n",
       "      <td>['#thequeen']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>12121</td>\n",
       "      <td>0</td>\n",
       "      <td>.' -&amp;gt; -&amp;gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4</td>\n",
       "      <td>' -gt -gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi + follow send oo</td>\n",
       "      <td>1</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>good to see #england \"fans\" making us all feel proud #sarcasm euro 2016  via @user #disgrace   ********</td>\n",
       "      <td>good see england \" fan \" make feel proud sarcasm euro via disgrace * * * * * * * *</td>\n",
       "      <td>1</td>\n",
       "      <td>['#england', '#sarcasm', '#disgrace']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12363</th>\n",
       "      <td>13709</td>\n",
       "      <td>0</td>\n",
       "      <td>‚Üù #united states net long-term tic flows: $-79.6b (april) vs previous $78.1b   #blog #silver #gold #forex</td>\n",
       "      <td>‚Üù united states net long term tic flow $ -b ( april ) vs previous $ b blog silver gold forex</td>\n",
       "      <td>0</td>\n",
       "      <td>['#united', '#blog', '#silver', '#gold', '#forex']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>7865</td>\n",
       "      <td>0</td>\n",
       "      <td>.. -&amp;gt; -&amp;gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4</td>\n",
       "      <td>-gt -gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi + follow send oo</td>\n",
       "      <td>1</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>988</td>\n",
       "      <td>1</td>\n",
       "      <td>\"no im not attracted to asian ppl bc im not asian\"  what if i tell you no im not attracted to u bc im not (inse race here) hoe</td>\n",
       "      <td>\" Instant Message attract asian ppl Instant message asian \" tell Instant Message attract instant message ( race ) hoe</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>10192</td>\n",
       "      <td>0</td>\n",
       "      <td>- sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user send 4o4o4 + @user</td>\n",
       "      <td>sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry + add + follow send oo +</td>\n",
       "      <td>2</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>7147</td>\n",
       "      <td>0</td>\n",
       "      <td>- sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user + @user + f @user</td>\n",
       "      <td>sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry + add + follow + + f</td>\n",
       "      <td>3</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23082</th>\n",
       "      <td>26407</td>\n",
       "      <td>0</td>\n",
       "      <td>@user   my new single ‚Äòboom + bust‚Äô is out friday alongside the pre-order for my debut ep also titled ‚Äòboom + bust‚Äô</td>\n",
       "      <td>new single ' boom + bust ' friday alongside pre order debut ep also title ' boom + bust '</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23241</th>\n",
       "      <td>26601</td>\n",
       "      <td>0</td>\n",
       "      <td>auba wil go 2 city, vardy x liverpool morata wil stay @ juve n gud old giroud wil stil sta for arsenal next season   #pathetic #wenger</td>\n",
       "      <td>wil go city previously name Twitter liverpool wil stay @ n gud old wil sta arsenal next season pathetic weng</td>\n",
       "      <td>0</td>\n",
       "      <td>['#pathetic', '#wenger']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "11451  12643      0   \n",
       "16184  18115      0   \n",
       "25207  29023      0   \n",
       "20401  23146      0   \n",
       "10999  12121      0   \n",
       "1867    1966      0   \n",
       "12363  13709      0   \n",
       "7250    7865      0   \n",
       "951      988      1   \n",
       "9294   10192      0   \n",
       "6604    7147      0   \n",
       "23082  26407      0   \n",
       "23241  26601      0   \n",
       "\n",
       "                                                                                                                                             tweet  \\\n",
       "11451                                                     has this happened to you? ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè #dj #host #enteainer  ‚Ä¶    \n",
       "16184            f.a.t.h.e.r.s. #day ‚Äúf‚Äù faithful.  ‚Äúa‚Äù lays there.  ‚Äút‚Äù trustwohy.  ‚Äúh‚Äù honoring.  ‚Äúe‚Äù very-loving.  ‚Äúr‚Äù righteous.  ‚Äús‚Äù suppoive   \n",
       "25207   =&gt; =&gt; =&gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send t...   \n",
       "20401                                ****** #thequeen ******* ***   bihday ** from the qc's !!  thoroughly enjoyed our 3 day weekend in london...    \n",
       "10999  .' -&gt; -&gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4   \n",
       "1867                                       good to see #england \"fans\" making us all feel proud #sarcasm euro 2016  via @user #disgrace   ********   \n",
       "12363                                    ‚Üù #united states net long-term tic flows: $-79.6b (april) vs previous $78.1b   #blog #silver #gold #forex   \n",
       "7250   .. -&gt; -&gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4   \n",
       "951              \"no im not attracted to asian ppl bc im not asian\"  what if i tell you no im not attracted to u bc im not (inse race here) hoe      \n",
       "9294                 - sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user send 4o4o4 + @user   \n",
       "6604                  - sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user + @user + f @user   \n",
       "23082                         @user   my new single ‚Äòboom + bust‚Äô is out friday alongside the pre-order for my debut ep also titled ‚Äòboom + bust‚Äô    \n",
       "23241       auba wil go 2 city, vardy x liverpool morata wil stay @ juve n gud old giroud wil stil sta for arsenal next season   #pathetic #wenger   \n",
       "\n",
       "                                                                                                               tweet_cleaned  \\\n",
       "11451                               happen ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè dj host   \n",
       "16184                                       father \" f \" faithful \" \" lay \" \" \" h \" honor \" e \" \" r \" righteous \" \" suppoive   \n",
       "25207     = gt = gt = gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi + follow send   \n",
       "20401                                                     * * * * * * * * * * * * * * * * bihday * * 's enjoy weekend london   \n",
       "10999       ' -gt -gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi + follow send oo   \n",
       "1867                                      good see england \" fan \" make feel proud sarcasm euro via disgrace * * * * * * * *   \n",
       "12363                           ‚Üù united states net long term tic flow $ -b ( april ) vs previous $ b blog silver gold forex   \n",
       "7250          -gt -gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi + follow send oo   \n",
       "951    \" Instant Message attract asian ppl Instant message asian \" tell Instant Message attract instant message ( race ) hoe   \n",
       "9294                       sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry + add + follow send oo +   \n",
       "6604                           sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry + add + follow + + f   \n",
       "23082                              new single ' boom + bust ' friday alongside pre order debut ep also title ' boom + bust '   \n",
       "23241           wil go city previously name Twitter liverpool wil stay @ n gud old wil sta arsenal next season pathetic weng   \n",
       "\n",
       "       user_handle  \\\n",
       "11451            0   \n",
       "16184            0   \n",
       "25207            1   \n",
       "20401            0   \n",
       "10999            1   \n",
       "1867             1   \n",
       "12363            0   \n",
       "7250             1   \n",
       "951              0   \n",
       "9294             2   \n",
       "6604             3   \n",
       "23082            1   \n",
       "23241            0   \n",
       "\n",
       "                                                                      hashtags  \\\n",
       "11451                                           ['#dj', '#host', '#enteainer']   \n",
       "16184                                                                 ['#day']   \n",
       "25207  ['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']   \n",
       "20401                                                            ['#thequeen']   \n",
       "10999  ['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']   \n",
       "1867                                     ['#england', '#sarcasm', '#disgrace']   \n",
       "12363                       ['#united', '#blog', '#silver', '#gold', '#forex']   \n",
       "7250   ['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']   \n",
       "951                                                                         []   \n",
       "9294                 ['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']   \n",
       "6604                 ['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']   \n",
       "23082                                                                       []   \n",
       "23241                                                 ['#pathetic', '#wenger']   \n",
       "\n",
       "      emojis  count_of_words  \n",
       "11451    NaN              40  \n",
       "16184    NaN              24  \n",
       "25207    NaN              24  \n",
       "20401    NaN              23  \n",
       "10999    NaN              22  \n",
       "1867     NaN              21  \n",
       "12363    NaN              21  \n",
       "7250     NaN              21  \n",
       "951      NaN              20  \n",
       "9294     NaN              20  \n",
       "6604     NaN              20  \n",
       "23082    NaN              20  \n",
       "23241    NaN              20  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = df_cleaned[\n",
    "    (df_cleaned['count_of_words'] > out_threshold_max) | \n",
    "    (df_cleaned['count_of_words'] < out_threshold_min)\n",
    "]\n",
    "filtered_outliers = outliers[outliers['emojis'].isna()]\n",
    "filtered_outliers.sort_values(by='count_of_words', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                13\n",
      "label             13\n",
      "tweet             13\n",
      "tweet_cleaned     13\n",
      "user_handle       13\n",
      "hashtags          13\n",
      "emojis             0\n",
      "count_of_words    13\n",
      "dtype: int64\n",
      "id                251\n",
      "label             251\n",
      "tweet             251\n",
      "tweet_cleaned     251\n",
      "user_handle       251\n",
      "hashtags          251\n",
      "emojis            251\n",
      "count_of_words    251\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "outliers = df_cleaned[\n",
    "    (df_cleaned['count_of_words'] > out_threshold_max) | \n",
    "    (df_cleaned['count_of_words'] < out_threshold_min)\n",
    "]\n",
    "print(outliers[outliers['emojis'].isna()].count())\n",
    "print(outliers[outliers['emojis'].notna()].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nasiba\\AppData\\Local\\Temp\\ipykernel_16412\\1423343772.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet_cleaned'] = df['tweet_cleaned'].apply(lambda x: pattern.sub('', x) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>count_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>988</td>\n",
       "      <td>1</td>\n",
       "      <td>\"no im not attracted to asian ppl bc im not asian\"  what if i tell you no im not attracted to u bc im not (inse race here) hoe</td>\n",
       "      <td>\" Instant Message attract asian ppl Instant message asian \" tell Instant Message attract instant message ( race ) hoe</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>good to see #england \"fans\" making us all feel proud #sarcasm euro 2016  via @user #disgrace   ********</td>\n",
       "      <td>good see england \" fan \" make feel proud sarcasm euro via disgrace * * * * * * * *</td>\n",
       "      <td>1</td>\n",
       "      <td>['#england', '#sarcasm', '#disgrace']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>7147</td>\n",
       "      <td>0</td>\n",
       "      <td>- sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user + @user + f @user</td>\n",
       "      <td>sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry  add  follow   f</td>\n",
       "      <td>3</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>7865</td>\n",
       "      <td>0</td>\n",
       "      <td>.. -&amp;gt; -&amp;gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4</td>\n",
       "      <td>gt gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi  follow send oo</td>\n",
       "      <td>1</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>10192</td>\n",
       "      <td>0</td>\n",
       "      <td>- sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user send 4o4o4 + @user</td>\n",
       "      <td>sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry  add  follow send oo</td>\n",
       "      <td>2</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>12121</td>\n",
       "      <td>0</td>\n",
       "      <td>.' -&amp;gt; -&amp;gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4</td>\n",
       "      <td>gt gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi  follow send oo</td>\n",
       "      <td>1</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>12643</td>\n",
       "      <td>0</td>\n",
       "      <td>has this happened to you? ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè #dj #host #enteainer  ‚Ä¶</td>\n",
       "      <td>happen ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè dj host</td>\n",
       "      <td>0</td>\n",
       "      <td>['#dj', '#host', '#enteainer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12363</th>\n",
       "      <td>13709</td>\n",
       "      <td>0</td>\n",
       "      <td>‚Üù #united states net long-term tic flows: $-79.6b (april) vs previous $78.1b   #blog #silver #gold #forex</td>\n",
       "      <td>united states net long term tic flow $ b ( april ) vs previous $ b blog silver gold forex</td>\n",
       "      <td>0</td>\n",
       "      <td>['#united', '#blog', '#silver', '#gold', '#forex']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16184</th>\n",
       "      <td>18115</td>\n",
       "      <td>0</td>\n",
       "      <td>f.a.t.h.e.r.s. #day ‚Äúf‚Äù faithful.  ‚Äúa‚Äù lays there.  ‚Äút‚Äù trustwohy.  ‚Äúh‚Äù honoring.  ‚Äúe‚Äù very-loving.  ‚Äúr‚Äù righteous.  ‚Äús‚Äù suppoive</td>\n",
       "      <td>father \" f \" faithful \" \" lay \" \" \" h \" honor \" e \" \" r \" righteous \" \" suppoive</td>\n",
       "      <td>0</td>\n",
       "      <td>['#day']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>23146</td>\n",
       "      <td>0</td>\n",
       "      <td>****** #thequeen ******* ***   bihday ** from the qc's !!  thoroughly enjoyed our 3 day weekend in london...</td>\n",
       "      <td>* * * * * * * * * * * * * * * * bihday * * s enjoy weekend london</td>\n",
       "      <td>0</td>\n",
       "      <td>['#thequeen']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23082</th>\n",
       "      <td>26407</td>\n",
       "      <td>0</td>\n",
       "      <td>@user   my new single ‚Äòboom + bust‚Äô is out friday alongside the pre-order for my debut ep also titled ‚Äòboom + bust‚Äô</td>\n",
       "      <td>new single  boom  bust  friday alongside pre order debut ep also title  boom  bust</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23241</th>\n",
       "      <td>26601</td>\n",
       "      <td>0</td>\n",
       "      <td>auba wil go 2 city, vardy x liverpool morata wil stay @ juve n gud old giroud wil stil sta for arsenal next season   #pathetic #wenger</td>\n",
       "      <td>wil go city previously name Twitter liverpool wil stay @ n gud old wil sta arsenal next season pathetic weng</td>\n",
       "      <td>0</td>\n",
       "      <td>['#pathetic', '#wenger']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25207</th>\n",
       "      <td>29023</td>\n",
       "      <td>0</td>\n",
       "      <td>=&amp;gt; =&amp;gt; =&amp;gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send t...</td>\n",
       "      <td>gt  gt  gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi  follow send</td>\n",
       "      <td>1</td>\n",
       "      <td>['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "951      988      1   \n",
       "1867    1966      0   \n",
       "6604    7147      0   \n",
       "7250    7865      0   \n",
       "9294   10192      0   \n",
       "10999  12121      0   \n",
       "11451  12643      0   \n",
       "12363  13709      0   \n",
       "16184  18115      0   \n",
       "20401  23146      0   \n",
       "23082  26407      0   \n",
       "23241  26601      0   \n",
       "25207  29023      0   \n",
       "\n",
       "                                                                                                                                             tweet  \\\n",
       "951              \"no im not attracted to asian ppl bc im not asian\"  what if i tell you no im not attracted to u bc im not (inse race here) hoe      \n",
       "1867                                       good to see #england \"fans\" making us all feel proud #sarcasm euro 2016  via @user #disgrace   ********   \n",
       "6604                  - sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user + @user + f @user   \n",
       "7250   .. -&gt; -&gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4   \n",
       "9294                 - sirf ashiq log follow karen #iqbal #galib #wasi #faraz #mohsin ki full   poetry + #no add + follow @user send 4o4o4 + @user   \n",
       "10999  .' -&gt; -&gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send to 4o4o4   \n",
       "11451                                                     has this happened to you? ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè #dj #host #enteainer  ‚Ä¶    \n",
       "12363                                    ‚Üù #united states net long-term tic flows: $-79.6b (april) vs previous $78.1b   #blog #silver #gold #forex   \n",
       "16184            f.a.t.h.e.r.s. #day ‚Äúf‚Äù faithful.  ‚Äúa‚Äù lays there.  ‚Äút‚Äù trustwohy.  ‚Äúh‚Äù honoring.  ‚Äúe‚Äù very-loving.  ‚Äúr‚Äù righteous.  ‚Äús‚Äù suppoive   \n",
       "20401                                ****** #thequeen ******* ***   bihday ** from the qc's !!  thoroughly enjoyed our 3 day weekend in london...    \n",
       "23082                         @user   my new single ‚Äòboom + bust‚Äô is out friday alongside the pre-order for my debut ep also titled ‚Äòboom + bust‚Äô    \n",
       "23241       auba wil go 2 city, vardy x liverpool morata wil stay @ juve n gud old giroud wil stil sta for arsenal next season   #pathetic #wenger   \n",
       "25207   =&gt; =&gt; =&gt; sirf ashiq log follow karen #iqbal #galib #wasi #faraz #sagar #mohsin ki full   poetry, #shairi + follow @user send t...   \n",
       "\n",
       "                                                                                                               tweet_cleaned  \\\n",
       "951    \" Instant Message attract asian ppl Instant message asian \" tell Instant Message attract instant message ( race ) hoe   \n",
       "1867                                      good see england \" fan \" make feel proud sarcasm euro via disgrace * * * * * * * *   \n",
       "6604                               sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry  add  follow   f   \n",
       "7250             gt gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi  follow send oo   \n",
       "9294                          sirf ashiq log follow karen iqbal galib wasi faraz mohsin ki full poetry  add  follow send oo    \n",
       "10999            gt gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi  follow send oo   \n",
       "11451                               happen ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè dj host   \n",
       "12363                              united states net long term tic flow $ b ( april ) vs previous $ b blog silver gold forex   \n",
       "16184                                       father \" f \" faithful \" \" lay \" \" \" h \" honor \" e \" \" r \" righteous \" \" suppoive   \n",
       "20401                                                      * * * * * * * * * * * * * * * * bihday * * s enjoy weekend london   \n",
       "23082                                    new single  boom  bust  friday alongside pre order debut ep also title  boom  bust    \n",
       "23241           wil go city previously name Twitter liverpool wil stay @ n gud old wil sta arsenal next season pathetic weng   \n",
       "25207          gt  gt  gt sirf ashiq log follow karen iqbal galib wasi faraz sagar mohsin ki full poetry shairi  follow send   \n",
       "\n",
       "       user_handle  \\\n",
       "951              0   \n",
       "1867             1   \n",
       "6604             3   \n",
       "7250             1   \n",
       "9294             2   \n",
       "10999            1   \n",
       "11451            0   \n",
       "12363            0   \n",
       "16184            0   \n",
       "20401            0   \n",
       "23082            1   \n",
       "23241            0   \n",
       "25207            1   \n",
       "\n",
       "                                                                      hashtags  \\\n",
       "951                                                                         []   \n",
       "1867                                     ['#england', '#sarcasm', '#disgrace']   \n",
       "6604                 ['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']   \n",
       "7250   ['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']   \n",
       "9294                 ['#iqbal', '#galib', '#wasi', '#faraz', '#mohsin', '#no']   \n",
       "10999  ['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']   \n",
       "11451                                           ['#dj', '#host', '#enteainer']   \n",
       "12363                       ['#united', '#blog', '#silver', '#gold', '#forex']   \n",
       "16184                                                                 ['#day']   \n",
       "20401                                                            ['#thequeen']   \n",
       "23082                                                                       []   \n",
       "23241                                                 ['#pathetic', '#wenger']   \n",
       "25207  ['#iqbal', '#galib', '#wasi', '#faraz', '#sagar', '#mohsin', '#shairi']   \n",
       "\n",
       "      emojis  count_of_words  \n",
       "951      NaN              20  \n",
       "1867     NaN              21  \n",
       "6604     NaN              20  \n",
       "7250     NaN              21  \n",
       "9294     NaN              20  \n",
       "10999    NaN              22  \n",
       "11451    NaN              40  \n",
       "12363    NaN              21  \n",
       "16184    NaN              24  \n",
       "20401    NaN              23  \n",
       "23082    NaN              20  \n",
       "23241    NaN              20  \n",
       "25207    NaN              24  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(df):\n",
    "    pattern = re.compile(r\"<.*?>|@\\w+|[\\/¬ß&‚Üù+'=-]\")  \n",
    "    df['tweet_cleaned'] = df['tweet_cleaned'].apply(lambda x: pattern.sub('', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "remove_special_df = remove_special_characters(outliers)\n",
    "remove_special_df[remove_special_df['emojis'].isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
