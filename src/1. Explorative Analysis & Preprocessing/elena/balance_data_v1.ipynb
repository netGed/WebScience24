{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter_hate-speech : data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# resambling\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"..\\\\..\\\\..\\\\data\\\\twitter_hate-speech\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         @user when a father is dysfunctional and is s...\n",
      "1        @user @user thanks for #lyft credit i can't us...\n",
      "2                                      bihday your majesty\n",
      "3        #model   i love u take with u all the time in ...\n",
      "4                   factsguide: society now    #motivation\n",
      "                               ...                        \n",
      "31957    ate @user isz that youuu?ðððððð...\n",
      "31958      to see nina turner on the airwaves trying to...\n",
      "31959    listening to sad songs on a monday morning otw...\n",
      "31960    @user #sikh #temple vandalised in in #calgary,...\n",
      "31961                     thank you @user for you follow  \n",
      "Name: tweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extracting tweet-column \n",
    "\n",
    "tweets = df_train['tweet']\n",
    "y_train = df_train['label']\n",
    "\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorization:\n",
      "\n",
      "Feature Names: ['00' '000' '000001' ... 'ó¾' 'øª' 'ø¹ù']\n",
      "Count Matrix:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# # vectorization of tweet column \n",
    "\n",
    "# count_vectorizer = CountVectorizer()\n",
    "\n",
    "# count_matrix = count_vectorizer.fit_transform(tweets)\n",
    "\n",
    "# count_array = count_matrix.toarray()\n",
    "\n",
    "# feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# # Output the results\n",
    "# print(\"Count Vectorization:\\n\")\n",
    "# print(\"Feature Names:\", feature_names)\n",
    "# print(\"Count Matrix:\\n\", count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Vectorization:\n",
      "\n",
      "Feature Names: ['00' '000' '000001' ... 'ó¾' 'øª' 'ø¹ù']\n",
      "TF-IDF Matrix:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Original training dataset shape: Counter({0: 29720, 1: 2242})\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tweets)\n",
    "\n",
    "# Converting TF-IDF matrix to array >> better visualization\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Getting the feature names/words\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"\\nTF-IDF Vectorization:\\n\")\n",
    "print(\"Feature Names:\", tfidf_feature_names)\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training dataset shape: Counter({0: 29720, 1: 2242})\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train['tweet']  \n",
    "y_train = df_train['label']  \n",
    "\n",
    "print(f\"Original training dataset shape: {Counter(y_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Hybrid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled training dataset shape: Counter({0: 18575, 1: 14860})\n"
     ]
    }
   ],
   "source": [
    "#  Oversmapling the minority class & undersampling the majority class\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)  \n",
    "undersample = RandomUnderSampler(sampling_strategy=0.8, random_state=42)  \n",
    "\n",
    "# using numeric data (verctorizaiton result) instead of text data\n",
    "X_train_sm, y_train_sm = smote.fit_resample(tfidf_matrix, y_train)\n",
    "X_train_combined, y_train_combined = undersample.fit_resample(X_train_sm, y_train_sm)\n",
    "\n",
    "print(f\"Resampled training dataset shape: {Counter(y_train_combined)}\")\n",
    "\n",
    "# Converting back to DataFrame \n",
    "df_resampled_manually = pd.DataFrame(X_train_combined.toarray(), columns=tfidf_feature_names)\n",
    "df_resampled_manually['label'] = y_train_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTETomek Hybrid-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (31962, 41392) 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "31957    0\n",
      "31958    0\n",
      "31959    0\n",
      "31960    1\n",
      "31961    0\n",
      "Name: label, Length: 31962, dtype: int64\n",
      "SMOTEENN resampled shape: (59440, 41392) (59440,)\n",
      "Resampled training dataset shape: Counter({0: 29720, 1: 29720})\n"
     ]
    }
   ],
   "source": [
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_smt, y_resampled_smt = smote_tomek.fit_resample(tfidf_matrix, df_train['label'] )\n",
    "\n",
    "# Checking resampled dataset shapes\n",
    "print(\"Original dataset shape:\", tfidf_matrix.shape, y_train)\n",
    "print(\"SMOTEENN resampled shape:\", X_resampled_smt.shape, y_resampled_smt.shape)\n",
    "print(f\"Resampled training dataset shape: {Counter(y_resampled_smt)}\")\n",
    "\n",
    "# Converting back to DataFrame \n",
    "X_resampled_SMOTEEN_df = pd.DataFrame(X_resampled_smt.toarray(), columns=tfidf_feature_names)\n",
    "X_resampled_SMOTEEN_df['label'] = y_resampled_smt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTEEN Hyprid-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (31962, 41392) 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "31957    0\n",
      "31958    0\n",
      "31959    0\n",
      "31960    1\n",
      "31961    0\n",
      "Name: label, Length: 31962, dtype: int64\n",
      "SMOTEENN resampled shape: (40696, 41392) (40696,)\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled_enn, y_resampled_enn = smote_enn.fit_resample(tfidf_matrix, df_train['label'] )\n",
    "\n",
    "# Checking resampled dataset shapes\n",
    "print(\"Original dataset shape:\", tfidf_matrix.shape, y_train)\n",
    "print(\"SMOTEENN resampled shape:\", X_resampled_enn.shape, y_resampled_enn.shape)\n",
    "print(f\"Resampled training dataset shape: {Counter(y_resampled_enn)}\")\n",
    "\n",
    "# Converting back to DataFrame \n",
    "X_resampled_SMOTEEN_df = pd.DataFrame(X_resampled_enn.toarray(), columns=tfidf_feature_names)\n",
    "X_resampled_SMOTEEN_df['label'] = y_resampled_enn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
